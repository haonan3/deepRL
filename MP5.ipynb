{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "import torch\n",
    "\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from utils import *\n",
    "from agent import *\n",
    "from model import *\n",
    "from config import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we initialise our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://gym.openai.com/envs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl/downloads/venv3/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_lives = find_max_lifes(env)\n",
    "state_size = env.observation_space.shape\n",
    "action_size = 3\n",
    "rewards, episodes = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DQN Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. \n",
    "\n",
    "__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n",
    "\n",
    "__Frame__ : Number of frames processed in total.\n",
    "\n",
    "__Memory Size__ : The current size of the replay memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(action_size)\n",
    "evaluation_reward = deque(maxlen=evaluation_reward_length)\n",
    "frame = 0\n",
    "memory_size = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl/downloads/venv3/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: 2.0   memory length: 196   epsilon: 1.0    steps: 196     evaluation reward: 2.0\n",
      "episode: 1   score: 3.0   memory length: 457   epsilon: 1.0    steps: 261     evaluation reward: 2.5\n",
      "episode: 2   score: 1.0   memory length: 630   epsilon: 1.0    steps: 173     evaluation reward: 2.0\n",
      "episode: 3   score: 1.0   memory length: 784   epsilon: 1.0    steps: 154     evaluation reward: 1.75\n",
      "episode: 4   score: 2.0   memory length: 988   epsilon: 1.0    steps: 204     evaluation reward: 1.8\n",
      "episode: 5   score: 0.0   memory length: 1123   epsilon: 1.0    steps: 135     evaluation reward: 1.5\n",
      "episode: 6   score: 2.0   memory length: 1352   epsilon: 1.0    steps: 229     evaluation reward: 1.5714285714285714\n",
      "episode: 7   score: 2.0   memory length: 1548   epsilon: 1.0    steps: 196     evaluation reward: 1.625\n",
      "episode: 8   score: 0.0   memory length: 1673   epsilon: 1.0    steps: 125     evaluation reward: 1.4444444444444444\n",
      "episode: 9   score: 0.0   memory length: 1806   epsilon: 1.0    steps: 133     evaluation reward: 1.3\n",
      "episode: 10   score: 0.0   memory length: 1937   epsilon: 1.0    steps: 131     evaluation reward: 1.1818181818181819\n",
      "episode: 11   score: 3.0   memory length: 2173   epsilon: 1.0    steps: 236     evaluation reward: 1.3333333333333333\n",
      "episode: 12   score: 2.0   memory length: 2411   epsilon: 1.0    steps: 238     evaluation reward: 1.3846153846153846\n",
      "episode: 13   score: 0.0   memory length: 2543   epsilon: 1.0    steps: 132     evaluation reward: 1.2857142857142858\n",
      "episode: 14   score: 2.0   memory length: 2744   epsilon: 1.0    steps: 201     evaluation reward: 1.3333333333333333\n",
      "episode: 15   score: 1.0   memory length: 2916   epsilon: 1.0    steps: 172     evaluation reward: 1.3125\n",
      "episode: 16   score: 1.0   memory length: 3099   epsilon: 1.0    steps: 183     evaluation reward: 1.2941176470588236\n",
      "episode: 17   score: 2.0   memory length: 3298   epsilon: 1.0    steps: 199     evaluation reward: 1.3333333333333333\n",
      "episode: 18   score: 3.0   memory length: 3552   epsilon: 1.0    steps: 254     evaluation reward: 1.4210526315789473\n",
      "episode: 19   score: 0.0   memory length: 3685   epsilon: 1.0    steps: 133     evaluation reward: 1.35\n",
      "episode: 20   score: 1.0   memory length: 3838   epsilon: 1.0    steps: 153     evaluation reward: 1.3333333333333333\n",
      "episode: 21   score: 2.0   memory length: 4031   epsilon: 1.0    steps: 193     evaluation reward: 1.3636363636363635\n",
      "episode: 22   score: 2.0   memory length: 4232   epsilon: 1.0    steps: 201     evaluation reward: 1.391304347826087\n",
      "episode: 23   score: 0.0   memory length: 4369   epsilon: 1.0    steps: 137     evaluation reward: 1.3333333333333333\n",
      "episode: 24   score: 1.0   memory length: 4549   epsilon: 1.0    steps: 180     evaluation reward: 1.32\n",
      "episode: 25   score: 0.0   memory length: 4688   epsilon: 1.0    steps: 139     evaluation reward: 1.2692307692307692\n",
      "episode: 26   score: 0.0   memory length: 4816   epsilon: 1.0    steps: 128     evaluation reward: 1.2222222222222223\n",
      "episode: 27   score: 1.0   memory length: 4982   epsilon: 1.0    steps: 166     evaluation reward: 1.2142857142857142\n",
      "episode: 28   score: 4.0   memory length: 5265   epsilon: 1.0    steps: 283     evaluation reward: 1.3103448275862069\n",
      "episode: 29   score: 0.0   memory length: 5399   epsilon: 1.0    steps: 134     evaluation reward: 1.2666666666666666\n",
      "episode: 30   score: 3.0   memory length: 5673   epsilon: 1.0    steps: 274     evaluation reward: 1.3225806451612903\n",
      "episode: 31   score: 2.0   memory length: 5868   epsilon: 1.0    steps: 195     evaluation reward: 1.34375\n",
      "episode: 32   score: 2.0   memory length: 6093   epsilon: 1.0    steps: 225     evaluation reward: 1.3636363636363635\n",
      "episode: 33   score: 1.0   memory length: 6256   epsilon: 1.0    steps: 163     evaluation reward: 1.3529411764705883\n",
      "episode: 34   score: 1.0   memory length: 6411   epsilon: 1.0    steps: 155     evaluation reward: 1.3428571428571427\n",
      "episode: 35   score: 2.0   memory length: 6616   epsilon: 1.0    steps: 205     evaluation reward: 1.3611111111111112\n",
      "episode: 36   score: 3.0   memory length: 6890   epsilon: 1.0    steps: 274     evaluation reward: 1.4054054054054055\n",
      "episode: 37   score: 0.0   memory length: 7030   epsilon: 1.0    steps: 140     evaluation reward: 1.368421052631579\n",
      "episode: 38   score: 1.0   memory length: 7213   epsilon: 1.0    steps: 183     evaluation reward: 1.358974358974359\n",
      "episode: 39   score: 3.0   memory length: 7455   epsilon: 1.0    steps: 242     evaluation reward: 1.4\n",
      "episode: 40   score: 0.0   memory length: 7582   epsilon: 1.0    steps: 127     evaluation reward: 1.3658536585365855\n",
      "episode: 41   score: 0.0   memory length: 7715   epsilon: 1.0    steps: 133     evaluation reward: 1.3333333333333333\n",
      "episode: 42   score: 5.0   memory length: 8072   epsilon: 1.0    steps: 357     evaluation reward: 1.4186046511627908\n",
      "episode: 43   score: 2.0   memory length: 8282   epsilon: 1.0    steps: 210     evaluation reward: 1.4318181818181819\n",
      "episode: 44   score: 2.0   memory length: 8516   epsilon: 1.0    steps: 234     evaluation reward: 1.4444444444444444\n",
      "episode: 45   score: 1.0   memory length: 8671   epsilon: 1.0    steps: 155     evaluation reward: 1.434782608695652\n",
      "episode: 46   score: 0.0   memory length: 8801   epsilon: 1.0    steps: 130     evaluation reward: 1.4042553191489362\n",
      "episode: 47   score: 1.0   memory length: 8975   epsilon: 1.0    steps: 174     evaluation reward: 1.3958333333333333\n",
      "episode: 48   score: 2.0   memory length: 9203   epsilon: 1.0    steps: 228     evaluation reward: 1.4081632653061225\n",
      "episode: 49   score: 1.0   memory length: 9375   epsilon: 1.0    steps: 172     evaluation reward: 1.4\n",
      "episode: 50   score: 0.0   memory length: 9501   epsilon: 1.0    steps: 126     evaluation reward: 1.3725490196078431\n",
      "episode: 51   score: 2.0   memory length: 9704   epsilon: 1.0    steps: 203     evaluation reward: 1.3846153846153846\n",
      "episode: 52   score: 2.0   memory length: 9901   epsilon: 1.0    steps: 197     evaluation reward: 1.3962264150943395\n",
      "episode: 53   score: 2.0   memory length: 10105   epsilon: 1.0    steps: 204     evaluation reward: 1.4074074074074074\n",
      "episode: 54   score: 0.0   memory length: 10234   epsilon: 1.0    steps: 129     evaluation reward: 1.3818181818181818\n",
      "episode: 55   score: 1.0   memory length: 10391   epsilon: 1.0    steps: 157     evaluation reward: 1.375\n",
      "episode: 56   score: 2.0   memory length: 10593   epsilon: 1.0    steps: 202     evaluation reward: 1.3859649122807018\n",
      "episode: 57   score: 1.0   memory length: 10775   epsilon: 1.0    steps: 182     evaluation reward: 1.3793103448275863\n",
      "episode: 58   score: 1.0   memory length: 10951   epsilon: 1.0    steps: 176     evaluation reward: 1.3728813559322033\n",
      "episode: 59   score: 0.0   memory length: 11085   epsilon: 1.0    steps: 134     evaluation reward: 1.35\n",
      "episode: 60   score: 2.0   memory length: 11288   epsilon: 1.0    steps: 203     evaluation reward: 1.360655737704918\n",
      "episode: 61   score: 1.0   memory length: 11469   epsilon: 1.0    steps: 181     evaluation reward: 1.3548387096774193\n",
      "episode: 62   score: 2.0   memory length: 11673   epsilon: 1.0    steps: 204     evaluation reward: 1.3650793650793651\n",
      "episode: 63   score: 0.0   memory length: 11796   epsilon: 1.0    steps: 123     evaluation reward: 1.34375\n",
      "episode: 64   score: 1.0   memory length: 11971   epsilon: 1.0    steps: 175     evaluation reward: 1.3384615384615384\n",
      "episode: 65   score: 2.0   memory length: 12188   epsilon: 1.0    steps: 217     evaluation reward: 1.3484848484848484\n",
      "episode: 66   score: 0.0   memory length: 12319   epsilon: 1.0    steps: 131     evaluation reward: 1.328358208955224\n",
      "episode: 67   score: 2.0   memory length: 12539   epsilon: 1.0    steps: 220     evaluation reward: 1.338235294117647\n",
      "episode: 68   score: 0.0   memory length: 12670   epsilon: 1.0    steps: 131     evaluation reward: 1.318840579710145\n",
      "episode: 69   score: 1.0   memory length: 12847   epsilon: 1.0    steps: 177     evaluation reward: 1.3142857142857143\n",
      "episode: 70   score: 0.0   memory length: 12982   epsilon: 1.0    steps: 135     evaluation reward: 1.295774647887324\n",
      "episode: 71   score: 0.0   memory length: 13118   epsilon: 1.0    steps: 136     evaluation reward: 1.2777777777777777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 72   score: 1.0   memory length: 13279   epsilon: 1.0    steps: 161     evaluation reward: 1.273972602739726\n",
      "episode: 73   score: 2.0   memory length: 13481   epsilon: 1.0    steps: 202     evaluation reward: 1.2837837837837838\n",
      "episode: 74   score: 2.0   memory length: 13679   epsilon: 1.0    steps: 198     evaluation reward: 1.2933333333333332\n",
      "episode: 75   score: 1.0   memory length: 13834   epsilon: 1.0    steps: 155     evaluation reward: 1.2894736842105263\n",
      "episode: 76   score: 0.0   memory length: 13970   epsilon: 1.0    steps: 136     evaluation reward: 1.2727272727272727\n",
      "episode: 77   score: 1.0   memory length: 14147   epsilon: 1.0    steps: 177     evaluation reward: 1.2692307692307692\n",
      "episode: 78   score: 2.0   memory length: 14349   epsilon: 1.0    steps: 202     evaluation reward: 1.2784810126582278\n",
      "episode: 79   score: 0.0   memory length: 14484   epsilon: 1.0    steps: 135     evaluation reward: 1.2625\n",
      "episode: 80   score: 2.0   memory length: 14702   epsilon: 1.0    steps: 218     evaluation reward: 1.271604938271605\n",
      "episode: 81   score: 4.0   memory length: 14993   epsilon: 1.0    steps: 291     evaluation reward: 1.3048780487804879\n",
      "episode: 82   score: 3.0   memory length: 15241   epsilon: 1.0    steps: 248     evaluation reward: 1.3253012048192772\n",
      "episode: 83   score: 0.0   memory length: 15380   epsilon: 1.0    steps: 139     evaluation reward: 1.3095238095238095\n",
      "episode: 84   score: 1.0   memory length: 15545   epsilon: 1.0    steps: 165     evaluation reward: 1.3058823529411765\n",
      "episode: 85   score: 1.0   memory length: 15721   epsilon: 1.0    steps: 176     evaluation reward: 1.302325581395349\n",
      "episode: 86   score: 2.0   memory length: 15910   epsilon: 1.0    steps: 189     evaluation reward: 1.3103448275862069\n",
      "episode: 87   score: 2.0   memory length: 16120   epsilon: 1.0    steps: 210     evaluation reward: 1.3181818181818181\n",
      "episode: 88   score: 1.0   memory length: 16281   epsilon: 1.0    steps: 161     evaluation reward: 1.3146067415730338\n",
      "episode: 89   score: 0.0   memory length: 16410   epsilon: 1.0    steps: 129     evaluation reward: 1.3\n",
      "episode: 90   score: 0.0   memory length: 16536   epsilon: 1.0    steps: 126     evaluation reward: 1.2857142857142858\n",
      "episode: 91   score: 2.0   memory length: 16723   epsilon: 1.0    steps: 187     evaluation reward: 1.2934782608695652\n",
      "episode: 92   score: 1.0   memory length: 16884   epsilon: 1.0    steps: 161     evaluation reward: 1.2903225806451613\n",
      "episode: 93   score: 2.0   memory length: 17100   epsilon: 1.0    steps: 216     evaluation reward: 1.297872340425532\n",
      "episode: 94   score: 3.0   memory length: 17318   epsilon: 1.0    steps: 218     evaluation reward: 1.3157894736842106\n",
      "episode: 95   score: 1.0   memory length: 17475   epsilon: 1.0    steps: 157     evaluation reward: 1.3125\n",
      "episode: 96   score: 0.0   memory length: 17612   epsilon: 1.0    steps: 137     evaluation reward: 1.2989690721649485\n",
      "episode: 97   score: 1.0   memory length: 17778   epsilon: 1.0    steps: 166     evaluation reward: 1.2959183673469388\n",
      "episode: 98   score: 3.0   memory length: 18020   epsilon: 1.0    steps: 242     evaluation reward: 1.3131313131313131\n",
      "episode: 99   score: 0.0   memory length: 18150   epsilon: 1.0    steps: 130     evaluation reward: 1.3\n",
      "episode: 100   score: 1.0   memory length: 18307   epsilon: 1.0    steps: 157     evaluation reward: 1.29\n",
      "episode: 101   score: 1.0   memory length: 18470   epsilon: 1.0    steps: 163     evaluation reward: 1.27\n",
      "episode: 102   score: 3.0   memory length: 18723   epsilon: 1.0    steps: 253     evaluation reward: 1.29\n",
      "episode: 103   score: 0.0   memory length: 18861   epsilon: 1.0    steps: 138     evaluation reward: 1.28\n",
      "episode: 104   score: 2.0   memory length: 19064   epsilon: 1.0    steps: 203     evaluation reward: 1.28\n",
      "episode: 105   score: 2.0   memory length: 19280   epsilon: 1.0    steps: 216     evaluation reward: 1.3\n",
      "episode: 106   score: 6.0   memory length: 19678   epsilon: 1.0    steps: 398     evaluation reward: 1.34\n",
      "episode: 107   score: 4.0   memory length: 19996   epsilon: 1.0    steps: 318     evaluation reward: 1.36\n",
      "episode: 108   score: 0.0   memory length: 20126   epsilon: 1.0    steps: 130     evaluation reward: 1.36\n",
      "episode: 109   score: 2.0   memory length: 20336   epsilon: 1.0    steps: 210     evaluation reward: 1.38\n",
      "episode: 110   score: 0.0   memory length: 20469   epsilon: 1.0    steps: 133     evaluation reward: 1.38\n",
      "episode: 111   score: 0.0   memory length: 20596   epsilon: 1.0    steps: 127     evaluation reward: 1.35\n",
      "episode: 112   score: 5.0   memory length: 20908   epsilon: 1.0    steps: 312     evaluation reward: 1.38\n",
      "episode: 113   score: 2.0   memory length: 21125   epsilon: 1.0    steps: 217     evaluation reward: 1.4\n",
      "episode: 114   score: 0.0   memory length: 21250   epsilon: 1.0    steps: 125     evaluation reward: 1.38\n",
      "episode: 115   score: 0.0   memory length: 21376   epsilon: 1.0    steps: 126     evaluation reward: 1.37\n",
      "episode: 116   score: 2.0   memory length: 21597   epsilon: 1.0    steps: 221     evaluation reward: 1.38\n",
      "episode: 117   score: 1.0   memory length: 21772   epsilon: 1.0    steps: 175     evaluation reward: 1.37\n",
      "episode: 118   score: 3.0   memory length: 22052   epsilon: 1.0    steps: 280     evaluation reward: 1.37\n",
      "episode: 119   score: 2.0   memory length: 22257   epsilon: 1.0    steps: 205     evaluation reward: 1.39\n",
      "episode: 120   score: 0.0   memory length: 22384   epsilon: 1.0    steps: 127     evaluation reward: 1.38\n",
      "episode: 121   score: 1.0   memory length: 22564   epsilon: 1.0    steps: 180     evaluation reward: 1.37\n",
      "episode: 122   score: 2.0   memory length: 22746   epsilon: 1.0    steps: 182     evaluation reward: 1.37\n",
      "episode: 123   score: 3.0   memory length: 22976   epsilon: 1.0    steps: 230     evaluation reward: 1.4\n",
      "episode: 124   score: 0.0   memory length: 23100   epsilon: 1.0    steps: 124     evaluation reward: 1.39\n",
      "episode: 125   score: 3.0   memory length: 23370   epsilon: 1.0    steps: 270     evaluation reward: 1.42\n",
      "episode: 126   score: 0.0   memory length: 23506   epsilon: 1.0    steps: 136     evaluation reward: 1.42\n",
      "episode: 127   score: 1.0   memory length: 23666   epsilon: 1.0    steps: 160     evaluation reward: 1.42\n",
      "episode: 128   score: 1.0   memory length: 23848   epsilon: 1.0    steps: 182     evaluation reward: 1.39\n",
      "episode: 129   score: 3.0   memory length: 24100   epsilon: 1.0    steps: 252     evaluation reward: 1.42\n",
      "episode: 130   score: 1.0   memory length: 24275   epsilon: 1.0    steps: 175     evaluation reward: 1.4\n",
      "episode: 131   score: 0.0   memory length: 24409   epsilon: 1.0    steps: 134     evaluation reward: 1.38\n",
      "episode: 132   score: 3.0   memory length: 24656   epsilon: 1.0    steps: 247     evaluation reward: 1.39\n",
      "episode: 133   score: 0.0   memory length: 24787   epsilon: 1.0    steps: 131     evaluation reward: 1.38\n",
      "episode: 134   score: 3.0   memory length: 25041   epsilon: 1.0    steps: 254     evaluation reward: 1.4\n",
      "episode: 135   score: 2.0   memory length: 25251   epsilon: 1.0    steps: 210     evaluation reward: 1.4\n",
      "episode: 136   score: 1.0   memory length: 25409   epsilon: 1.0    steps: 158     evaluation reward: 1.38\n",
      "episode: 137   score: 2.0   memory length: 25634   epsilon: 1.0    steps: 225     evaluation reward: 1.4\n",
      "episode: 138   score: 0.0   memory length: 25768   epsilon: 1.0    steps: 134     evaluation reward: 1.39\n",
      "episode: 139   score: 1.0   memory length: 25945   epsilon: 1.0    steps: 177     evaluation reward: 1.37\n",
      "episode: 140   score: 0.0   memory length: 26086   epsilon: 1.0    steps: 141     evaluation reward: 1.37\n",
      "episode: 141   score: 1.0   memory length: 26248   epsilon: 1.0    steps: 162     evaluation reward: 1.38\n",
      "episode: 142   score: 0.0   memory length: 26386   epsilon: 1.0    steps: 138     evaluation reward: 1.33\n",
      "episode: 143   score: 0.0   memory length: 26513   epsilon: 1.0    steps: 127     evaluation reward: 1.31\n",
      "episode: 144   score: 2.0   memory length: 26738   epsilon: 1.0    steps: 225     evaluation reward: 1.31\n",
      "episode: 145   score: 3.0   memory length: 26993   epsilon: 1.0    steps: 255     evaluation reward: 1.33\n",
      "episode: 146   score: 1.0   memory length: 27149   epsilon: 1.0    steps: 156     evaluation reward: 1.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 147   score: 1.0   memory length: 27328   epsilon: 1.0    steps: 179     evaluation reward: 1.34\n",
      "episode: 148   score: 1.0   memory length: 27502   epsilon: 1.0    steps: 174     evaluation reward: 1.33\n",
      "episode: 149   score: 1.0   memory length: 27661   epsilon: 1.0    steps: 159     evaluation reward: 1.33\n",
      "episode: 150   score: 2.0   memory length: 27847   epsilon: 1.0    steps: 186     evaluation reward: 1.35\n",
      "episode: 151   score: 0.0   memory length: 27988   epsilon: 1.0    steps: 141     evaluation reward: 1.33\n",
      "episode: 152   score: 0.0   memory length: 28113   epsilon: 1.0    steps: 125     evaluation reward: 1.31\n",
      "episode: 153   score: 2.0   memory length: 28318   epsilon: 1.0    steps: 205     evaluation reward: 1.31\n",
      "episode: 154   score: 2.0   memory length: 28508   epsilon: 1.0    steps: 190     evaluation reward: 1.33\n",
      "episode: 155   score: 2.0   memory length: 28713   epsilon: 1.0    steps: 205     evaluation reward: 1.34\n",
      "episode: 156   score: 0.0   memory length: 28845   epsilon: 1.0    steps: 132     evaluation reward: 1.32\n",
      "episode: 157   score: 1.0   memory length: 29012   epsilon: 1.0    steps: 167     evaluation reward: 1.32\n",
      "episode: 158   score: 0.0   memory length: 29139   epsilon: 1.0    steps: 127     evaluation reward: 1.31\n",
      "episode: 159   score: 0.0   memory length: 29274   epsilon: 1.0    steps: 135     evaluation reward: 1.31\n",
      "episode: 160   score: 0.0   memory length: 29422   epsilon: 1.0    steps: 148     evaluation reward: 1.29\n",
      "episode: 161   score: 1.0   memory length: 29581   epsilon: 1.0    steps: 159     evaluation reward: 1.29\n",
      "episode: 162   score: 2.0   memory length: 29793   epsilon: 1.0    steps: 212     evaluation reward: 1.29\n",
      "episode: 163   score: 0.0   memory length: 29921   epsilon: 1.0    steps: 128     evaluation reward: 1.29\n",
      "episode: 164   score: 2.0   memory length: 30149   epsilon: 1.0    steps: 228     evaluation reward: 1.3\n",
      "episode: 165   score: 0.0   memory length: 30285   epsilon: 1.0    steps: 136     evaluation reward: 1.28\n",
      "episode: 166   score: 2.0   memory length: 30491   epsilon: 1.0    steps: 206     evaluation reward: 1.3\n",
      "episode: 167   score: 1.0   memory length: 30662   epsilon: 1.0    steps: 171     evaluation reward: 1.29\n",
      "episode: 168   score: 1.0   memory length: 30825   epsilon: 1.0    steps: 163     evaluation reward: 1.3\n",
      "episode: 169   score: 1.0   memory length: 30996   epsilon: 1.0    steps: 171     evaluation reward: 1.3\n",
      "episode: 170   score: 3.0   memory length: 31228   epsilon: 1.0    steps: 232     evaluation reward: 1.33\n",
      "episode: 171   score: 0.0   memory length: 31366   epsilon: 1.0    steps: 138     evaluation reward: 1.33\n",
      "episode: 172   score: 2.0   memory length: 31577   epsilon: 1.0    steps: 211     evaluation reward: 1.34\n",
      "episode: 173   score: 1.0   memory length: 31734   epsilon: 1.0    steps: 157     evaluation reward: 1.33\n",
      "episode: 174   score: 0.0   memory length: 31863   epsilon: 1.0    steps: 129     evaluation reward: 1.31\n",
      "episode: 175   score: 2.0   memory length: 32065   epsilon: 1.0    steps: 202     evaluation reward: 1.32\n",
      "episode: 176   score: 2.0   memory length: 32270   epsilon: 1.0    steps: 205     evaluation reward: 1.34\n",
      "episode: 177   score: 3.0   memory length: 32505   epsilon: 1.0    steps: 235     evaluation reward: 1.36\n",
      "episode: 178   score: 0.0   memory length: 32638   epsilon: 1.0    steps: 133     evaluation reward: 1.34\n",
      "episode: 179   score: 1.0   memory length: 32810   epsilon: 1.0    steps: 172     evaluation reward: 1.35\n",
      "episode: 180   score: 0.0   memory length: 32944   epsilon: 1.0    steps: 134     evaluation reward: 1.33\n",
      "episode: 181   score: 1.0   memory length: 33109   epsilon: 1.0    steps: 165     evaluation reward: 1.3\n",
      "episode: 182   score: 2.0   memory length: 33316   epsilon: 1.0    steps: 207     evaluation reward: 1.29\n",
      "episode: 183   score: 0.0   memory length: 33448   epsilon: 1.0    steps: 132     evaluation reward: 1.29\n",
      "episode: 184   score: 2.0   memory length: 33652   epsilon: 1.0    steps: 204     evaluation reward: 1.3\n",
      "episode: 185   score: 3.0   memory length: 33906   epsilon: 1.0    steps: 254     evaluation reward: 1.32\n",
      "episode: 186   score: 0.0   memory length: 34032   epsilon: 1.0    steps: 126     evaluation reward: 1.3\n",
      "episode: 187   score: 0.0   memory length: 34163   epsilon: 1.0    steps: 131     evaluation reward: 1.28\n",
      "episode: 188   score: 0.0   memory length: 34294   epsilon: 1.0    steps: 131     evaluation reward: 1.27\n",
      "episode: 189   score: 3.0   memory length: 34553   epsilon: 1.0    steps: 259     evaluation reward: 1.3\n",
      "episode: 190   score: 1.0   memory length: 34717   epsilon: 1.0    steps: 164     evaluation reward: 1.31\n",
      "episode: 191   score: 0.0   memory length: 34852   epsilon: 1.0    steps: 135     evaluation reward: 1.29\n",
      "episode: 192   score: 2.0   memory length: 35060   epsilon: 1.0    steps: 208     evaluation reward: 1.3\n",
      "episode: 193   score: 1.0   memory length: 35234   epsilon: 1.0    steps: 174     evaluation reward: 1.29\n",
      "episode: 194   score: 3.0   memory length: 35461   epsilon: 1.0    steps: 227     evaluation reward: 1.29\n",
      "episode: 195   score: 1.0   memory length: 35644   epsilon: 1.0    steps: 183     evaluation reward: 1.29\n",
      "episode: 196   score: 3.0   memory length: 35892   epsilon: 1.0    steps: 248     evaluation reward: 1.32\n",
      "episode: 197   score: 3.0   memory length: 36139   epsilon: 1.0    steps: 247     evaluation reward: 1.34\n",
      "episode: 198   score: 2.0   memory length: 36356   epsilon: 1.0    steps: 217     evaluation reward: 1.33\n",
      "episode: 199   score: 4.0   memory length: 36659   epsilon: 1.0    steps: 303     evaluation reward: 1.37\n",
      "episode: 200   score: 3.0   memory length: 36912   epsilon: 1.0    steps: 253     evaluation reward: 1.39\n",
      "episode: 201   score: 1.0   memory length: 37077   epsilon: 1.0    steps: 165     evaluation reward: 1.39\n",
      "episode: 202   score: 1.0   memory length: 37231   epsilon: 1.0    steps: 154     evaluation reward: 1.37\n",
      "episode: 203   score: 1.0   memory length: 37412   epsilon: 1.0    steps: 181     evaluation reward: 1.38\n",
      "episode: 204   score: 1.0   memory length: 37578   epsilon: 1.0    steps: 166     evaluation reward: 1.37\n",
      "episode: 205   score: 1.0   memory length: 37757   epsilon: 1.0    steps: 179     evaluation reward: 1.36\n",
      "episode: 206   score: 4.0   memory length: 38061   epsilon: 1.0    steps: 304     evaluation reward: 1.34\n",
      "episode: 207   score: 0.0   memory length: 38189   epsilon: 1.0    steps: 128     evaluation reward: 1.3\n",
      "episode: 208   score: 0.0   memory length: 38321   epsilon: 1.0    steps: 132     evaluation reward: 1.3\n",
      "episode: 209   score: 0.0   memory length: 38454   epsilon: 1.0    steps: 133     evaluation reward: 1.28\n",
      "episode: 210   score: 1.0   memory length: 38626   epsilon: 1.0    steps: 172     evaluation reward: 1.29\n",
      "episode: 211   score: 0.0   memory length: 38754   epsilon: 1.0    steps: 128     evaluation reward: 1.29\n",
      "episode: 212   score: 2.0   memory length: 38948   epsilon: 1.0    steps: 194     evaluation reward: 1.26\n",
      "episode: 213   score: 0.0   memory length: 39079   epsilon: 1.0    steps: 131     evaluation reward: 1.24\n",
      "episode: 214   score: 0.0   memory length: 39205   epsilon: 1.0    steps: 126     evaluation reward: 1.24\n",
      "episode: 215   score: 2.0   memory length: 39427   epsilon: 1.0    steps: 222     evaluation reward: 1.26\n",
      "episode: 216   score: 3.0   memory length: 39672   epsilon: 1.0    steps: 245     evaluation reward: 1.27\n",
      "episode: 217   score: 1.0   memory length: 39852   epsilon: 1.0    steps: 180     evaluation reward: 1.27\n",
      "episode: 218   score: 0.0   memory length: 39977   epsilon: 1.0    steps: 125     evaluation reward: 1.24\n",
      "episode: 219   score: 0.0   memory length: 40100   epsilon: 1.0    steps: 123     evaluation reward: 1.22\n",
      "episode: 220   score: 0.0   memory length: 40241   epsilon: 1.0    steps: 141     evaluation reward: 1.22\n",
      "episode: 221   score: 0.0   memory length: 40374   epsilon: 1.0    steps: 133     evaluation reward: 1.21\n",
      "episode: 222   score: 4.0   memory length: 40680   epsilon: 1.0    steps: 306     evaluation reward: 1.23\n",
      "episode: 223   score: 1.0   memory length: 40863   epsilon: 1.0    steps: 183     evaluation reward: 1.21\n",
      "episode: 224   score: 1.0   memory length: 41041   epsilon: 1.0    steps: 178     evaluation reward: 1.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 225   score: 2.0   memory length: 41221   epsilon: 1.0    steps: 180     evaluation reward: 1.21\n",
      "episode: 226   score: 0.0   memory length: 41358   epsilon: 1.0    steps: 137     evaluation reward: 1.21\n",
      "episode: 227   score: 3.0   memory length: 41584   epsilon: 1.0    steps: 226     evaluation reward: 1.23\n",
      "episode: 228   score: 2.0   memory length: 41789   epsilon: 1.0    steps: 205     evaluation reward: 1.24\n",
      "episode: 229   score: 0.0   memory length: 41923   epsilon: 1.0    steps: 134     evaluation reward: 1.21\n",
      "episode: 230   score: 0.0   memory length: 42065   epsilon: 1.0    steps: 142     evaluation reward: 1.2\n",
      "episode: 231   score: 1.0   memory length: 42240   epsilon: 1.0    steps: 175     evaluation reward: 1.21\n",
      "episode: 232   score: 3.0   memory length: 42461   epsilon: 1.0    steps: 221     evaluation reward: 1.21\n",
      "episode: 233   score: 2.0   memory length: 42660   epsilon: 1.0    steps: 199     evaluation reward: 1.23\n",
      "episode: 234   score: 0.0   memory length: 42802   epsilon: 1.0    steps: 142     evaluation reward: 1.2\n",
      "episode: 235   score: 2.0   memory length: 42984   epsilon: 1.0    steps: 182     evaluation reward: 1.2\n",
      "episode: 236   score: 2.0   memory length: 43220   epsilon: 1.0    steps: 236     evaluation reward: 1.21\n",
      "episode: 237   score: 0.0   memory length: 43359   epsilon: 1.0    steps: 139     evaluation reward: 1.19\n",
      "episode: 238   score: 3.0   memory length: 43591   epsilon: 1.0    steps: 232     evaluation reward: 1.22\n",
      "episode: 239   score: 7.0   memory length: 43873   epsilon: 1.0    steps: 282     evaluation reward: 1.28\n",
      "episode: 240   score: 0.0   memory length: 44003   epsilon: 1.0    steps: 130     evaluation reward: 1.28\n",
      "episode: 241   score: 4.0   memory length: 44266   epsilon: 1.0    steps: 263     evaluation reward: 1.31\n",
      "episode: 242   score: 4.0   memory length: 44564   epsilon: 1.0    steps: 298     evaluation reward: 1.35\n",
      "episode: 243   score: 0.0   memory length: 44701   epsilon: 1.0    steps: 137     evaluation reward: 1.35\n",
      "episode: 244   score: 1.0   memory length: 44872   epsilon: 1.0    steps: 171     evaluation reward: 1.34\n",
      "episode: 245   score: 0.0   memory length: 45008   epsilon: 1.0    steps: 136     evaluation reward: 1.31\n",
      "episode: 246   score: 0.0   memory length: 45139   epsilon: 1.0    steps: 131     evaluation reward: 1.3\n",
      "episode: 247   score: 1.0   memory length: 45319   epsilon: 1.0    steps: 180     evaluation reward: 1.3\n",
      "episode: 248   score: 0.0   memory length: 45454   epsilon: 1.0    steps: 135     evaluation reward: 1.29\n",
      "episode: 249   score: 2.0   memory length: 45658   epsilon: 1.0    steps: 204     evaluation reward: 1.3\n",
      "episode: 250   score: 1.0   memory length: 45812   epsilon: 1.0    steps: 154     evaluation reward: 1.29\n",
      "episode: 251   score: 2.0   memory length: 46018   epsilon: 1.0    steps: 206     evaluation reward: 1.31\n",
      "episode: 252   score: 2.0   memory length: 46207   epsilon: 1.0    steps: 189     evaluation reward: 1.33\n",
      "episode: 253   score: 1.0   memory length: 46371   epsilon: 1.0    steps: 164     evaluation reward: 1.32\n",
      "episode: 254   score: 1.0   memory length: 46523   epsilon: 1.0    steps: 152     evaluation reward: 1.31\n",
      "episode: 255   score: 2.0   memory length: 46726   epsilon: 1.0    steps: 203     evaluation reward: 1.31\n",
      "episode: 256   score: 1.0   memory length: 46902   epsilon: 1.0    steps: 176     evaluation reward: 1.32\n",
      "episode: 257   score: 2.0   memory length: 47105   epsilon: 1.0    steps: 203     evaluation reward: 1.33\n",
      "episode: 258   score: 2.0   memory length: 47298   epsilon: 1.0    steps: 193     evaluation reward: 1.35\n",
      "episode: 259   score: 3.0   memory length: 47566   epsilon: 1.0    steps: 268     evaluation reward: 1.38\n",
      "episode: 260   score: 1.0   memory length: 47741   epsilon: 1.0    steps: 175     evaluation reward: 1.39\n",
      "episode: 261   score: 1.0   memory length: 47912   epsilon: 1.0    steps: 171     evaluation reward: 1.39\n",
      "episode: 262   score: 0.0   memory length: 48052   epsilon: 1.0    steps: 140     evaluation reward: 1.37\n",
      "episode: 263   score: 2.0   memory length: 48250   epsilon: 1.0    steps: 198     evaluation reward: 1.39\n",
      "episode: 264   score: 1.0   memory length: 48430   epsilon: 1.0    steps: 180     evaluation reward: 1.38\n",
      "episode: 265   score: 0.0   memory length: 48560   epsilon: 1.0    steps: 130     evaluation reward: 1.38\n",
      "episode: 266   score: 1.0   memory length: 48740   epsilon: 1.0    steps: 180     evaluation reward: 1.37\n",
      "episode: 267   score: 2.0   memory length: 48949   epsilon: 1.0    steps: 209     evaluation reward: 1.38\n",
      "episode: 268   score: 0.0   memory length: 49095   epsilon: 1.0    steps: 146     evaluation reward: 1.37\n",
      "episode: 269   score: 2.0   memory length: 49330   epsilon: 1.0    steps: 235     evaluation reward: 1.38\n",
      "episode: 270   score: 1.0   memory length: 49506   epsilon: 1.0    steps: 176     evaluation reward: 1.36\n",
      "episode: 271   score: 0.0   memory length: 49636   epsilon: 1.0    steps: 130     evaluation reward: 1.36\n",
      "episode: 272   score: 2.0   memory length: 49819   epsilon: 1.0    steps: 183     evaluation reward: 1.36\n",
      "now time :  2018-12-19 01:36:13.067584\n",
      "episode: 273   score: 1.0   memory length: 50001   epsilon: 1.0    steps: 182     evaluation reward: 1.36\n",
      "episode: 274   score: 4.0   memory length: 50274   epsilon: 1.0    steps: 273     evaluation reward: 1.4\n",
      "episode: 275   score: 1.0   memory length: 50461   epsilon: 1.0    steps: 187     evaluation reward: 1.39\n",
      "episode: 276   score: 3.0   memory length: 50737   epsilon: 1.0    steps: 276     evaluation reward: 1.4\n",
      "episode: 277   score: 1.0   memory length: 50909   epsilon: 1.0    steps: 172     evaluation reward: 1.38\n",
      "episode: 278   score: 2.0   memory length: 51100   epsilon: 1.0    steps: 191     evaluation reward: 1.4\n",
      "episode: 279   score: 1.0   memory length: 51257   epsilon: 1.0    steps: 157     evaluation reward: 1.4\n",
      "episode: 280   score: 2.0   memory length: 51470   epsilon: 1.0    steps: 213     evaluation reward: 1.42\n",
      "episode: 281   score: 0.0   memory length: 51600   epsilon: 1.0    steps: 130     evaluation reward: 1.41\n",
      "episode: 282   score: 2.0   memory length: 51806   epsilon: 1.0    steps: 206     evaluation reward: 1.41\n",
      "episode: 283   score: 0.0   memory length: 51935   epsilon: 1.0    steps: 129     evaluation reward: 1.41\n",
      "episode: 284   score: 2.0   memory length: 52146   epsilon: 1.0    steps: 211     evaluation reward: 1.41\n",
      "episode: 285   score: 0.0   memory length: 52277   epsilon: 1.0    steps: 131     evaluation reward: 1.38\n",
      "episode: 286   score: 4.0   memory length: 52556   epsilon: 1.0    steps: 279     evaluation reward: 1.42\n",
      "episode: 287   score: 1.0   memory length: 52711   epsilon: 1.0    steps: 155     evaluation reward: 1.43\n",
      "episode: 288   score: 0.0   memory length: 52835   epsilon: 1.0    steps: 124     evaluation reward: 1.43\n",
      "episode: 289   score: 1.0   memory length: 52994   epsilon: 1.0    steps: 159     evaluation reward: 1.41\n",
      "episode: 290   score: 0.0   memory length: 53130   epsilon: 1.0    steps: 136     evaluation reward: 1.4\n",
      "episode: 291   score: 1.0   memory length: 53283   epsilon: 1.0    steps: 153     evaluation reward: 1.41\n",
      "episode: 292   score: 1.0   memory length: 53454   epsilon: 1.0    steps: 171     evaluation reward: 1.4\n",
      "episode: 293   score: 0.0   memory length: 53604   epsilon: 1.0    steps: 150     evaluation reward: 1.39\n",
      "episode: 294   score: 1.0   memory length: 53778   epsilon: 1.0    steps: 174     evaluation reward: 1.37\n",
      "episode: 295   score: 0.0   memory length: 53903   epsilon: 1.0    steps: 125     evaluation reward: 1.36\n",
      "episode: 296   score: 6.0   memory length: 54240   epsilon: 1.0    steps: 337     evaluation reward: 1.39\n",
      "episode: 297   score: 1.0   memory length: 54418   epsilon: 1.0    steps: 178     evaluation reward: 1.37\n",
      "episode: 298   score: 2.0   memory length: 54626   epsilon: 1.0    steps: 208     evaluation reward: 1.37\n",
      "episode: 299   score: 1.0   memory length: 54786   epsilon: 1.0    steps: 160     evaluation reward: 1.34\n",
      "episode: 300   score: 3.0   memory length: 55072   epsilon: 1.0    steps: 286     evaluation reward: 1.34\n",
      "episode: 301   score: 1.0   memory length: 55233   epsilon: 1.0    steps: 161     evaluation reward: 1.34\n",
      "episode: 302   score: 4.0   memory length: 55532   epsilon: 1.0    steps: 299     evaluation reward: 1.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 303   score: 0.0   memory length: 55671   epsilon: 1.0    steps: 139     evaluation reward: 1.36\n",
      "episode: 304   score: 0.0   memory length: 55803   epsilon: 1.0    steps: 132     evaluation reward: 1.35\n",
      "episode: 305   score: 2.0   memory length: 56026   epsilon: 1.0    steps: 223     evaluation reward: 1.36\n",
      "episode: 306   score: 2.0   memory length: 56224   epsilon: 1.0    steps: 198     evaluation reward: 1.34\n",
      "episode: 307   score: 3.0   memory length: 56460   epsilon: 1.0    steps: 236     evaluation reward: 1.37\n",
      "episode: 308   score: 1.0   memory length: 56646   epsilon: 1.0    steps: 186     evaluation reward: 1.38\n",
      "episode: 309   score: 3.0   memory length: 56899   epsilon: 1.0    steps: 253     evaluation reward: 1.41\n",
      "episode: 310   score: 1.0   memory length: 57102   epsilon: 1.0    steps: 203     evaluation reward: 1.41\n",
      "episode: 311   score: 1.0   memory length: 57283   epsilon: 1.0    steps: 181     evaluation reward: 1.42\n",
      "episode: 312   score: 0.0   memory length: 57413   epsilon: 1.0    steps: 130     evaluation reward: 1.4\n",
      "episode: 313   score: 0.0   memory length: 57542   epsilon: 1.0    steps: 129     evaluation reward: 1.4\n",
      "episode: 314   score: 1.0   memory length: 57698   epsilon: 1.0    steps: 156     evaluation reward: 1.41\n",
      "episode: 315   score: 0.0   memory length: 57825   epsilon: 1.0    steps: 127     evaluation reward: 1.39\n",
      "episode: 316   score: 0.0   memory length: 57955   epsilon: 1.0    steps: 130     evaluation reward: 1.36\n",
      "episode: 317   score: 0.0   memory length: 58082   epsilon: 1.0    steps: 127     evaluation reward: 1.35\n",
      "episode: 318   score: 1.0   memory length: 58249   epsilon: 1.0    steps: 167     evaluation reward: 1.36\n",
      "episode: 319   score: 0.0   memory length: 58387   epsilon: 1.0    steps: 138     evaluation reward: 1.36\n",
      "episode: 320   score: 3.0   memory length: 58652   epsilon: 1.0    steps: 265     evaluation reward: 1.39\n",
      "episode: 321   score: 0.0   memory length: 58779   epsilon: 1.0    steps: 127     evaluation reward: 1.39\n",
      "episode: 322   score: 0.0   memory length: 58907   epsilon: 1.0    steps: 128     evaluation reward: 1.35\n",
      "episode: 323   score: 0.0   memory length: 59037   epsilon: 1.0    steps: 130     evaluation reward: 1.34\n",
      "episode: 324   score: 3.0   memory length: 59278   epsilon: 1.0    steps: 241     evaluation reward: 1.36\n",
      "episode: 325   score: 0.0   memory length: 59403   epsilon: 1.0    steps: 125     evaluation reward: 1.34\n",
      "episode: 326   score: 3.0   memory length: 59638   epsilon: 1.0    steps: 235     evaluation reward: 1.37\n",
      "episode: 327   score: 0.0   memory length: 59771   epsilon: 1.0    steps: 133     evaluation reward: 1.34\n",
      "episode: 328   score: 2.0   memory length: 59984   epsilon: 1.0    steps: 213     evaluation reward: 1.34\n",
      "episode: 329   score: 0.0   memory length: 60116   epsilon: 1.0    steps: 132     evaluation reward: 1.34\n",
      "episode: 330   score: 0.0   memory length: 60252   epsilon: 1.0    steps: 136     evaluation reward: 1.34\n",
      "episode: 331   score: 4.0   memory length: 60556   epsilon: 1.0    steps: 304     evaluation reward: 1.37\n",
      "episode: 332   score: 1.0   memory length: 60707   epsilon: 1.0    steps: 151     evaluation reward: 1.35\n",
      "episode: 333   score: 0.0   memory length: 60844   epsilon: 1.0    steps: 137     evaluation reward: 1.33\n",
      "episode: 334   score: 2.0   memory length: 61051   epsilon: 1.0    steps: 207     evaluation reward: 1.35\n",
      "episode: 335   score: 1.0   memory length: 61204   epsilon: 1.0    steps: 153     evaluation reward: 1.34\n",
      "episode: 336   score: 2.0   memory length: 61429   epsilon: 1.0    steps: 225     evaluation reward: 1.34\n",
      "episode: 337   score: 1.0   memory length: 61604   epsilon: 1.0    steps: 175     evaluation reward: 1.35\n",
      "episode: 338   score: 5.0   memory length: 61917   epsilon: 1.0    steps: 313     evaluation reward: 1.37\n",
      "episode: 339   score: 1.0   memory length: 62099   epsilon: 1.0    steps: 182     evaluation reward: 1.31\n",
      "episode: 340   score: 0.0   memory length: 62230   epsilon: 1.0    steps: 131     evaluation reward: 1.31\n",
      "episode: 341   score: 1.0   memory length: 62387   epsilon: 1.0    steps: 157     evaluation reward: 1.28\n",
      "episode: 342   score: 1.0   memory length: 62549   epsilon: 1.0    steps: 162     evaluation reward: 1.25\n",
      "episode: 343   score: 2.0   memory length: 62759   epsilon: 1.0    steps: 210     evaluation reward: 1.27\n",
      "episode: 344   score: 0.0   memory length: 62891   epsilon: 1.0    steps: 132     evaluation reward: 1.26\n",
      "episode: 345   score: 2.0   memory length: 63095   epsilon: 1.0    steps: 204     evaluation reward: 1.28\n",
      "episode: 346   score: 0.0   memory length: 63223   epsilon: 1.0    steps: 128     evaluation reward: 1.28\n",
      "episode: 347   score: 0.0   memory length: 63354   epsilon: 1.0    steps: 131     evaluation reward: 1.27\n",
      "episode: 348   score: 2.0   memory length: 63550   epsilon: 1.0    steps: 196     evaluation reward: 1.29\n",
      "episode: 349   score: 2.0   memory length: 63756   epsilon: 1.0    steps: 206     evaluation reward: 1.29\n",
      "episode: 350   score: 0.0   memory length: 63883   epsilon: 1.0    steps: 127     evaluation reward: 1.28\n",
      "episode: 351   score: 0.0   memory length: 64018   epsilon: 1.0    steps: 135     evaluation reward: 1.26\n",
      "episode: 352   score: 1.0   memory length: 64200   epsilon: 1.0    steps: 182     evaluation reward: 1.25\n",
      "episode: 353   score: 1.0   memory length: 64362   epsilon: 1.0    steps: 162     evaluation reward: 1.25\n",
      "episode: 354   score: 2.0   memory length: 64585   epsilon: 1.0    steps: 223     evaluation reward: 1.26\n",
      "episode: 355   score: 1.0   memory length: 64745   epsilon: 1.0    steps: 160     evaluation reward: 1.25\n",
      "episode: 356   score: 1.0   memory length: 64920   epsilon: 1.0    steps: 175     evaluation reward: 1.25\n",
      "episode: 357   score: 1.0   memory length: 65097   epsilon: 1.0    steps: 177     evaluation reward: 1.24\n",
      "episode: 358   score: 1.0   memory length: 65251   epsilon: 1.0    steps: 154     evaluation reward: 1.23\n",
      "episode: 359   score: 1.0   memory length: 65438   epsilon: 1.0    steps: 187     evaluation reward: 1.21\n",
      "episode: 360   score: 0.0   memory length: 65570   epsilon: 1.0    steps: 132     evaluation reward: 1.2\n",
      "episode: 361   score: 0.0   memory length: 65703   epsilon: 1.0    steps: 133     evaluation reward: 1.19\n",
      "episode: 362   score: 2.0   memory length: 65908   epsilon: 1.0    steps: 205     evaluation reward: 1.21\n",
      "episode: 363   score: 0.0   memory length: 66036   epsilon: 1.0    steps: 128     evaluation reward: 1.19\n",
      "episode: 364   score: 2.0   memory length: 66262   epsilon: 1.0    steps: 226     evaluation reward: 1.2\n",
      "episode: 365   score: 4.0   memory length: 66544   epsilon: 1.0    steps: 282     evaluation reward: 1.24\n",
      "episode: 366   score: 2.0   memory length: 66733   epsilon: 1.0    steps: 189     evaluation reward: 1.25\n",
      "episode: 367   score: 0.0   memory length: 66870   epsilon: 1.0    steps: 137     evaluation reward: 1.23\n",
      "episode: 368   score: 0.0   memory length: 66999   epsilon: 1.0    steps: 129     evaluation reward: 1.23\n",
      "episode: 369   score: 0.0   memory length: 67127   epsilon: 1.0    steps: 128     evaluation reward: 1.21\n",
      "episode: 370   score: 2.0   memory length: 67344   epsilon: 1.0    steps: 217     evaluation reward: 1.22\n",
      "episode: 371   score: 0.0   memory length: 67477   epsilon: 1.0    steps: 133     evaluation reward: 1.22\n",
      "episode: 372   score: 2.0   memory length: 67707   epsilon: 1.0    steps: 230     evaluation reward: 1.22\n",
      "episode: 373   score: 0.0   memory length: 67840   epsilon: 1.0    steps: 133     evaluation reward: 1.21\n",
      "episode: 374   score: 1.0   memory length: 67997   epsilon: 1.0    steps: 157     evaluation reward: 1.18\n",
      "episode: 375   score: 1.0   memory length: 68175   epsilon: 1.0    steps: 178     evaluation reward: 1.18\n",
      "episode: 376   score: 0.0   memory length: 68308   epsilon: 1.0    steps: 133     evaluation reward: 1.15\n",
      "episode: 377   score: 7.0   memory length: 68631   epsilon: 1.0    steps: 323     evaluation reward: 1.21\n",
      "episode: 378   score: 2.0   memory length: 68849   epsilon: 1.0    steps: 218     evaluation reward: 1.21\n",
      "episode: 379   score: 3.0   memory length: 69102   epsilon: 1.0    steps: 253     evaluation reward: 1.23\n",
      "episode: 380   score: 3.0   memory length: 69352   epsilon: 1.0    steps: 250     evaluation reward: 1.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 381   score: 2.0   memory length: 69556   epsilon: 1.0    steps: 204     evaluation reward: 1.26\n",
      "episode: 382   score: 1.0   memory length: 69720   epsilon: 1.0    steps: 164     evaluation reward: 1.25\n",
      "episode: 383   score: 3.0   memory length: 69947   epsilon: 1.0    steps: 227     evaluation reward: 1.28\n",
      "episode: 384   score: 1.0   memory length: 70128   epsilon: 1.0    steps: 181     evaluation reward: 1.27\n",
      "episode: 385   score: 0.0   memory length: 70255   epsilon: 1.0    steps: 127     evaluation reward: 1.27\n",
      "episode: 386   score: 0.0   memory length: 70381   epsilon: 1.0    steps: 126     evaluation reward: 1.23\n",
      "episode: 387   score: 2.0   memory length: 70578   epsilon: 1.0    steps: 197     evaluation reward: 1.24\n",
      "episode: 388   score: 1.0   memory length: 70754   epsilon: 1.0    steps: 176     evaluation reward: 1.25\n",
      "episode: 389   score: 0.0   memory length: 70893   epsilon: 1.0    steps: 139     evaluation reward: 1.24\n",
      "episode: 390   score: 2.0   memory length: 71107   epsilon: 1.0    steps: 214     evaluation reward: 1.26\n",
      "episode: 391   score: 2.0   memory length: 71326   epsilon: 1.0    steps: 219     evaluation reward: 1.27\n",
      "episode: 392   score: 1.0   memory length: 71482   epsilon: 1.0    steps: 156     evaluation reward: 1.27\n",
      "episode: 393   score: 3.0   memory length: 71758   epsilon: 1.0    steps: 276     evaluation reward: 1.3\n",
      "episode: 394   score: 1.0   memory length: 71943   epsilon: 1.0    steps: 185     evaluation reward: 1.3\n",
      "episode: 395   score: 2.0   memory length: 72146   epsilon: 1.0    steps: 203     evaluation reward: 1.32\n",
      "episode: 396   score: 1.0   memory length: 72300   epsilon: 1.0    steps: 154     evaluation reward: 1.27\n",
      "episode: 397   score: 2.0   memory length: 72510   epsilon: 1.0    steps: 210     evaluation reward: 1.28\n",
      "episode: 398   score: 1.0   memory length: 72679   epsilon: 1.0    steps: 169     evaluation reward: 1.27\n",
      "episode: 399   score: 0.0   memory length: 72806   epsilon: 1.0    steps: 127     evaluation reward: 1.26\n",
      "episode: 400   score: 0.0   memory length: 72944   epsilon: 1.0    steps: 138     evaluation reward: 1.23\n",
      "episode: 401   score: 2.0   memory length: 73151   epsilon: 1.0    steps: 207     evaluation reward: 1.24\n",
      "episode: 402   score: 0.0   memory length: 73291   epsilon: 1.0    steps: 140     evaluation reward: 1.2\n",
      "episode: 403   score: 2.0   memory length: 73499   epsilon: 1.0    steps: 208     evaluation reward: 1.22\n",
      "episode: 404   score: 2.0   memory length: 73683   epsilon: 1.0    steps: 184     evaluation reward: 1.24\n",
      "episode: 405   score: 2.0   memory length: 73889   epsilon: 1.0    steps: 206     evaluation reward: 1.24\n",
      "episode: 406   score: 0.0   memory length: 74026   epsilon: 1.0    steps: 137     evaluation reward: 1.22\n",
      "episode: 407   score: 0.0   memory length: 74151   epsilon: 1.0    steps: 125     evaluation reward: 1.19\n",
      "episode: 408   score: 3.0   memory length: 74388   epsilon: 1.0    steps: 237     evaluation reward: 1.21\n",
      "episode: 409   score: 3.0   memory length: 74642   epsilon: 1.0    steps: 254     evaluation reward: 1.21\n",
      "episode: 410   score: 0.0   memory length: 74778   epsilon: 1.0    steps: 136     evaluation reward: 1.2\n",
      "episode: 411   score: 2.0   memory length: 74990   epsilon: 1.0    steps: 212     evaluation reward: 1.21\n",
      "episode: 412   score: 0.0   memory length: 75122   epsilon: 1.0    steps: 132     evaluation reward: 1.21\n",
      "episode: 413   score: 2.0   memory length: 75338   epsilon: 1.0    steps: 216     evaluation reward: 1.23\n",
      "episode: 414   score: 2.0   memory length: 75548   epsilon: 1.0    steps: 210     evaluation reward: 1.24\n",
      "episode: 415   score: 1.0   memory length: 75732   epsilon: 1.0    steps: 184     evaluation reward: 1.25\n",
      "episode: 416   score: 3.0   memory length: 75965   epsilon: 1.0    steps: 233     evaluation reward: 1.28\n",
      "episode: 417   score: 0.0   memory length: 76100   epsilon: 1.0    steps: 135     evaluation reward: 1.28\n",
      "episode: 418   score: 1.0   memory length: 76262   epsilon: 1.0    steps: 162     evaluation reward: 1.28\n",
      "episode: 419   score: 1.0   memory length: 76414   epsilon: 1.0    steps: 152     evaluation reward: 1.29\n",
      "episode: 420   score: 4.0   memory length: 76740   epsilon: 1.0    steps: 326     evaluation reward: 1.3\n",
      "episode: 421   score: 0.0   memory length: 76879   epsilon: 1.0    steps: 139     evaluation reward: 1.3\n",
      "episode: 422   score: 0.0   memory length: 77019   epsilon: 1.0    steps: 140     evaluation reward: 1.3\n",
      "episode: 423   score: 1.0   memory length: 77225   epsilon: 1.0    steps: 206     evaluation reward: 1.31\n",
      "episode: 424   score: 0.0   memory length: 77359   epsilon: 1.0    steps: 134     evaluation reward: 1.28\n",
      "episode: 425   score: 0.0   memory length: 77502   epsilon: 1.0    steps: 143     evaluation reward: 1.28\n",
      "episode: 426   score: 2.0   memory length: 77700   epsilon: 1.0    steps: 198     evaluation reward: 1.27\n",
      "episode: 427   score: 1.0   memory length: 77859   epsilon: 1.0    steps: 159     evaluation reward: 1.28\n",
      "episode: 428   score: 1.0   memory length: 78022   epsilon: 1.0    steps: 163     evaluation reward: 1.27\n",
      "episode: 429   score: 2.0   memory length: 78237   epsilon: 1.0    steps: 215     evaluation reward: 1.29\n",
      "episode: 430   score: 3.0   memory length: 78518   epsilon: 1.0    steps: 281     evaluation reward: 1.32\n",
      "episode: 431   score: 2.0   memory length: 78743   epsilon: 1.0    steps: 225     evaluation reward: 1.3\n",
      "episode: 432   score: 1.0   memory length: 78928   epsilon: 1.0    steps: 185     evaluation reward: 1.3\n",
      "episode: 433   score: 1.0   memory length: 79097   epsilon: 1.0    steps: 169     evaluation reward: 1.31\n",
      "episode: 434   score: 3.0   memory length: 79347   epsilon: 1.0    steps: 250     evaluation reward: 1.32\n",
      "episode: 435   score: 0.0   memory length: 79475   epsilon: 1.0    steps: 128     evaluation reward: 1.31\n",
      "episode: 436   score: 1.0   memory length: 79634   epsilon: 1.0    steps: 159     evaluation reward: 1.3\n",
      "episode: 437   score: 2.0   memory length: 79844   epsilon: 1.0    steps: 210     evaluation reward: 1.31\n",
      "episode: 438   score: 0.0   memory length: 79973   epsilon: 1.0    steps: 129     evaluation reward: 1.26\n",
      "episode: 439   score: 0.0   memory length: 80107   epsilon: 1.0    steps: 134     evaluation reward: 1.25\n",
      "episode: 440   score: 0.0   memory length: 80240   epsilon: 1.0    steps: 133     evaluation reward: 1.25\n",
      "episode: 441   score: 0.0   memory length: 80371   epsilon: 1.0    steps: 131     evaluation reward: 1.24\n",
      "episode: 442   score: 2.0   memory length: 80583   epsilon: 1.0    steps: 212     evaluation reward: 1.25\n",
      "episode: 443   score: 3.0   memory length: 80801   epsilon: 1.0    steps: 218     evaluation reward: 1.26\n",
      "episode: 444   score: 1.0   memory length: 80977   epsilon: 1.0    steps: 176     evaluation reward: 1.27\n",
      "episode: 445   score: 2.0   memory length: 81180   epsilon: 1.0    steps: 203     evaluation reward: 1.27\n",
      "episode: 446   score: 0.0   memory length: 81315   epsilon: 1.0    steps: 135     evaluation reward: 1.27\n",
      "episode: 447   score: 2.0   memory length: 81521   epsilon: 1.0    steps: 206     evaluation reward: 1.29\n",
      "episode: 448   score: 1.0   memory length: 81690   epsilon: 1.0    steps: 169     evaluation reward: 1.28\n",
      "episode: 449   score: 2.0   memory length: 81885   epsilon: 1.0    steps: 195     evaluation reward: 1.28\n",
      "episode: 450   score: 1.0   memory length: 82045   epsilon: 1.0    steps: 160     evaluation reward: 1.29\n",
      "episode: 451   score: 0.0   memory length: 82173   epsilon: 1.0    steps: 128     evaluation reward: 1.29\n",
      "episode: 452   score: 0.0   memory length: 82320   epsilon: 1.0    steps: 147     evaluation reward: 1.28\n",
      "episode: 453   score: 0.0   memory length: 82453   epsilon: 1.0    steps: 133     evaluation reward: 1.27\n",
      "episode: 454   score: 4.0   memory length: 82717   epsilon: 1.0    steps: 264     evaluation reward: 1.29\n",
      "episode: 455   score: 0.0   memory length: 82841   epsilon: 1.0    steps: 124     evaluation reward: 1.28\n",
      "episode: 456   score: 2.0   memory length: 83049   epsilon: 1.0    steps: 208     evaluation reward: 1.29\n",
      "episode: 457   score: 0.0   memory length: 83176   epsilon: 1.0    steps: 127     evaluation reward: 1.28\n",
      "episode: 458   score: 0.0   memory length: 83302   epsilon: 1.0    steps: 126     evaluation reward: 1.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 459   score: 1.0   memory length: 83464   epsilon: 1.0    steps: 162     evaluation reward: 1.27\n",
      "episode: 460   score: 2.0   memory length: 83674   epsilon: 1.0    steps: 210     evaluation reward: 1.29\n",
      "episode: 461   score: 0.0   memory length: 83804   epsilon: 1.0    steps: 130     evaluation reward: 1.29\n",
      "episode: 462   score: 2.0   memory length: 84020   epsilon: 1.0    steps: 216     evaluation reward: 1.29\n",
      "episode: 463   score: 3.0   memory length: 84257   epsilon: 1.0    steps: 237     evaluation reward: 1.32\n",
      "episode: 464   score: 0.0   memory length: 84386   epsilon: 1.0    steps: 129     evaluation reward: 1.3\n",
      "episode: 465   score: 2.0   memory length: 84596   epsilon: 1.0    steps: 210     evaluation reward: 1.28\n",
      "episode: 466   score: 2.0   memory length: 84794   epsilon: 1.0    steps: 198     evaluation reward: 1.28\n",
      "episode: 467   score: 3.0   memory length: 85024   epsilon: 1.0    steps: 230     evaluation reward: 1.31\n",
      "episode: 468   score: 2.0   memory length: 85232   epsilon: 1.0    steps: 208     evaluation reward: 1.33\n",
      "episode: 469   score: 2.0   memory length: 85437   epsilon: 1.0    steps: 205     evaluation reward: 1.35\n",
      "episode: 470   score: 0.0   memory length: 85565   epsilon: 1.0    steps: 128     evaluation reward: 1.33\n",
      "episode: 471   score: 3.0   memory length: 85796   epsilon: 1.0    steps: 231     evaluation reward: 1.36\n",
      "episode: 472   score: 0.0   memory length: 85927   epsilon: 1.0    steps: 131     evaluation reward: 1.34\n",
      "episode: 473   score: 1.0   memory length: 86104   epsilon: 1.0    steps: 177     evaluation reward: 1.35\n",
      "episode: 474   score: 4.0   memory length: 86389   epsilon: 1.0    steps: 285     evaluation reward: 1.38\n",
      "episode: 475   score: 2.0   memory length: 86578   epsilon: 1.0    steps: 189     evaluation reward: 1.39\n",
      "episode: 476   score: 0.0   memory length: 86703   epsilon: 1.0    steps: 125     evaluation reward: 1.39\n",
      "episode: 477   score: 0.0   memory length: 86833   epsilon: 1.0    steps: 130     evaluation reward: 1.32\n",
      "episode: 478   score: 1.0   memory length: 87010   epsilon: 1.0    steps: 177     evaluation reward: 1.31\n",
      "episode: 479   score: 1.0   memory length: 87185   epsilon: 1.0    steps: 175     evaluation reward: 1.29\n",
      "episode: 480   score: 2.0   memory length: 87392   epsilon: 1.0    steps: 207     evaluation reward: 1.28\n",
      "episode: 481   score: 1.0   memory length: 87565   epsilon: 1.0    steps: 173     evaluation reward: 1.27\n",
      "episode: 482   score: 2.0   memory length: 87782   epsilon: 1.0    steps: 217     evaluation reward: 1.28\n",
      "episode: 483   score: 0.0   memory length: 87906   epsilon: 1.0    steps: 124     evaluation reward: 1.25\n",
      "episode: 484   score: 0.0   memory length: 88037   epsilon: 1.0    steps: 131     evaluation reward: 1.24\n",
      "episode: 485   score: 2.0   memory length: 88223   epsilon: 1.0    steps: 186     evaluation reward: 1.26\n",
      "episode: 486   score: 0.0   memory length: 88358   epsilon: 1.0    steps: 135     evaluation reward: 1.26\n",
      "episode: 487   score: 0.0   memory length: 88493   epsilon: 1.0    steps: 135     evaluation reward: 1.24\n",
      "episode: 488   score: 2.0   memory length: 88695   epsilon: 1.0    steps: 202     evaluation reward: 1.25\n",
      "episode: 489   score: 2.0   memory length: 88905   epsilon: 1.0    steps: 210     evaluation reward: 1.27\n",
      "episode: 490   score: 3.0   memory length: 89178   epsilon: 1.0    steps: 273     evaluation reward: 1.28\n",
      "episode: 491   score: 0.0   memory length: 89303   epsilon: 1.0    steps: 125     evaluation reward: 1.26\n",
      "episode: 492   score: 3.0   memory length: 89567   epsilon: 1.0    steps: 264     evaluation reward: 1.28\n",
      "episode: 493   score: 1.0   memory length: 89725   epsilon: 1.0    steps: 158     evaluation reward: 1.26\n",
      "episode: 494   score: 3.0   memory length: 89968   epsilon: 1.0    steps: 243     evaluation reward: 1.28\n",
      "episode: 495   score: 0.0   memory length: 90101   epsilon: 1.0    steps: 133     evaluation reward: 1.26\n",
      "episode: 496   score: 1.0   memory length: 90255   epsilon: 1.0    steps: 154     evaluation reward: 1.26\n",
      "episode: 497   score: 1.0   memory length: 90435   epsilon: 1.0    steps: 180     evaluation reward: 1.25\n",
      "episode: 498   score: 0.0   memory length: 90569   epsilon: 1.0    steps: 134     evaluation reward: 1.24\n",
      "episode: 499   score: 2.0   memory length: 90787   epsilon: 1.0    steps: 218     evaluation reward: 1.26\n",
      "episode: 500   score: 2.0   memory length: 90991   epsilon: 1.0    steps: 204     evaluation reward: 1.28\n",
      "episode: 501   score: 1.0   memory length: 91154   epsilon: 1.0    steps: 163     evaluation reward: 1.27\n",
      "episode: 502   score: 0.0   memory length: 91284   epsilon: 1.0    steps: 130     evaluation reward: 1.27\n",
      "episode: 503   score: 2.0   memory length: 91484   epsilon: 1.0    steps: 200     evaluation reward: 1.27\n",
      "episode: 504   score: 1.0   memory length: 91635   epsilon: 1.0    steps: 151     evaluation reward: 1.26\n",
      "episode: 505   score: 0.0   memory length: 91771   epsilon: 1.0    steps: 136     evaluation reward: 1.24\n",
      "episode: 506   score: 2.0   memory length: 92000   epsilon: 1.0    steps: 229     evaluation reward: 1.26\n",
      "episode: 507   score: 0.0   memory length: 92133   epsilon: 1.0    steps: 133     evaluation reward: 1.26\n",
      "episode: 508   score: 1.0   memory length: 92288   epsilon: 1.0    steps: 155     evaluation reward: 1.24\n",
      "episode: 509   score: 1.0   memory length: 92463   epsilon: 1.0    steps: 175     evaluation reward: 1.22\n",
      "episode: 510   score: 1.0   memory length: 92643   epsilon: 1.0    steps: 180     evaluation reward: 1.23\n",
      "episode: 511   score: 0.0   memory length: 92789   epsilon: 1.0    steps: 146     evaluation reward: 1.21\n",
      "episode: 512   score: 2.0   memory length: 92994   epsilon: 1.0    steps: 205     evaluation reward: 1.23\n",
      "episode: 513   score: 3.0   memory length: 93223   epsilon: 1.0    steps: 229     evaluation reward: 1.24\n",
      "episode: 514   score: 0.0   memory length: 93350   epsilon: 1.0    steps: 127     evaluation reward: 1.22\n",
      "episode: 515   score: 1.0   memory length: 93525   epsilon: 1.0    steps: 175     evaluation reward: 1.22\n",
      "episode: 516   score: 2.0   memory length: 93725   epsilon: 1.0    steps: 200     evaluation reward: 1.21\n",
      "episode: 517   score: 0.0   memory length: 93849   epsilon: 1.0    steps: 124     evaluation reward: 1.21\n",
      "episode: 518   score: 1.0   memory length: 94007   epsilon: 1.0    steps: 158     evaluation reward: 1.21\n",
      "episode: 519   score: 0.0   memory length: 94131   epsilon: 1.0    steps: 124     evaluation reward: 1.2\n",
      "episode: 520   score: 2.0   memory length: 94336   epsilon: 1.0    steps: 205     evaluation reward: 1.18\n",
      "episode: 521   score: 1.0   memory length: 94514   epsilon: 1.0    steps: 178     evaluation reward: 1.19\n",
      "episode: 522   score: 0.0   memory length: 94647   epsilon: 1.0    steps: 133     evaluation reward: 1.19\n",
      "episode: 523   score: 0.0   memory length: 94777   epsilon: 1.0    steps: 130     evaluation reward: 1.18\n",
      "episode: 524   score: 1.0   memory length: 94943   epsilon: 1.0    steps: 166     evaluation reward: 1.19\n",
      "episode: 525   score: 0.0   memory length: 95081   epsilon: 1.0    steps: 138     evaluation reward: 1.19\n",
      "episode: 526   score: 1.0   memory length: 95263   epsilon: 1.0    steps: 182     evaluation reward: 1.18\n",
      "episode: 527   score: 2.0   memory length: 95467   epsilon: 1.0    steps: 204     evaluation reward: 1.19\n",
      "episode: 528   score: 0.0   memory length: 95599   epsilon: 1.0    steps: 132     evaluation reward: 1.18\n",
      "episode: 529   score: 4.0   memory length: 95919   epsilon: 1.0    steps: 320     evaluation reward: 1.2\n",
      "episode: 530   score: 3.0   memory length: 96175   epsilon: 1.0    steps: 256     evaluation reward: 1.2\n",
      "episode: 531   score: 2.0   memory length: 96400   epsilon: 1.0    steps: 225     evaluation reward: 1.2\n",
      "episode: 532   score: 2.0   memory length: 96606   epsilon: 1.0    steps: 206     evaluation reward: 1.21\n",
      "episode: 533   score: 0.0   memory length: 96739   epsilon: 1.0    steps: 133     evaluation reward: 1.2\n",
      "episode: 534   score: 2.0   memory length: 96958   epsilon: 1.0    steps: 219     evaluation reward: 1.19\n",
      "episode: 535   score: 0.0   memory length: 97087   epsilon: 1.0    steps: 129     evaluation reward: 1.19\n",
      "episode: 536   score: 2.0   memory length: 97285   epsilon: 1.0    steps: 198     evaluation reward: 1.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 537   score: 0.0   memory length: 97411   epsilon: 1.0    steps: 126     evaluation reward: 1.18\n",
      "episode: 538   score: 2.0   memory length: 97637   epsilon: 1.0    steps: 226     evaluation reward: 1.2\n",
      "episode: 539   score: 0.0   memory length: 97763   epsilon: 1.0    steps: 126     evaluation reward: 1.2\n",
      "episode: 540   score: 0.0   memory length: 97887   epsilon: 1.0    steps: 124     evaluation reward: 1.2\n",
      "episode: 541   score: 1.0   memory length: 98069   epsilon: 1.0    steps: 182     evaluation reward: 1.21\n",
      "episode: 542   score: 3.0   memory length: 98328   epsilon: 1.0    steps: 259     evaluation reward: 1.22\n",
      "episode: 543   score: 2.0   memory length: 98521   epsilon: 1.0    steps: 193     evaluation reward: 1.21\n",
      "episode: 544   score: 1.0   memory length: 98678   epsilon: 1.0    steps: 157     evaluation reward: 1.21\n",
      "episode: 545   score: 1.0   memory length: 98853   epsilon: 1.0    steps: 175     evaluation reward: 1.2\n",
      "episode: 546   score: 1.0   memory length: 99028   epsilon: 1.0    steps: 175     evaluation reward: 1.21\n",
      "episode: 547   score: 2.0   memory length: 99231   epsilon: 1.0    steps: 203     evaluation reward: 1.21\n",
      "episode: 548   score: 5.0   memory length: 99562   epsilon: 1.0    steps: 331     evaluation reward: 1.25\n",
      "episode: 549   score: 0.0   memory length: 99688   epsilon: 1.0    steps: 126     evaluation reward: 1.23\n",
      "episode: 550   score: 0.0   memory length: 99816   epsilon: 1.0    steps: 128     evaluation reward: 1.22\n",
      "episode: 551   score: 1.0   memory length: 99976   epsilon: 1.0    steps: 160     evaluation reward: 1.23\n",
      "now time :  2018-12-19 01:39:17.450916\n",
      "episode: 552   score: 2.0   memory length: 100186   epsilon: 0.999814870000004    steps: 210     evaluation reward: 1.25\n",
      "episode: 553   score: 2.0   memory length: 100372   epsilon: 0.999630730000008    steps: 186     evaluation reward: 1.27\n",
      "episode: 554   score: 2.0   memory length: 100580   epsilon: 0.9994248100000125    steps: 208     evaluation reward: 1.25\n",
      "episode: 555   score: 4.0   memory length: 100899   epsilon: 0.9991090000000193    steps: 319     evaluation reward: 1.29\n",
      "episode: 556   score: 0.0   memory length: 101026   epsilon: 0.9989832700000221    steps: 127     evaluation reward: 1.27\n",
      "episode: 557   score: 2.0   memory length: 101255   epsilon: 0.998756560000027    steps: 229     evaluation reward: 1.29\n",
      "episode: 558   score: 1.0   memory length: 101428   epsilon: 0.9985852900000307    steps: 173     evaluation reward: 1.3\n",
      "episode: 559   score: 0.0   memory length: 101572   epsilon: 0.9984427300000338    steps: 144     evaluation reward: 1.29\n",
      "episode: 560   score: 1.0   memory length: 101738   epsilon: 0.9982783900000374    steps: 166     evaluation reward: 1.28\n",
      "episode: 561   score: 5.0   memory length: 102028   epsilon: 0.9979912900000436    steps: 290     evaluation reward: 1.33\n",
      "episode: 562   score: 0.0   memory length: 102158   epsilon: 0.9978625900000464    steps: 130     evaluation reward: 1.31\n",
      "episode: 563   score: 2.0   memory length: 102384   epsilon: 0.9976388500000513    steps: 226     evaluation reward: 1.3\n",
      "episode: 564   score: 1.0   memory length: 102561   epsilon: 0.9974636200000551    steps: 177     evaluation reward: 1.31\n",
      "episode: 565   score: 3.0   memory length: 102816   epsilon: 0.9972111700000605    steps: 255     evaluation reward: 1.32\n",
      "episode: 566   score: 3.0   memory length: 103045   epsilon: 0.9969844600000655    steps: 229     evaluation reward: 1.33\n",
      "episode: 567   score: 1.0   memory length: 103204   epsilon: 0.9968270500000689    steps: 159     evaluation reward: 1.31\n",
      "episode: 568   score: 0.0   memory length: 103331   epsilon: 0.9967013200000716    steps: 127     evaluation reward: 1.29\n",
      "episode: 569   score: 0.0   memory length: 103457   epsilon: 0.9965765800000743    steps: 126     evaluation reward: 1.27\n",
      "episode: 570   score: 4.0   memory length: 103747   epsilon: 0.9962894800000806    steps: 290     evaluation reward: 1.31\n",
      "episode: 571   score: 0.0   memory length: 103872   epsilon: 0.9961657300000832    steps: 125     evaluation reward: 1.28\n",
      "episode: 572   score: 0.0   memory length: 103994   epsilon: 0.9960449500000859    steps: 122     evaluation reward: 1.28\n",
      "episode: 573   score: 2.0   memory length: 104210   epsilon: 0.9958311100000905    steps: 216     evaluation reward: 1.29\n",
      "episode: 574   score: 1.0   memory length: 104383   epsilon: 0.9956598400000942    steps: 173     evaluation reward: 1.26\n",
      "episode: 575   score: 1.0   memory length: 104555   epsilon: 0.9954895600000979    steps: 172     evaluation reward: 1.25\n",
      "episode: 576   score: 0.0   memory length: 104687   epsilon: 0.9953588800001008    steps: 132     evaluation reward: 1.25\n",
      "episode: 577   score: 1.0   memory length: 104845   epsilon: 0.9952024600001041    steps: 158     evaluation reward: 1.26\n",
      "episode: 578   score: 1.0   memory length: 105022   epsilon: 0.995027230000108    steps: 177     evaluation reward: 1.26\n",
      "episode: 579   score: 1.0   memory length: 105178   epsilon: 0.9948727900001113    steps: 156     evaluation reward: 1.26\n",
      "episode: 580   score: 3.0   memory length: 105445   epsilon: 0.994608460000117    steps: 267     evaluation reward: 1.27\n",
      "episode: 581   score: 3.0   memory length: 105711   epsilon: 0.9943451200001228    steps: 266     evaluation reward: 1.29\n",
      "episode: 582   score: 1.0   memory length: 105891   epsilon: 0.9941669200001266    steps: 180     evaluation reward: 1.28\n",
      "episode: 583   score: 0.0   memory length: 106020   epsilon: 0.9940392100001294    steps: 129     evaluation reward: 1.28\n",
      "episode: 584   score: 0.0   memory length: 106161   epsilon: 0.9938996200001324    steps: 141     evaluation reward: 1.28\n",
      "episode: 585   score: 1.0   memory length: 106342   epsilon: 0.9937204300001363    steps: 181     evaluation reward: 1.27\n",
      "episode: 586   score: 0.0   memory length: 106467   epsilon: 0.993596680000139    steps: 125     evaluation reward: 1.27\n",
      "episode: 587   score: 2.0   memory length: 106682   epsilon: 0.9933838300001436    steps: 215     evaluation reward: 1.29\n",
      "episode: 588   score: 0.0   memory length: 106816   epsilon: 0.9932511700001465    steps: 134     evaluation reward: 1.27\n",
      "episode: 589   score: 3.0   memory length: 107073   epsilon: 0.992996740000152    steps: 257     evaluation reward: 1.28\n",
      "episode: 590   score: 0.0   memory length: 107209   epsilon: 0.992862100000155    steps: 136     evaluation reward: 1.25\n",
      "episode: 591   score: 1.0   memory length: 107365   epsilon: 0.9927076600001583    steps: 156     evaluation reward: 1.26\n",
      "episode: 592   score: 0.0   memory length: 107498   epsilon: 0.9925759900001612    steps: 133     evaluation reward: 1.23\n",
      "episode: 593   score: 1.0   memory length: 107656   epsilon: 0.9924195700001646    steps: 158     evaluation reward: 1.23\n",
      "episode: 594   score: 1.0   memory length: 107813   epsilon: 0.9922641400001679    steps: 157     evaluation reward: 1.21\n",
      "episode: 595   score: 0.0   memory length: 107946   epsilon: 0.9921324700001708    steps: 133     evaluation reward: 1.21\n",
      "episode: 596   score: 1.0   memory length: 108124   epsilon: 0.9919562500001746    steps: 178     evaluation reward: 1.21\n",
      "episode: 597   score: 3.0   memory length: 108386   epsilon: 0.9916968700001803    steps: 262     evaluation reward: 1.23\n",
      "episode: 598   score: 1.0   memory length: 108559   epsilon: 0.991525600000184    steps: 173     evaluation reward: 1.24\n",
      "episode: 599   score: 3.0   memory length: 108839   epsilon: 0.99124840000019    steps: 280     evaluation reward: 1.25\n",
      "episode: 600   score: 0.0   memory length: 108967   epsilon: 0.9911216800001927    steps: 128     evaluation reward: 1.23\n",
      "episode: 601   score: 4.0   memory length: 109267   epsilon: 0.9908246800001992    steps: 300     evaluation reward: 1.26\n",
      "episode: 602   score: 3.0   memory length: 109519   epsilon: 0.9905752000002046    steps: 252     evaluation reward: 1.29\n",
      "episode: 603   score: 4.0   memory length: 109809   epsilon: 0.9902881000002108    steps: 290     evaluation reward: 1.31\n",
      "episode: 604   score: 1.0   memory length: 109973   epsilon: 0.9901257400002144    steps: 164     evaluation reward: 1.31\n",
      "episode: 605   score: 0.0   memory length: 110109   epsilon: 0.9899911000002173    steps: 136     evaluation reward: 1.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 606   score: 2.0   memory length: 110314   epsilon: 0.9897881500002217    steps: 205     evaluation reward: 1.31\n",
      "episode: 607   score: 0.0   memory length: 110450   epsilon: 0.9896535100002246    steps: 136     evaluation reward: 1.31\n",
      "episode: 608   score: 1.0   memory length: 110622   epsilon: 0.9894832300002283    steps: 172     evaluation reward: 1.31\n",
      "episode: 609   score: 0.0   memory length: 110749   epsilon: 0.989357500000231    steps: 127     evaluation reward: 1.3\n",
      "episode: 610   score: 1.0   memory length: 110926   epsilon: 0.9891822700002348    steps: 177     evaluation reward: 1.3\n",
      "episode: 611   score: 1.0   memory length: 111106   epsilon: 0.9890040700002387    steps: 180     evaluation reward: 1.31\n",
      "episode: 612   score: 3.0   memory length: 111375   epsilon: 0.9887377600002445    steps: 269     evaluation reward: 1.32\n",
      "episode: 613   score: 3.0   memory length: 111605   epsilon: 0.9885100600002494    steps: 230     evaluation reward: 1.32\n",
      "episode: 614   score: 2.0   memory length: 111808   epsilon: 0.9883090900002538    steps: 203     evaluation reward: 1.34\n",
      "episode: 615   score: 1.0   memory length: 111986   epsilon: 0.9881328700002576    steps: 178     evaluation reward: 1.34\n",
      "episode: 616   score: 1.0   memory length: 112144   epsilon: 0.987976450000261    steps: 158     evaluation reward: 1.33\n",
      "episode: 617   score: 3.0   memory length: 112396   epsilon: 0.9877269700002664    steps: 252     evaluation reward: 1.36\n",
      "episode: 618   score: 4.0   memory length: 112697   epsilon: 0.9874289800002729    steps: 301     evaluation reward: 1.39\n",
      "episode: 619   score: 3.0   memory length: 112951   epsilon: 0.9871775200002784    steps: 254     evaluation reward: 1.42\n",
      "episode: 620   score: 1.0   memory length: 113132   epsilon: 0.9869983300002823    steps: 181     evaluation reward: 1.41\n",
      "episode: 621   score: 1.0   memory length: 113284   epsilon: 0.9868478500002855    steps: 152     evaluation reward: 1.41\n",
      "episode: 622   score: 3.0   memory length: 113554   epsilon: 0.9865805500002913    steps: 270     evaluation reward: 1.44\n",
      "episode: 623   score: 1.0   memory length: 113710   epsilon: 0.9864261100002947    steps: 156     evaluation reward: 1.45\n",
      "episode: 624   score: 2.0   memory length: 113891   epsilon: 0.9862469200002986    steps: 181     evaluation reward: 1.46\n",
      "episode: 625   score: 1.0   memory length: 114083   epsilon: 0.9860568400003027    steps: 192     evaluation reward: 1.47\n",
      "episode: 626   score: 0.0   memory length: 114212   epsilon: 0.9859291300003055    steps: 129     evaluation reward: 1.46\n",
      "episode: 627   score: 8.0   memory length: 114569   epsilon: 0.9855757000003131    steps: 357     evaluation reward: 1.52\n",
      "episode: 628   score: 1.0   memory length: 114748   epsilon: 0.985398490000317    steps: 179     evaluation reward: 1.53\n",
      "episode: 629   score: 3.0   memory length: 115003   epsilon: 0.9851460400003225    steps: 255     evaluation reward: 1.52\n",
      "episode: 630   score: 2.0   memory length: 115206   epsilon: 0.9849450700003268    steps: 203     evaluation reward: 1.51\n",
      "episode: 631   score: 2.0   memory length: 115413   epsilon: 0.9847401400003313    steps: 207     evaluation reward: 1.51\n",
      "episode: 632   score: 0.0   memory length: 115543   epsilon: 0.9846114400003341    steps: 130     evaluation reward: 1.49\n",
      "episode: 633   score: 0.0   memory length: 115675   epsilon: 0.9844807600003369    steps: 132     evaluation reward: 1.49\n",
      "episode: 634   score: 0.0   memory length: 115806   epsilon: 0.9843510700003397    steps: 131     evaluation reward: 1.47\n",
      "episode: 635   score: 1.0   memory length: 115965   epsilon: 0.9841936600003431    steps: 159     evaluation reward: 1.48\n",
      "episode: 636   score: 5.0   memory length: 116270   epsilon: 0.9838917100003497    steps: 305     evaluation reward: 1.51\n",
      "episode: 637   score: 2.0   memory length: 116471   epsilon: 0.983692720000354    steps: 201     evaluation reward: 1.53\n",
      "episode: 638   score: 0.0   memory length: 116603   epsilon: 0.9835620400003569    steps: 132     evaluation reward: 1.51\n",
      "episode: 639   score: 1.0   memory length: 116792   epsilon: 0.9833749300003609    steps: 189     evaluation reward: 1.52\n",
      "episode: 640   score: 3.0   memory length: 117054   epsilon: 0.9831155500003665    steps: 262     evaluation reward: 1.55\n",
      "episode: 641   score: 2.0   memory length: 117265   epsilon: 0.9829066600003711    steps: 211     evaluation reward: 1.56\n",
      "episode: 642   score: 2.0   memory length: 117469   epsilon: 0.9827047000003755    steps: 204     evaluation reward: 1.55\n",
      "episode: 643   score: 1.0   memory length: 117631   epsilon: 0.982544320000379    steps: 162     evaluation reward: 1.54\n",
      "episode: 644   score: 0.0   memory length: 117763   epsilon: 0.9824136400003818    steps: 132     evaluation reward: 1.53\n",
      "episode: 645   score: 0.0   memory length: 117893   epsilon: 0.9822849400003846    steps: 130     evaluation reward: 1.52\n",
      "episode: 646   score: 0.0   memory length: 118023   epsilon: 0.9821562400003874    steps: 130     evaluation reward: 1.51\n",
      "episode: 647   score: 6.0   memory length: 118403   epsilon: 0.9817800400003955    steps: 380     evaluation reward: 1.55\n",
      "episode: 648   score: 2.0   memory length: 118607   epsilon: 0.9815780800003999    steps: 204     evaluation reward: 1.52\n",
      "episode: 649   score: 0.0   memory length: 118736   epsilon: 0.9814503700004027    steps: 129     evaluation reward: 1.52\n",
      "episode: 650   score: 0.0   memory length: 118862   epsilon: 0.9813256300004054    steps: 126     evaluation reward: 1.52\n",
      "episode: 651   score: 2.0   memory length: 119061   epsilon: 0.9811286200004097    steps: 199     evaluation reward: 1.53\n",
      "episode: 652   score: 0.0   memory length: 119203   epsilon: 0.9809880400004127    steps: 142     evaluation reward: 1.51\n",
      "episode: 653   score: 0.0   memory length: 119333   epsilon: 0.9808593400004155    steps: 130     evaluation reward: 1.49\n",
      "episode: 654   score: 2.0   memory length: 119555   epsilon: 0.9806395600004203    steps: 222     evaluation reward: 1.49\n",
      "episode: 655   score: 3.0   memory length: 119797   epsilon: 0.9803999800004255    steps: 242     evaluation reward: 1.48\n",
      "episode: 656   score: 3.0   memory length: 120029   epsilon: 0.9801703000004305    steps: 232     evaluation reward: 1.51\n",
      "episode: 657   score: 0.0   memory length: 120154   epsilon: 0.9800465500004332    steps: 125     evaluation reward: 1.49\n",
      "episode: 658   score: 3.0   memory length: 120430   epsilon: 0.9797733100004391    steps: 276     evaluation reward: 1.51\n",
      "episode: 659   score: 0.0   memory length: 120570   epsilon: 0.9796347100004421    steps: 140     evaluation reward: 1.51\n",
      "episode: 660   score: 1.0   memory length: 120745   epsilon: 0.9794614600004459    steps: 175     evaluation reward: 1.51\n",
      "episode: 661   score: 2.0   memory length: 120961   epsilon: 0.9792476200004505    steps: 216     evaluation reward: 1.48\n",
      "episode: 662   score: 2.0   memory length: 121188   epsilon: 0.9790228900004554    steps: 227     evaluation reward: 1.5\n",
      "episode: 663   score: 2.0   memory length: 121397   epsilon: 0.9788159800004599    steps: 209     evaluation reward: 1.5\n",
      "episode: 664   score: 1.0   memory length: 121561   epsilon: 0.9786536200004634    steps: 164     evaluation reward: 1.5\n",
      "episode: 665   score: 1.0   memory length: 121741   epsilon: 0.9784754200004673    steps: 180     evaluation reward: 1.48\n",
      "episode: 666   score: 2.0   memory length: 121939   epsilon: 0.9782794000004715    steps: 198     evaluation reward: 1.47\n",
      "episode: 667   score: 2.0   memory length: 122152   epsilon: 0.9780685300004761    steps: 213     evaluation reward: 1.48\n",
      "episode: 668   score: 0.0   memory length: 122276   epsilon: 0.9779457700004788    steps: 124     evaluation reward: 1.48\n",
      "episode: 669   score: 0.0   memory length: 122409   epsilon: 0.9778141000004816    steps: 133     evaluation reward: 1.48\n",
      "episode: 670   score: 2.0   memory length: 122646   epsilon: 0.9775794700004867    steps: 237     evaluation reward: 1.46\n",
      "episode: 671   score: 1.0   memory length: 122803   epsilon: 0.9774240400004901    steps: 157     evaluation reward: 1.47\n",
      "episode: 672   score: 0.0   memory length: 122934   epsilon: 0.9772943500004929    steps: 131     evaluation reward: 1.47\n",
      "episode: 673   score: 0.0   memory length: 123078   epsilon: 0.977151790000496    steps: 144     evaluation reward: 1.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 674   score: 2.0   memory length: 123299   epsilon: 0.9769330000005008    steps: 221     evaluation reward: 1.46\n",
      "episode: 675   score: 5.0   memory length: 123657   epsilon: 0.9765785800005085    steps: 358     evaluation reward: 1.5\n",
      "episode: 676   score: 1.0   memory length: 123843   epsilon: 0.9763944400005125    steps: 186     evaluation reward: 1.51\n",
      "episode: 677   score: 3.0   memory length: 124101   epsilon: 0.976139020000518    steps: 258     evaluation reward: 1.53\n",
      "episode: 678   score: 0.0   memory length: 124238   epsilon: 0.9760033900005209    steps: 137     evaluation reward: 1.52\n",
      "episode: 679   score: 0.0   memory length: 124368   epsilon: 0.9758746900005237    steps: 130     evaluation reward: 1.51\n",
      "episode: 680   score: 2.0   memory length: 124574   epsilon: 0.9756707500005282    steps: 206     evaluation reward: 1.5\n",
      "episode: 681   score: 0.0   memory length: 124708   epsilon: 0.975538090000531    steps: 134     evaluation reward: 1.47\n",
      "episode: 682   score: 1.0   memory length: 124884   epsilon: 0.9753638500005348    steps: 176     evaluation reward: 1.47\n",
      "episode: 683   score: 0.0   memory length: 125031   epsilon: 0.975218320000538    steps: 147     evaluation reward: 1.47\n",
      "episode: 684   score: 2.0   memory length: 125236   epsilon: 0.9750153700005424    steps: 205     evaluation reward: 1.49\n",
      "episode: 685   score: 3.0   memory length: 125471   epsilon: 0.9747827200005474    steps: 235     evaluation reward: 1.51\n",
      "episode: 686   score: 1.0   memory length: 125644   epsilon: 0.9746114500005512    steps: 173     evaluation reward: 1.52\n",
      "episode: 687   score: 2.0   memory length: 125841   epsilon: 0.9744164200005554    steps: 197     evaluation reward: 1.52\n",
      "episode: 688   score: 2.0   memory length: 126058   epsilon: 0.9742015900005601    steps: 217     evaluation reward: 1.54\n",
      "episode: 689   score: 1.0   memory length: 126236   epsilon: 0.9740253700005639    steps: 178     evaluation reward: 1.52\n",
      "episode: 690   score: 2.0   memory length: 126456   epsilon: 0.9738075700005686    steps: 220     evaluation reward: 1.54\n",
      "episode: 691   score: 0.0   memory length: 126588   epsilon: 0.9736768900005714    steps: 132     evaluation reward: 1.53\n",
      "episode: 692   score: 2.0   memory length: 126796   epsilon: 0.9734709700005759    steps: 208     evaluation reward: 1.55\n",
      "episode: 693   score: 0.0   memory length: 126924   epsilon: 0.9733442500005787    steps: 128     evaluation reward: 1.54\n",
      "episode: 694   score: 2.0   memory length: 127128   epsilon: 0.973142290000583    steps: 204     evaluation reward: 1.55\n",
      "episode: 695   score: 5.0   memory length: 127433   epsilon: 0.9728403400005896    steps: 305     evaluation reward: 1.6\n",
      "episode: 696   score: 1.0   memory length: 127617   epsilon: 0.9726581800005936    steps: 184     evaluation reward: 1.6\n",
      "episode: 697   score: 2.0   memory length: 127810   epsilon: 0.9724671100005977    steps: 193     evaluation reward: 1.59\n",
      "episode: 698   score: 1.0   memory length: 127991   epsilon: 0.9722879200006016    steps: 181     evaluation reward: 1.59\n",
      "episode: 699   score: 0.0   memory length: 128117   epsilon: 0.9721631800006043    steps: 126     evaluation reward: 1.56\n",
      "episode: 700   score: 3.0   memory length: 128340   epsilon: 0.9719424100006091    steps: 223     evaluation reward: 1.59\n",
      "episode: 701   score: 5.0   memory length: 128661   epsilon: 0.971624620000616    steps: 321     evaluation reward: 1.6\n",
      "episode: 702   score: 2.0   memory length: 128844   epsilon: 0.9714434500006199    steps: 183     evaluation reward: 1.59\n",
      "episode: 703   score: 1.0   memory length: 129000   epsilon: 0.9712890100006233    steps: 156     evaluation reward: 1.56\n",
      "episode: 704   score: 0.0   memory length: 129130   epsilon: 0.9711603100006261    steps: 130     evaluation reward: 1.55\n",
      "episode: 705   score: 2.0   memory length: 129333   epsilon: 0.9709593400006304    steps: 203     evaluation reward: 1.57\n",
      "episode: 706   score: 1.0   memory length: 129502   epsilon: 0.9707920300006341    steps: 169     evaluation reward: 1.56\n",
      "episode: 707   score: 1.0   memory length: 129667   epsilon: 0.9706286800006376    steps: 165     evaluation reward: 1.57\n",
      "episode: 708   score: 4.0   memory length: 129949   epsilon: 0.9703495000006437    steps: 282     evaluation reward: 1.6\n",
      "episode: 709   score: 0.0   memory length: 130093   epsilon: 0.9702069400006468    steps: 144     evaluation reward: 1.6\n",
      "episode: 710   score: 2.0   memory length: 130294   epsilon: 0.9700079500006511    steps: 201     evaluation reward: 1.61\n",
      "episode: 711   score: 1.0   memory length: 130463   epsilon: 0.9698406400006547    steps: 169     evaluation reward: 1.61\n",
      "episode: 712   score: 2.0   memory length: 130668   epsilon: 0.9696376900006591    steps: 205     evaluation reward: 1.6\n",
      "episode: 713   score: 3.0   memory length: 130919   epsilon: 0.9693892000006645    steps: 251     evaluation reward: 1.6\n",
      "episode: 714   score: 1.0   memory length: 131078   epsilon: 0.969231790000668    steps: 159     evaluation reward: 1.59\n",
      "episode: 715   score: 2.0   memory length: 131306   epsilon: 0.9690060700006728    steps: 228     evaluation reward: 1.6\n",
      "episode: 716   score: 1.0   memory length: 131483   epsilon: 0.9688308400006767    steps: 177     evaluation reward: 1.6\n",
      "episode: 717   score: 0.0   memory length: 131615   epsilon: 0.9687001600006795    steps: 132     evaluation reward: 1.57\n",
      "episode: 718   score: 1.0   memory length: 131800   epsilon: 0.9685170100006835    steps: 185     evaluation reward: 1.54\n",
      "episode: 719   score: 2.0   memory length: 132000   epsilon: 0.9683190100006878    steps: 200     evaluation reward: 1.53\n",
      "episode: 720   score: 0.0   memory length: 132133   epsilon: 0.9681873400006906    steps: 133     evaluation reward: 1.52\n",
      "episode: 721   score: 0.0   memory length: 132267   epsilon: 0.9680546800006935    steps: 134     evaluation reward: 1.51\n",
      "episode: 722   score: 1.0   memory length: 132426   epsilon: 0.9678972700006969    steps: 159     evaluation reward: 1.49\n",
      "episode: 723   score: 3.0   memory length: 132672   epsilon: 0.9676537300007022    steps: 246     evaluation reward: 1.51\n",
      "episode: 724   score: 1.0   memory length: 132849   epsilon: 0.967478500000706    steps: 177     evaluation reward: 1.5\n",
      "episode: 725   score: 1.0   memory length: 133023   epsilon: 0.9673062400007097    steps: 174     evaluation reward: 1.5\n",
      "episode: 726   score: 2.0   memory length: 133230   epsilon: 0.9671013100007142    steps: 207     evaluation reward: 1.52\n",
      "episode: 727   score: 1.0   memory length: 133397   epsilon: 0.9669359800007178    steps: 167     evaluation reward: 1.45\n",
      "episode: 728   score: 1.0   memory length: 133582   epsilon: 0.9667528300007218    steps: 185     evaluation reward: 1.45\n",
      "episode: 729   score: 1.0   memory length: 133758   epsilon: 0.9665785900007255    steps: 176     evaluation reward: 1.43\n",
      "episode: 730   score: 0.0   memory length: 133895   epsilon: 0.9664429600007285    steps: 137     evaluation reward: 1.41\n",
      "episode: 731   score: 3.0   memory length: 134166   epsilon: 0.9661746700007343    steps: 271     evaluation reward: 1.42\n",
      "episode: 732   score: 2.0   memory length: 134365   epsilon: 0.9659776600007386    steps: 199     evaluation reward: 1.44\n",
      "episode: 733   score: 3.0   memory length: 134596   epsilon: 0.9657489700007436    steps: 231     evaluation reward: 1.47\n",
      "episode: 734   score: 1.0   memory length: 134757   epsilon: 0.965589580000747    steps: 161     evaluation reward: 1.48\n",
      "episode: 735   score: 2.0   memory length: 134985   epsilon: 0.9653638600007519    steps: 228     evaluation reward: 1.49\n",
      "episode: 736   score: 3.0   memory length: 135257   epsilon: 0.9650945800007578    steps: 272     evaluation reward: 1.47\n",
      "episode: 737   score: 1.0   memory length: 135417   epsilon: 0.9649361800007612    steps: 160     evaluation reward: 1.46\n",
      "episode: 738   score: 1.0   memory length: 135578   epsilon: 0.9647767900007647    steps: 161     evaluation reward: 1.47\n",
      "episode: 739   score: 0.0   memory length: 135720   epsilon: 0.9646362100007677    steps: 142     evaluation reward: 1.46\n",
      "episode: 740   score: 0.0   memory length: 135855   epsilon: 0.9645025600007706    steps: 135     evaluation reward: 1.43\n",
      "episode: 741   score: 1.0   memory length: 136011   epsilon: 0.964348120000774    steps: 156     evaluation reward: 1.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 742   score: 1.0   memory length: 136171   epsilon: 0.9641897200007774    steps: 160     evaluation reward: 1.41\n",
      "episode: 743   score: 2.0   memory length: 136390   epsilon: 0.9639729100007821    steps: 219     evaluation reward: 1.42\n",
      "episode: 744   score: 3.0   memory length: 136640   epsilon: 0.9637254100007875    steps: 250     evaluation reward: 1.45\n",
      "episode: 745   score: 1.0   memory length: 136813   epsilon: 0.9635541400007912    steps: 173     evaluation reward: 1.46\n",
      "episode: 746   score: 2.0   memory length: 137038   epsilon: 0.963331390000796    steps: 225     evaluation reward: 1.48\n",
      "episode: 747   score: 2.0   memory length: 137257   epsilon: 0.9631145800008007    steps: 219     evaluation reward: 1.44\n",
      "episode: 748   score: 1.0   memory length: 137412   epsilon: 0.9629611300008041    steps: 155     evaluation reward: 1.43\n",
      "episode: 749   score: 2.0   memory length: 137621   epsilon: 0.9627542200008086    steps: 209     evaluation reward: 1.45\n",
      "episode: 750   score: 0.0   memory length: 137750   epsilon: 0.9626265100008113    steps: 129     evaluation reward: 1.45\n",
      "episode: 751   score: 1.0   memory length: 137925   epsilon: 0.9624532600008151    steps: 175     evaluation reward: 1.44\n",
      "episode: 752   score: 2.0   memory length: 138114   epsilon: 0.9622661500008192    steps: 189     evaluation reward: 1.46\n",
      "episode: 753   score: 0.0   memory length: 138242   epsilon: 0.9621394300008219    steps: 128     evaluation reward: 1.46\n",
      "episode: 754   score: 2.0   memory length: 138454   epsilon: 0.9619295500008265    steps: 212     evaluation reward: 1.46\n",
      "episode: 755   score: 4.0   memory length: 138767   epsilon: 0.9616196800008332    steps: 313     evaluation reward: 1.47\n",
      "episode: 756   score: 0.0   memory length: 138897   epsilon: 0.961490980000836    steps: 130     evaluation reward: 1.44\n",
      "episode: 757   score: 1.0   memory length: 139053   epsilon: 0.9613365400008393    steps: 156     evaluation reward: 1.45\n",
      "episode: 758   score: 0.0   memory length: 139179   epsilon: 0.961211800000842    steps: 126     evaluation reward: 1.42\n",
      "episode: 759   score: 3.0   memory length: 139416   epsilon: 0.9609771700008471    steps: 237     evaluation reward: 1.45\n",
      "episode: 760   score: 0.0   memory length: 139547   epsilon: 0.96084748000085    steps: 131     evaluation reward: 1.44\n",
      "episode: 761   score: 3.0   memory length: 139792   epsilon: 0.9606049300008552    steps: 245     evaluation reward: 1.45\n",
      "episode: 762   score: 0.0   memory length: 139924   epsilon: 0.9604742500008581    steps: 132     evaluation reward: 1.43\n",
      "episode: 763   score: 4.0   memory length: 140242   epsilon: 0.9601594300008649    steps: 318     evaluation reward: 1.45\n",
      "episode: 764   score: 0.0   memory length: 140366   epsilon: 0.9600366700008676    steps: 124     evaluation reward: 1.44\n",
      "episode: 765   score: 0.0   memory length: 140498   epsilon: 0.9599059900008704    steps: 132     evaluation reward: 1.43\n",
      "episode: 766   score: 1.0   memory length: 140664   epsilon: 0.959741650000874    steps: 166     evaluation reward: 1.42\n",
      "episode: 767   score: 4.0   memory length: 140933   epsilon: 0.9594753400008798    steps: 269     evaluation reward: 1.44\n",
      "episode: 768   score: 0.0   memory length: 141070   epsilon: 0.9593397100008827    steps: 137     evaluation reward: 1.44\n",
      "episode: 769   score: 0.0   memory length: 141200   epsilon: 0.9592110100008855    steps: 130     evaluation reward: 1.44\n",
      "episode: 770   score: 4.0   memory length: 141471   epsilon: 0.9589427200008913    steps: 271     evaluation reward: 1.46\n",
      "episode: 771   score: 1.0   memory length: 141634   epsilon: 0.9587813500008948    steps: 163     evaluation reward: 1.46\n",
      "episode: 772   score: 1.0   memory length: 141813   epsilon: 0.9586041400008987    steps: 179     evaluation reward: 1.47\n",
      "episode: 773   score: 1.0   memory length: 141991   epsilon: 0.9584279200009025    steps: 178     evaluation reward: 1.48\n",
      "episode: 774   score: 0.0   memory length: 142114   epsilon: 0.9583061500009051    steps: 123     evaluation reward: 1.46\n",
      "episode: 775   score: 1.0   memory length: 142292   epsilon: 0.958129930000909    steps: 178     evaluation reward: 1.42\n",
      "episode: 776   score: 1.0   memory length: 142449   epsilon: 0.9579745000009123    steps: 157     evaluation reward: 1.42\n",
      "episode: 777   score: 3.0   memory length: 142700   epsilon: 0.9577260100009177    steps: 251     evaluation reward: 1.42\n",
      "episode: 778   score: 2.0   memory length: 142910   epsilon: 0.9575181100009222    steps: 210     evaluation reward: 1.44\n",
      "episode: 779   score: 0.0   memory length: 143042   epsilon: 0.9573874300009251    steps: 132     evaluation reward: 1.44\n",
      "episode: 780   score: 2.0   memory length: 143247   epsilon: 0.9571844800009295    steps: 205     evaluation reward: 1.44\n",
      "episode: 781   score: 3.0   memory length: 143485   epsilon: 0.9569488600009346    steps: 238     evaluation reward: 1.47\n",
      "episode: 782   score: 0.0   memory length: 143619   epsilon: 0.9568162000009375    steps: 134     evaluation reward: 1.46\n",
      "episode: 783   score: 3.0   memory length: 143860   epsilon: 0.9565776100009427    steps: 241     evaluation reward: 1.49\n",
      "episode: 784   score: 1.0   memory length: 144030   epsilon: 0.9564093100009463    steps: 170     evaluation reward: 1.48\n",
      "episode: 785   score: 1.0   memory length: 144189   epsilon: 0.9562519000009497    steps: 159     evaluation reward: 1.46\n",
      "episode: 786   score: 2.0   memory length: 144392   epsilon: 0.9560509300009541    steps: 203     evaluation reward: 1.47\n",
      "episode: 787   score: 2.0   memory length: 144617   epsilon: 0.9558281800009589    steps: 225     evaluation reward: 1.47\n",
      "episode: 788   score: 2.0   memory length: 144842   epsilon: 0.9556054300009638    steps: 225     evaluation reward: 1.47\n",
      "episode: 789   score: 3.0   memory length: 145098   epsilon: 0.9553519900009693    steps: 256     evaluation reward: 1.49\n",
      "episode: 790   score: 2.0   memory length: 145296   epsilon: 0.9551559700009735    steps: 198     evaluation reward: 1.49\n",
      "episode: 791   score: 1.0   memory length: 145457   epsilon: 0.954996580000977    steps: 161     evaluation reward: 1.5\n",
      "episode: 792   score: 4.0   memory length: 145722   epsilon: 0.9547342300009827    steps: 265     evaluation reward: 1.52\n",
      "episode: 793   score: 2.0   memory length: 145919   epsilon: 0.9545392000009869    steps: 197     evaluation reward: 1.54\n",
      "episode: 794   score: 0.0   memory length: 146057   epsilon: 0.9544025800009899    steps: 138     evaluation reward: 1.52\n",
      "episode: 795   score: 5.0   memory length: 146389   epsilon: 0.954073900000997    steps: 332     evaluation reward: 1.52\n",
      "episode: 796   score: 2.0   memory length: 146591   epsilon: 0.9538739200010014    steps: 202     evaluation reward: 1.53\n",
      "episode: 797   score: 0.0   memory length: 146726   epsilon: 0.9537402700010043    steps: 135     evaluation reward: 1.51\n",
      "episode: 798   score: 0.0   memory length: 146853   epsilon: 0.953614540001007    steps: 127     evaluation reward: 1.5\n",
      "episode: 799   score: 1.0   memory length: 147034   epsilon: 0.9534353500010109    steps: 181     evaluation reward: 1.51\n",
      "episode: 800   score: 1.0   memory length: 147190   epsilon: 0.9532809100010142    steps: 156     evaluation reward: 1.49\n",
      "episode: 801   score: 1.0   memory length: 147366   epsilon: 0.953106670001018    steps: 176     evaluation reward: 1.45\n",
      "episode: 802   score: 1.0   memory length: 147531   epsilon: 0.9529433200010216    steps: 165     evaluation reward: 1.44\n",
      "episode: 803   score: 2.0   memory length: 147741   epsilon: 0.9527354200010261    steps: 210     evaluation reward: 1.45\n",
      "episode: 804   score: 1.0   memory length: 147907   epsilon: 0.9525710800010296    steps: 166     evaluation reward: 1.46\n",
      "episode: 805   score: 1.0   memory length: 148084   epsilon: 0.9523958500010334    steps: 177     evaluation reward: 1.45\n",
      "episode: 806   score: 1.0   memory length: 148278   epsilon: 0.9522037900010376    steps: 194     evaluation reward: 1.45\n",
      "episode: 807   score: 3.0   memory length: 148510   epsilon: 0.9519741100010426    steps: 232     evaluation reward: 1.47\n",
      "episode: 808   score: 1.0   memory length: 148685   epsilon: 0.9518008600010464    steps: 175     evaluation reward: 1.44\n",
      "episode: 809   score: 1.0   memory length: 148872   epsilon: 0.9516157300010504    steps: 187     evaluation reward: 1.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 810   score: 1.0   memory length: 149028   epsilon: 0.9514612900010537    steps: 156     evaluation reward: 1.44\n",
      "episode: 811   score: 4.0   memory length: 149307   epsilon: 0.9511850800010597    steps: 279     evaluation reward: 1.47\n",
      "episode: 812   score: 0.0   memory length: 149432   epsilon: 0.9510613300010624    steps: 125     evaluation reward: 1.45\n",
      "episode: 813   score: 0.0   memory length: 149562   epsilon: 0.9509326300010652    steps: 130     evaluation reward: 1.42\n",
      "episode: 814   score: 2.0   memory length: 149768   epsilon: 0.9507286900010696    steps: 206     evaluation reward: 1.43\n",
      "episode: 815   score: 0.0   memory length: 149899   epsilon: 0.9505990000010724    steps: 131     evaluation reward: 1.41\n",
      "now time :  2018-12-19 01:53:37.991147\n",
      "episode: 816   score: 1.0   memory length: 150070   epsilon: 0.9504297100010761    steps: 171     evaluation reward: 1.41\n",
      "episode: 817   score: 2.0   memory length: 150278   epsilon: 0.9502237900010806    steps: 208     evaluation reward: 1.43\n",
      "episode: 818   score: 1.0   memory length: 150432   epsilon: 0.9500713300010839    steps: 154     evaluation reward: 1.43\n",
      "episode: 819   score: 1.0   memory length: 150600   epsilon: 0.9499050100010875    steps: 168     evaluation reward: 1.42\n",
      "episode: 820   score: 2.0   memory length: 150821   epsilon: 0.9496862200010923    steps: 221     evaluation reward: 1.44\n",
      "episode: 821   score: 1.0   memory length: 150986   epsilon: 0.9495228700010958    steps: 165     evaluation reward: 1.45\n",
      "episode: 822   score: 0.0   memory length: 151119   epsilon: 0.9493912000010987    steps: 133     evaluation reward: 1.44\n",
      "episode: 823   score: 1.0   memory length: 151300   epsilon: 0.9492120100011026    steps: 181     evaluation reward: 1.42\n",
      "episode: 824   score: 1.0   memory length: 151482   epsilon: 0.9490318300011065    steps: 182     evaluation reward: 1.42\n",
      "episode: 825   score: 0.0   memory length: 151611   epsilon: 0.9489041200011092    steps: 129     evaluation reward: 1.41\n",
      "episode: 826   score: 2.0   memory length: 151795   epsilon: 0.9487219600011132    steps: 184     evaluation reward: 1.41\n",
      "episode: 827   score: 2.0   memory length: 152009   epsilon: 0.9485101000011178    steps: 214     evaluation reward: 1.42\n",
      "episode: 828   score: 1.0   memory length: 152164   epsilon: 0.9483566500011211    steps: 155     evaluation reward: 1.42\n",
      "episode: 829   score: 1.0   memory length: 152345   epsilon: 0.948177460001125    steps: 181     evaluation reward: 1.42\n",
      "episode: 830   score: 1.0   memory length: 152500   epsilon: 0.9480240100011283    steps: 155     evaluation reward: 1.43\n",
      "episode: 831   score: 4.0   memory length: 152795   epsilon: 0.9477319600011347    steps: 295     evaluation reward: 1.44\n",
      "episode: 832   score: 3.0   memory length: 153026   epsilon: 0.9475032700011397    steps: 231     evaluation reward: 1.45\n",
      "episode: 833   score: 2.0   memory length: 153229   epsilon: 0.947302300001144    steps: 203     evaluation reward: 1.44\n",
      "episode: 834   score: 1.0   memory length: 153388   epsilon: 0.9471448900011474    steps: 159     evaluation reward: 1.44\n",
      "episode: 835   score: 3.0   memory length: 153611   epsilon: 0.9469241200011522    steps: 223     evaluation reward: 1.45\n",
      "episode: 836   score: 3.0   memory length: 153864   epsilon: 0.9466736500011577    steps: 253     evaluation reward: 1.45\n",
      "episode: 837   score: 0.0   memory length: 153998   epsilon: 0.9465409900011605    steps: 134     evaluation reward: 1.44\n",
      "episode: 838   score: 0.0   memory length: 154133   epsilon: 0.9464073400011634    steps: 135     evaluation reward: 1.43\n",
      "episode: 839   score: 4.0   memory length: 154444   epsilon: 0.9460994500011701    steps: 311     evaluation reward: 1.47\n",
      "episode: 840   score: 2.0   memory length: 154653   epsilon: 0.9458925400011746    steps: 209     evaluation reward: 1.49\n",
      "episode: 841   score: 1.0   memory length: 154814   epsilon: 0.9457331500011781    steps: 161     evaluation reward: 1.49\n",
      "episode: 842   score: 1.0   memory length: 154971   epsilon: 0.9455777200011815    steps: 157     evaluation reward: 1.49\n",
      "episode: 843   score: 1.0   memory length: 155145   epsilon: 0.9454054600011852    steps: 174     evaluation reward: 1.48\n",
      "episode: 844   score: 2.0   memory length: 155349   epsilon: 0.9452035000011896    steps: 204     evaluation reward: 1.47\n",
      "episode: 845   score: 1.0   memory length: 155506   epsilon: 0.945048070001193    steps: 157     evaluation reward: 1.47\n",
      "episode: 846   score: 1.0   memory length: 155690   epsilon: 0.9448659100011969    steps: 184     evaluation reward: 1.46\n",
      "episode: 847   score: 2.0   memory length: 155887   epsilon: 0.9446708800012011    steps: 197     evaluation reward: 1.46\n",
      "episode: 848   score: 2.0   memory length: 156074   epsilon: 0.9444857500012052    steps: 187     evaluation reward: 1.47\n",
      "episode: 849   score: 2.0   memory length: 156278   epsilon: 0.9442837900012095    steps: 204     evaluation reward: 1.47\n",
      "episode: 850   score: 1.0   memory length: 156436   epsilon: 0.9441273700012129    steps: 158     evaluation reward: 1.48\n",
      "episode: 851   score: 2.0   memory length: 156622   epsilon: 0.9439432300012169    steps: 186     evaluation reward: 1.49\n",
      "episode: 852   score: 0.0   memory length: 156750   epsilon: 0.9438165100012197    steps: 128     evaluation reward: 1.47\n",
      "episode: 853   score: 0.0   memory length: 156880   epsilon: 0.9436878100012225    steps: 130     evaluation reward: 1.47\n",
      "episode: 854   score: 2.0   memory length: 157079   epsilon: 0.9434908000012268    steps: 199     evaluation reward: 1.47\n",
      "episode: 855   score: 5.0   memory length: 157413   epsilon: 0.9431601400012339    steps: 334     evaluation reward: 1.48\n",
      "episode: 856   score: 1.0   memory length: 157595   epsilon: 0.9429799600012378    steps: 182     evaluation reward: 1.49\n",
      "episode: 857   score: 1.0   memory length: 157776   epsilon: 0.9428007700012417    steps: 181     evaluation reward: 1.49\n",
      "episode: 858   score: 3.0   memory length: 158018   epsilon: 0.9425611900012469    steps: 242     evaluation reward: 1.52\n",
      "episode: 859   score: 0.0   memory length: 158148   epsilon: 0.9424324900012497    steps: 130     evaluation reward: 1.49\n",
      "episode: 860   score: 3.0   memory length: 158364   epsilon: 0.9422186500012544    steps: 216     evaluation reward: 1.52\n",
      "episode: 861   score: 2.0   memory length: 158587   epsilon: 0.9419978800012592    steps: 223     evaluation reward: 1.51\n",
      "episode: 862   score: 1.0   memory length: 158747   epsilon: 0.9418394800012626    steps: 160     evaluation reward: 1.52\n",
      "episode: 863   score: 0.0   memory length: 158873   epsilon: 0.9417147400012653    steps: 126     evaluation reward: 1.48\n",
      "episode: 864   score: 2.0   memory length: 159056   epsilon: 0.9415335700012692    steps: 183     evaluation reward: 1.5\n",
      "episode: 865   score: 1.0   memory length: 159237   epsilon: 0.9413543800012731    steps: 181     evaluation reward: 1.51\n",
      "episode: 866   score: 2.0   memory length: 159440   epsilon: 0.9411534100012775    steps: 203     evaluation reward: 1.52\n",
      "episode: 867   score: 4.0   memory length: 159697   epsilon: 0.940898980001283    steps: 257     evaluation reward: 1.52\n",
      "episode: 868   score: 0.0   memory length: 159829   epsilon: 0.9407683000012859    steps: 132     evaluation reward: 1.52\n",
      "episode: 869   score: 1.0   memory length: 159998   epsilon: 0.9406009900012895    steps: 169     evaluation reward: 1.53\n",
      "episode: 870   score: 2.0   memory length: 160226   epsilon: 0.9403752700012944    steps: 228     evaluation reward: 1.51\n",
      "episode: 871   score: 0.0   memory length: 160365   epsilon: 0.9402376600012974    steps: 139     evaluation reward: 1.5\n",
      "episode: 872   score: 1.0   memory length: 160518   epsilon: 0.9400861900013007    steps: 153     evaluation reward: 1.5\n",
      "episode: 873   score: 2.0   memory length: 160728   epsilon: 0.9398782900013052    steps: 210     evaluation reward: 1.51\n",
      "episode: 874   score: 1.0   memory length: 160885   epsilon: 0.9397228600013086    steps: 157     evaluation reward: 1.52\n",
      "episode: 875   score: 3.0   memory length: 161142   epsilon: 0.9394684300013141    steps: 257     evaluation reward: 1.54\n",
      "episode: 876   score: 1.0   memory length: 161317   epsilon: 0.9392951800013178    steps: 175     evaluation reward: 1.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 877   score: 3.0   memory length: 161574   epsilon: 0.9390407500013234    steps: 257     evaluation reward: 1.54\n",
      "episode: 878   score: 3.0   memory length: 161837   epsilon: 0.938780380001329    steps: 263     evaluation reward: 1.55\n",
      "episode: 879   score: 0.0   memory length: 161970   epsilon: 0.9386487100013319    steps: 133     evaluation reward: 1.55\n",
      "episode: 880   score: 2.0   memory length: 162194   epsilon: 0.9384269500013367    steps: 224     evaluation reward: 1.55\n",
      "episode: 881   score: 3.0   memory length: 162430   epsilon: 0.9381933100013418    steps: 236     evaluation reward: 1.55\n",
      "episode: 882   score: 0.0   memory length: 162558   epsilon: 0.9380665900013445    steps: 128     evaluation reward: 1.55\n",
      "episode: 883   score: 2.0   memory length: 162771   epsilon: 0.9378557200013491    steps: 213     evaluation reward: 1.54\n",
      "episode: 884   score: 2.0   memory length: 162976   epsilon: 0.9376527700013535    steps: 205     evaluation reward: 1.55\n",
      "episode: 885   score: 2.0   memory length: 163204   epsilon: 0.9374270500013584    steps: 228     evaluation reward: 1.56\n",
      "episode: 886   score: 1.0   memory length: 163362   epsilon: 0.9372706300013618    steps: 158     evaluation reward: 1.55\n",
      "episode: 887   score: 0.0   memory length: 163487   epsilon: 0.9371468800013645    steps: 125     evaluation reward: 1.53\n",
      "episode: 888   score: 4.0   memory length: 163788   epsilon: 0.936848890001371    steps: 301     evaluation reward: 1.55\n",
      "episode: 889   score: 2.0   memory length: 163989   epsilon: 0.9366499000013753    steps: 201     evaluation reward: 1.54\n",
      "episode: 890   score: 1.0   memory length: 164160   epsilon: 0.9364806100013789    steps: 171     evaluation reward: 1.53\n",
      "episode: 891   score: 1.0   memory length: 164315   epsilon: 0.9363271600013823    steps: 155     evaluation reward: 1.53\n",
      "episode: 892   score: 4.0   memory length: 164606   epsilon: 0.9360390700013885    steps: 291     evaluation reward: 1.53\n",
      "episode: 893   score: 2.0   memory length: 164810   epsilon: 0.9358371100013929    steps: 204     evaluation reward: 1.53\n",
      "episode: 894   score: 1.0   memory length: 164990   epsilon: 0.9356589100013968    steps: 180     evaluation reward: 1.54\n",
      "episode: 895   score: 3.0   memory length: 165251   epsilon: 0.9354005200014024    steps: 261     evaluation reward: 1.52\n",
      "episode: 896   score: 0.0   memory length: 165383   epsilon: 0.9352698400014052    steps: 132     evaluation reward: 1.5\n",
      "episode: 897   score: 4.0   memory length: 165650   epsilon: 0.935005510001411    steps: 267     evaluation reward: 1.54\n",
      "episode: 898   score: 1.0   memory length: 165809   epsilon: 0.9348481000014144    steps: 159     evaluation reward: 1.55\n",
      "episode: 899   score: 5.0   memory length: 166112   epsilon: 0.9345481300014209    steps: 303     evaluation reward: 1.59\n",
      "episode: 900   score: 3.0   memory length: 166354   epsilon: 0.9343085500014261    steps: 242     evaluation reward: 1.61\n",
      "episode: 901   score: 0.0   memory length: 166494   epsilon: 0.9341699500014291    steps: 140     evaluation reward: 1.6\n",
      "episode: 902   score: 0.0   memory length: 166624   epsilon: 0.9340412500014319    steps: 130     evaluation reward: 1.59\n",
      "episode: 903   score: 1.0   memory length: 166785   epsilon: 0.9338818600014354    steps: 161     evaluation reward: 1.58\n",
      "episode: 904   score: 1.0   memory length: 166961   epsilon: 0.9337076200014391    steps: 176     evaluation reward: 1.58\n",
      "episode: 905   score: 2.0   memory length: 167162   epsilon: 0.9335086300014435    steps: 201     evaluation reward: 1.59\n",
      "episode: 906   score: 3.0   memory length: 167403   epsilon: 0.9332700400014486    steps: 241     evaluation reward: 1.61\n",
      "episode: 907   score: 1.0   memory length: 167560   epsilon: 0.933114610001452    steps: 157     evaluation reward: 1.59\n",
      "episode: 908   score: 2.0   memory length: 167759   epsilon: 0.9329176000014563    steps: 199     evaluation reward: 1.6\n",
      "episode: 909   score: 2.0   memory length: 167959   epsilon: 0.9327196000014606    steps: 200     evaluation reward: 1.61\n",
      "episode: 910   score: 2.0   memory length: 168145   epsilon: 0.9325354600014646    steps: 186     evaluation reward: 1.62\n",
      "episode: 911   score: 1.0   memory length: 168302   epsilon: 0.932380030001468    steps: 157     evaluation reward: 1.59\n",
      "episode: 912   score: 3.0   memory length: 168541   epsilon: 0.9321434200014731    steps: 239     evaluation reward: 1.62\n",
      "episode: 913   score: 2.0   memory length: 168726   epsilon: 0.9319602700014771    steps: 185     evaluation reward: 1.64\n",
      "episode: 914   score: 2.0   memory length: 168929   epsilon: 0.9317593000014814    steps: 203     evaluation reward: 1.64\n",
      "episode: 915   score: 4.0   memory length: 169242   epsilon: 0.9314494300014882    steps: 313     evaluation reward: 1.68\n",
      "episode: 916   score: 2.0   memory length: 169467   epsilon: 0.931226680001493    steps: 225     evaluation reward: 1.69\n",
      "episode: 917   score: 0.0   memory length: 169599   epsilon: 0.9310960000014958    steps: 132     evaluation reward: 1.67\n",
      "episode: 918   score: 4.0   memory length: 169842   epsilon: 0.9308554300015011    steps: 243     evaluation reward: 1.7\n",
      "episode: 919   score: 4.0   memory length: 170103   epsilon: 0.9305970400015067    steps: 261     evaluation reward: 1.73\n",
      "episode: 920   score: 1.0   memory length: 170273   epsilon: 0.9304287400015103    steps: 170     evaluation reward: 1.72\n",
      "episode: 921   score: 1.0   memory length: 170445   epsilon: 0.930258460001514    steps: 172     evaluation reward: 1.72\n",
      "episode: 922   score: 2.0   memory length: 170653   epsilon: 0.9300525400015185    steps: 208     evaluation reward: 1.74\n",
      "episode: 923   score: 0.0   memory length: 170779   epsilon: 0.9299278000015212    steps: 126     evaluation reward: 1.73\n",
      "episode: 924   score: 1.0   memory length: 170941   epsilon: 0.9297674200015247    steps: 162     evaluation reward: 1.73\n",
      "episode: 925   score: 1.0   memory length: 171134   epsilon: 0.9295763500015288    steps: 193     evaluation reward: 1.74\n",
      "episode: 926   score: 1.0   memory length: 171291   epsilon: 0.9294209200015322    steps: 157     evaluation reward: 1.73\n",
      "episode: 927   score: 0.0   memory length: 171420   epsilon: 0.929293210001535    steps: 129     evaluation reward: 1.71\n",
      "episode: 928   score: 3.0   memory length: 171671   epsilon: 0.9290447200015404    steps: 251     evaluation reward: 1.73\n",
      "episode: 929   score: 1.0   memory length: 171837   epsilon: 0.9288803800015439    steps: 166     evaluation reward: 1.73\n",
      "episode: 930   score: 2.0   memory length: 172040   epsilon: 0.9286794100015483    steps: 203     evaluation reward: 1.74\n",
      "episode: 931   score: 0.0   memory length: 172168   epsilon: 0.928552690001551    steps: 128     evaluation reward: 1.7\n",
      "episode: 932   score: 2.0   memory length: 172359   epsilon: 0.9283636000015552    steps: 191     evaluation reward: 1.69\n",
      "episode: 933   score: 0.0   memory length: 172509   epsilon: 0.9282151000015584    steps: 150     evaluation reward: 1.67\n",
      "episode: 934   score: 1.0   memory length: 172676   epsilon: 0.928049770001562    steps: 167     evaluation reward: 1.67\n",
      "episode: 935   score: 0.0   memory length: 172804   epsilon: 0.9279230500015647    steps: 128     evaluation reward: 1.64\n",
      "episode: 936   score: 2.0   memory length: 173013   epsilon: 0.9277161400015692    steps: 209     evaluation reward: 1.63\n",
      "episode: 937   score: 1.0   memory length: 173176   epsilon: 0.9275547700015727    steps: 163     evaluation reward: 1.64\n",
      "episode: 938   score: 3.0   memory length: 173447   epsilon: 0.9272864800015785    steps: 271     evaluation reward: 1.67\n",
      "episode: 939   score: 2.0   memory length: 173651   epsilon: 0.9270845200015829    steps: 204     evaluation reward: 1.65\n",
      "episode: 940   score: 1.0   memory length: 173808   epsilon: 0.9269290900015863    steps: 157     evaluation reward: 1.64\n",
      "episode: 941   score: 0.0   memory length: 173934   epsilon: 0.926804350001589    steps: 126     evaluation reward: 1.63\n",
      "episode: 942   score: 0.0   memory length: 174068   epsilon: 0.9266716900015919    steps: 134     evaluation reward: 1.62\n",
      "episode: 943   score: 2.0   memory length: 174273   epsilon: 0.9264687400015963    steps: 205     evaluation reward: 1.63\n",
      "episode: 944   score: 0.0   memory length: 174403   epsilon: 0.9263400400015991    steps: 130     evaluation reward: 1.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 945   score: 3.0   memory length: 174674   epsilon: 0.9260717500016049    steps: 271     evaluation reward: 1.63\n",
      "episode: 946   score: 1.0   memory length: 174827   epsilon: 0.9259202800016082    steps: 153     evaluation reward: 1.63\n",
      "episode: 947   score: 1.0   memory length: 175011   epsilon: 0.9257381200016122    steps: 184     evaluation reward: 1.62\n",
      "episode: 948   score: 0.0   memory length: 175143   epsilon: 0.925607440001615    steps: 132     evaluation reward: 1.6\n",
      "episode: 949   score: 2.0   memory length: 175348   epsilon: 0.9254044900016194    steps: 205     evaluation reward: 1.6\n",
      "episode: 950   score: 6.0   memory length: 175680   epsilon: 0.9250758100016265    steps: 332     evaluation reward: 1.65\n",
      "episode: 951   score: 0.0   memory length: 175825   epsilon: 0.9249322600016296    steps: 145     evaluation reward: 1.63\n",
      "episode: 952   score: 2.0   memory length: 176034   epsilon: 0.9247253500016341    steps: 209     evaluation reward: 1.65\n",
      "episode: 953   score: 3.0   memory length: 176271   epsilon: 0.9244907200016392    steps: 237     evaluation reward: 1.68\n",
      "episode: 954   score: 0.0   memory length: 176402   epsilon: 0.924361030001642    steps: 131     evaluation reward: 1.66\n",
      "episode: 955   score: 0.0   memory length: 176540   epsilon: 0.924224410001645    steps: 138     evaluation reward: 1.61\n",
      "episode: 956   score: 1.0   memory length: 176700   epsilon: 0.9240660100016485    steps: 160     evaluation reward: 1.61\n",
      "episode: 957   score: 3.0   memory length: 176924   epsilon: 0.9238442500016533    steps: 224     evaluation reward: 1.63\n",
      "episode: 958   score: 1.0   memory length: 177089   epsilon: 0.9236809000016568    steps: 165     evaluation reward: 1.61\n",
      "episode: 959   score: 2.0   memory length: 177297   epsilon: 0.9234749800016613    steps: 208     evaluation reward: 1.63\n",
      "episode: 960   score: 4.0   memory length: 177606   epsilon: 0.9231690700016679    steps: 309     evaluation reward: 1.64\n",
      "episode: 961   score: 1.0   memory length: 177769   epsilon: 0.9230077000016714    steps: 163     evaluation reward: 1.63\n",
      "episode: 962   score: 1.0   memory length: 177942   epsilon: 0.9228364300016751    steps: 173     evaluation reward: 1.63\n",
      "episode: 963   score: 3.0   memory length: 178171   epsilon: 0.9226097200016801    steps: 229     evaluation reward: 1.66\n",
      "episode: 964   score: 1.0   memory length: 178337   epsilon: 0.9224453800016836    steps: 166     evaluation reward: 1.65\n",
      "episode: 965   score: 3.0   memory length: 178600   epsilon: 0.9221850100016893    steps: 263     evaluation reward: 1.67\n",
      "episode: 966   score: 0.0   memory length: 178727   epsilon: 0.922059280001692    steps: 127     evaluation reward: 1.65\n",
      "episode: 967   score: 2.0   memory length: 178952   epsilon: 0.9218365300016969    steps: 225     evaluation reward: 1.63\n",
      "episode: 968   score: 3.0   memory length: 179189   epsilon: 0.921601900001702    steps: 237     evaluation reward: 1.66\n",
      "episode: 969   score: 2.0   memory length: 179392   epsilon: 0.9214009300017063    steps: 203     evaluation reward: 1.67\n",
      "episode: 970   score: 0.0   memory length: 179525   epsilon: 0.9212692600017092    steps: 133     evaluation reward: 1.65\n",
      "episode: 971   score: 2.0   memory length: 179737   epsilon: 0.9210593800017137    steps: 212     evaluation reward: 1.67\n",
      "episode: 972   score: 0.0   memory length: 179878   epsilon: 0.9209197900017168    steps: 141     evaluation reward: 1.66\n",
      "episode: 973   score: 3.0   memory length: 180140   epsilon: 0.9206604100017224    steps: 262     evaluation reward: 1.67\n",
      "episode: 974   score: 1.0   memory length: 180325   epsilon: 0.9204772600017264    steps: 185     evaluation reward: 1.67\n",
      "episode: 975   score: 1.0   memory length: 180493   epsilon: 0.92031094000173    steps: 168     evaluation reward: 1.65\n",
      "episode: 976   score: 1.0   memory length: 180647   epsilon: 0.9201584800017333    steps: 154     evaluation reward: 1.65\n",
      "episode: 977   score: 1.0   memory length: 180803   epsilon: 0.9200040400017366    steps: 156     evaluation reward: 1.63\n",
      "episode: 978   score: 2.0   memory length: 181026   epsilon: 0.9197832700017414    steps: 223     evaluation reward: 1.62\n",
      "episode: 979   score: 2.0   memory length: 181228   epsilon: 0.9195832900017458    steps: 202     evaluation reward: 1.64\n",
      "episode: 980   score: 4.0   memory length: 181500   epsilon: 0.9193140100017516    steps: 272     evaluation reward: 1.66\n",
      "episode: 981   score: 1.0   memory length: 181655   epsilon: 0.919160560001755    steps: 155     evaluation reward: 1.64\n",
      "episode: 982   score: 3.0   memory length: 181902   epsilon: 0.9189160300017603    steps: 247     evaluation reward: 1.67\n",
      "episode: 983   score: 2.0   memory length: 182106   epsilon: 0.9187140700017646    steps: 204     evaluation reward: 1.67\n",
      "episode: 984   score: 0.0   memory length: 182241   epsilon: 0.9185804200017675    steps: 135     evaluation reward: 1.65\n",
      "episode: 985   score: 3.0   memory length: 182493   epsilon: 0.918330940001773    steps: 252     evaluation reward: 1.66\n",
      "episode: 986   score: 4.0   memory length: 182798   epsilon: 0.9180289900017795    steps: 305     evaluation reward: 1.69\n",
      "episode: 987   score: 2.0   memory length: 183001   epsilon: 0.9178280200017839    steps: 203     evaluation reward: 1.71\n",
      "episode: 988   score: 3.0   memory length: 183224   epsilon: 0.9176072500017887    steps: 223     evaluation reward: 1.7\n",
      "episode: 989   score: 0.0   memory length: 183354   epsilon: 0.9174785500017915    steps: 130     evaluation reward: 1.68\n",
      "episode: 990   score: 1.0   memory length: 183527   epsilon: 0.9173072800017952    steps: 173     evaluation reward: 1.68\n",
      "episode: 991   score: 1.0   memory length: 183713   epsilon: 0.9171231400017992    steps: 186     evaluation reward: 1.68\n",
      "episode: 992   score: 2.0   memory length: 183918   epsilon: 0.9169201900018036    steps: 205     evaluation reward: 1.66\n",
      "episode: 993   score: 2.0   memory length: 184132   epsilon: 0.9167083300018082    steps: 214     evaluation reward: 1.66\n",
      "episode: 994   score: 3.0   memory length: 184384   epsilon: 0.9164588500018136    steps: 252     evaluation reward: 1.68\n",
      "episode: 995   score: 2.0   memory length: 184583   epsilon: 0.9162618400018179    steps: 199     evaluation reward: 1.67\n",
      "episode: 996   score: 5.0   memory length: 184869   epsilon: 0.915978700001824    steps: 286     evaluation reward: 1.72\n",
      "episode: 997   score: 2.0   memory length: 185104   epsilon: 0.9157460500018291    steps: 235     evaluation reward: 1.7\n",
      "episode: 998   score: 1.0   memory length: 185263   epsilon: 0.9155886400018325    steps: 159     evaluation reward: 1.7\n",
      "episode: 999   score: 0.0   memory length: 185391   epsilon: 0.9154619200018352    steps: 128     evaluation reward: 1.65\n",
      "episode: 1000   score: 1.0   memory length: 185550   epsilon: 0.9153045100018387    steps: 159     evaluation reward: 1.63\n",
      "episode: 1001   score: 4.0   memory length: 185854   epsilon: 0.9150035500018452    steps: 304     evaluation reward: 1.67\n",
      "episode: 1002   score: 1.0   memory length: 186010   epsilon: 0.9148491100018485    steps: 156     evaluation reward: 1.68\n",
      "episode: 1003   score: 2.0   memory length: 186219   epsilon: 0.914642200001853    steps: 209     evaluation reward: 1.69\n",
      "episode: 1004   score: 2.0   memory length: 186419   epsilon: 0.9144442000018573    steps: 200     evaluation reward: 1.7\n",
      "episode: 1005   score: 1.0   memory length: 186595   epsilon: 0.9142699600018611    steps: 176     evaluation reward: 1.69\n",
      "episode: 1006   score: 2.0   memory length: 186796   epsilon: 0.9140709700018654    steps: 201     evaluation reward: 1.68\n",
      "episode: 1007   score: 1.0   memory length: 186957   epsilon: 0.9139115800018689    steps: 161     evaluation reward: 1.68\n",
      "episode: 1008   score: 4.0   memory length: 187217   epsilon: 0.9136541800018745    steps: 260     evaluation reward: 1.7\n",
      "episode: 1009   score: 0.0   memory length: 187351   epsilon: 0.9135215200018774    steps: 134     evaluation reward: 1.68\n",
      "episode: 1010   score: 6.0   memory length: 187724   epsilon: 0.9131522500018854    steps: 373     evaluation reward: 1.72\n",
      "episode: 1011   score: 2.0   memory length: 187933   epsilon: 0.9129453400018899    steps: 209     evaluation reward: 1.73\n",
      "episode: 1012   score: 2.0   memory length: 188140   epsilon: 0.9127404100018943    steps: 207     evaluation reward: 1.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1013   score: 0.0   memory length: 188264   epsilon: 0.912617650001897    steps: 124     evaluation reward: 1.7\n",
      "episode: 1014   score: 1.0   memory length: 188422   epsilon: 0.9124612300019004    steps: 158     evaluation reward: 1.69\n",
      "episode: 1015   score: 0.0   memory length: 188551   epsilon: 0.9123335200019032    steps: 129     evaluation reward: 1.65\n",
      "episode: 1016   score: 1.0   memory length: 188705   epsilon: 0.9121810600019065    steps: 154     evaluation reward: 1.64\n",
      "episode: 1017   score: 3.0   memory length: 188948   epsilon: 0.9119404900019117    steps: 243     evaluation reward: 1.67\n",
      "episode: 1018   score: 3.0   memory length: 189207   epsilon: 0.9116840800019173    steps: 259     evaluation reward: 1.66\n",
      "episode: 1019   score: 2.0   memory length: 189390   epsilon: 0.9115029100019212    steps: 183     evaluation reward: 1.64\n",
      "episode: 1020   score: 3.0   memory length: 189644   epsilon: 0.9112514500019266    steps: 254     evaluation reward: 1.66\n",
      "episode: 1021   score: 2.0   memory length: 189833   epsilon: 0.9110643400019307    steps: 189     evaluation reward: 1.67\n",
      "episode: 1022   score: 2.0   memory length: 190032   epsilon: 0.910867330001935    steps: 199     evaluation reward: 1.67\n",
      "episode: 1023   score: 0.0   memory length: 190160   epsilon: 0.9107406100019377    steps: 128     evaluation reward: 1.67\n",
      "episode: 1024   score: 0.0   memory length: 190286   epsilon: 0.9106158700019404    steps: 126     evaluation reward: 1.66\n",
      "episode: 1025   score: 2.0   memory length: 190480   epsilon: 0.9104238100019446    steps: 194     evaluation reward: 1.67\n",
      "episode: 1026   score: 2.0   memory length: 190704   epsilon: 0.9102020500019494    steps: 224     evaluation reward: 1.68\n",
      "episode: 1027   score: 0.0   memory length: 190836   epsilon: 0.9100713700019523    steps: 132     evaluation reward: 1.68\n",
      "episode: 1028   score: 4.0   memory length: 191120   epsilon: 0.9097902100019584    steps: 284     evaluation reward: 1.69\n",
      "episode: 1029   score: 1.0   memory length: 191280   epsilon: 0.9096318100019618    steps: 160     evaluation reward: 1.69\n",
      "episode: 1030   score: 2.0   memory length: 191484   epsilon: 0.9094298500019662    steps: 204     evaluation reward: 1.69\n",
      "episode: 1031   score: 1.0   memory length: 191645   epsilon: 0.9092704600019696    steps: 161     evaluation reward: 1.7\n",
      "episode: 1032   score: 0.0   memory length: 191775   epsilon: 0.9091417600019724    steps: 130     evaluation reward: 1.68\n",
      "episode: 1033   score: 4.0   memory length: 192046   epsilon: 0.9088734700019783    steps: 271     evaluation reward: 1.72\n",
      "episode: 1034   score: 2.0   memory length: 192252   epsilon: 0.9086695300019827    steps: 206     evaluation reward: 1.73\n",
      "episode: 1035   score: 3.0   memory length: 192523   epsilon: 0.9084012400019885    steps: 271     evaluation reward: 1.76\n",
      "episode: 1036   score: 4.0   memory length: 192797   epsilon: 0.9081299800019944    steps: 274     evaluation reward: 1.78\n",
      "episode: 1037   score: 2.0   memory length: 192977   epsilon: 0.9079517800019983    steps: 180     evaluation reward: 1.79\n",
      "episode: 1038   score: 0.0   memory length: 193111   epsilon: 0.9078191200020012    steps: 134     evaluation reward: 1.76\n",
      "episode: 1039   score: 2.0   memory length: 193336   epsilon: 0.907596370002006    steps: 225     evaluation reward: 1.76\n",
      "episode: 1040   score: 2.0   memory length: 193564   epsilon: 0.9073706500020109    steps: 228     evaluation reward: 1.77\n",
      "episode: 1041   score: 4.0   memory length: 193859   epsilon: 0.9070786000020172    steps: 295     evaluation reward: 1.81\n",
      "episode: 1042   score: 0.0   memory length: 193992   epsilon: 0.9069469300020201    steps: 133     evaluation reward: 1.81\n",
      "episode: 1043   score: 0.0   memory length: 194128   epsilon: 0.906812290002023    steps: 136     evaluation reward: 1.79\n",
      "episode: 1044   score: 4.0   memory length: 194451   epsilon: 0.90649252000203    steps: 323     evaluation reward: 1.83\n",
      "episode: 1045   score: 0.0   memory length: 194578   epsilon: 0.9063667900020327    steps: 127     evaluation reward: 1.8\n",
      "episode: 1046   score: 2.0   memory length: 194784   epsilon: 0.9061628500020371    steps: 206     evaluation reward: 1.81\n",
      "episode: 1047   score: 2.0   memory length: 194965   epsilon: 0.905983660002041    steps: 181     evaluation reward: 1.82\n",
      "episode: 1048   score: 0.0   memory length: 195095   epsilon: 0.9058549600020438    steps: 130     evaluation reward: 1.82\n",
      "episode: 1049   score: 3.0   memory length: 195352   epsilon: 0.9056005300020493    steps: 257     evaluation reward: 1.83\n",
      "episode: 1050   score: 4.0   memory length: 195642   epsilon: 0.9053134300020556    steps: 290     evaluation reward: 1.81\n",
      "episode: 1051   score: 1.0   memory length: 195830   epsilon: 0.9051273100020596    steps: 188     evaluation reward: 1.82\n",
      "episode: 1052   score: 2.0   memory length: 196017   epsilon: 0.9049421800020636    steps: 187     evaluation reward: 1.82\n",
      "episode: 1053   score: 2.0   memory length: 196206   epsilon: 0.9047550700020677    steps: 189     evaluation reward: 1.81\n",
      "episode: 1054   score: 1.0   memory length: 196396   epsilon: 0.9045669700020718    steps: 190     evaluation reward: 1.82\n",
      "episode: 1055   score: 2.0   memory length: 196604   epsilon: 0.9043610500020762    steps: 208     evaluation reward: 1.84\n",
      "episode: 1056   score: 1.0   memory length: 196761   epsilon: 0.9042056200020796    steps: 157     evaluation reward: 1.84\n",
      "episode: 1057   score: 2.0   memory length: 196969   epsilon: 0.9039997000020841    steps: 208     evaluation reward: 1.83\n",
      "episode: 1058   score: 0.0   memory length: 197094   epsilon: 0.9038759500020868    steps: 125     evaluation reward: 1.82\n",
      "episode: 1059   score: 3.0   memory length: 197332   epsilon: 0.9036403300020919    steps: 238     evaluation reward: 1.83\n",
      "episode: 1060   score: 3.0   memory length: 197568   epsilon: 0.903406690002097    steps: 236     evaluation reward: 1.82\n",
      "episode: 1061   score: 5.0   memory length: 197888   epsilon: 0.9030898900021038    steps: 320     evaluation reward: 1.86\n",
      "episode: 1062   score: 3.0   memory length: 198160   epsilon: 0.9028206100021097    steps: 272     evaluation reward: 1.88\n",
      "episode: 1063   score: 1.0   memory length: 198347   epsilon: 0.9026354800021137    steps: 187     evaluation reward: 1.86\n",
      "episode: 1064   score: 2.0   memory length: 198531   epsilon: 0.9024533200021176    steps: 184     evaluation reward: 1.87\n",
      "episode: 1065   score: 1.0   memory length: 198694   epsilon: 0.9022919500021211    steps: 163     evaluation reward: 1.85\n",
      "episode: 1066   score: 0.0   memory length: 198819   epsilon: 0.9021682000021238    steps: 125     evaluation reward: 1.85\n",
      "episode: 1067   score: 4.0   memory length: 199105   epsilon: 0.90188506000213    steps: 286     evaluation reward: 1.87\n",
      "episode: 1068   score: 5.0   memory length: 199392   epsilon: 0.9016009300021361    steps: 287     evaluation reward: 1.89\n",
      "episode: 1069   score: 0.0   memory length: 199525   epsilon: 0.901469260002139    steps: 133     evaluation reward: 1.87\n",
      "episode: 1070   score: 2.0   memory length: 199735   epsilon: 0.9012613600021435    steps: 210     evaluation reward: 1.89\n",
      "episode: 1071   score: 2.0   memory length: 199917   epsilon: 0.9010811800021474    steps: 182     evaluation reward: 1.89\n",
      "now time :  2018-12-19 02:08:40.412274\n",
      "episode: 1072   score: 2.0   memory length: 200123   epsilon: 0.9008772400021519    steps: 206     evaluation reward: 1.91\n",
      "episode: 1073   score: 1.0   memory length: 200277   epsilon: 0.9007247800021552    steps: 154     evaluation reward: 1.89\n",
      "episode: 1074   score: 1.0   memory length: 200439   epsilon: 0.9005644000021586    steps: 162     evaluation reward: 1.89\n",
      "episode: 1075   score: 1.0   memory length: 200601   epsilon: 0.9004040200021621    steps: 162     evaluation reward: 1.89\n",
      "episode: 1076   score: 7.0   memory length: 200854   epsilon: 0.9001535500021676    steps: 253     evaluation reward: 1.95\n",
      "episode: 1077   score: 3.0   memory length: 201097   epsilon: 0.8999129800021728    steps: 243     evaluation reward: 1.97\n",
      "episode: 1078   score: 3.0   memory length: 201346   epsilon: 0.8996664700021781    steps: 249     evaluation reward: 1.98\n",
      "episode: 1079   score: 1.0   memory length: 201504   epsilon: 0.8995100500021815    steps: 158     evaluation reward: 1.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1080   score: 3.0   memory length: 201744   epsilon: 0.8992724500021867    steps: 240     evaluation reward: 1.96\n",
      "episode: 1081   score: 4.0   memory length: 202028   epsilon: 0.8989912900021928    steps: 284     evaluation reward: 1.99\n",
      "episode: 1082   score: 0.0   memory length: 202158   epsilon: 0.8988625900021956    steps: 130     evaluation reward: 1.96\n",
      "episode: 1083   score: 0.0   memory length: 202294   epsilon: 0.8987279500021985    steps: 136     evaluation reward: 1.94\n",
      "episode: 1084   score: 2.0   memory length: 202482   epsilon: 0.8985418300022026    steps: 188     evaluation reward: 1.96\n",
      "episode: 1085   score: 2.0   memory length: 202712   epsilon: 0.8983141300022075    steps: 230     evaluation reward: 1.95\n",
      "episode: 1086   score: 0.0   memory length: 202848   epsilon: 0.8981794900022104    steps: 136     evaluation reward: 1.91\n",
      "episode: 1087   score: 4.0   memory length: 203112   epsilon: 0.8979181300022161    steps: 264     evaluation reward: 1.93\n",
      "episode: 1088   score: 3.0   memory length: 203358   epsilon: 0.8976745900022214    steps: 246     evaluation reward: 1.93\n",
      "episode: 1089   score: 1.0   memory length: 203541   epsilon: 0.8974934200022253    steps: 183     evaluation reward: 1.94\n",
      "episode: 1090   score: 3.0   memory length: 203757   epsilon: 0.89727958000223    steps: 216     evaluation reward: 1.96\n",
      "episode: 1091   score: 0.0   memory length: 203896   epsilon: 0.897141970002233    steps: 139     evaluation reward: 1.95\n",
      "episode: 1092   score: 1.0   memory length: 204072   epsilon: 0.8969677300022367    steps: 176     evaluation reward: 1.94\n",
      "episode: 1093   score: 0.0   memory length: 204204   epsilon: 0.8968370500022396    steps: 132     evaluation reward: 1.92\n",
      "episode: 1094   score: 0.0   memory length: 204343   epsilon: 0.8966994400022426    steps: 139     evaluation reward: 1.89\n",
      "episode: 1095   score: 4.0   memory length: 204590   epsilon: 0.8964549100022479    steps: 247     evaluation reward: 1.91\n",
      "episode: 1096   score: 4.0   memory length: 204865   epsilon: 0.8961826600022538    steps: 275     evaluation reward: 1.9\n",
      "episode: 1097   score: 4.0   memory length: 205172   epsilon: 0.8958787300022604    steps: 307     evaluation reward: 1.92\n",
      "episode: 1098   score: 1.0   memory length: 205332   epsilon: 0.8957203300022638    steps: 160     evaluation reward: 1.92\n",
      "episode: 1099   score: 1.0   memory length: 205507   epsilon: 0.8955470800022676    steps: 175     evaluation reward: 1.93\n",
      "episode: 1100   score: 1.0   memory length: 205667   epsilon: 0.895388680002271    steps: 160     evaluation reward: 1.93\n",
      "episode: 1101   score: 1.0   memory length: 205854   epsilon: 0.895203550002275    steps: 187     evaluation reward: 1.9\n",
      "episode: 1102   score: 2.0   memory length: 206065   epsilon: 0.8949946600022796    steps: 211     evaluation reward: 1.91\n",
      "episode: 1103   score: 2.0   memory length: 206255   epsilon: 0.8948065600022836    steps: 190     evaluation reward: 1.91\n",
      "episode: 1104   score: 2.0   memory length: 206459   epsilon: 0.894604600002288    steps: 204     evaluation reward: 1.91\n",
      "episode: 1105   score: 3.0   memory length: 206679   epsilon: 0.8943868000022928    steps: 220     evaluation reward: 1.93\n",
      "episode: 1106   score: 2.0   memory length: 206885   epsilon: 0.8941828600022972    steps: 206     evaluation reward: 1.93\n",
      "episode: 1107   score: 0.0   memory length: 207019   epsilon: 0.8940502000023001    steps: 134     evaluation reward: 1.92\n",
      "episode: 1108   score: 0.0   memory length: 207146   epsilon: 0.8939244700023028    steps: 127     evaluation reward: 1.88\n",
      "episode: 1109   score: 1.0   memory length: 207299   epsilon: 0.8937730000023061    steps: 153     evaluation reward: 1.89\n",
      "episode: 1110   score: 0.0   memory length: 207434   epsilon: 0.893639350002309    steps: 135     evaluation reward: 1.83\n",
      "episode: 1111   score: 4.0   memory length: 207740   epsilon: 0.8933364100023156    steps: 306     evaluation reward: 1.85\n",
      "episode: 1112   score: 1.0   memory length: 207893   epsilon: 0.8931849400023189    steps: 153     evaluation reward: 1.84\n",
      "episode: 1113   score: 0.0   memory length: 208020   epsilon: 0.8930592100023216    steps: 127     evaluation reward: 1.84\n",
      "episode: 1114   score: 4.0   memory length: 208290   epsilon: 0.8927919100023274    steps: 270     evaluation reward: 1.87\n",
      "episode: 1115   score: 1.0   memory length: 208448   epsilon: 0.8926354900023308    steps: 158     evaluation reward: 1.88\n",
      "episode: 1116   score: 0.0   memory length: 208578   epsilon: 0.8925067900023336    steps: 130     evaluation reward: 1.87\n",
      "episode: 1117   score: 3.0   memory length: 208793   epsilon: 0.8922939400023382    steps: 215     evaluation reward: 1.87\n",
      "episode: 1118   score: 0.0   memory length: 208918   epsilon: 0.8921701900023409    steps: 125     evaluation reward: 1.84\n",
      "episode: 1119   score: 1.0   memory length: 209095   epsilon: 0.8919949600023447    steps: 177     evaluation reward: 1.83\n",
      "episode: 1120   score: 3.0   memory length: 209353   epsilon: 0.8917395400023502    steps: 258     evaluation reward: 1.83\n",
      "episode: 1121   score: 0.0   memory length: 209477   epsilon: 0.8916167800023529    steps: 124     evaluation reward: 1.81\n",
      "episode: 1122   score: 1.0   memory length: 209636   epsilon: 0.8914593700023563    steps: 159     evaluation reward: 1.8\n",
      "episode: 1123   score: 8.0   memory length: 210077   epsilon: 0.8910227800023658    steps: 441     evaluation reward: 1.88\n",
      "episode: 1124   score: 1.0   memory length: 210256   epsilon: 0.8908455700023696    steps: 179     evaluation reward: 1.89\n",
      "episode: 1125   score: 0.0   memory length: 210387   epsilon: 0.8907158800023725    steps: 131     evaluation reward: 1.87\n",
      "episode: 1126   score: 2.0   memory length: 210589   epsilon: 0.8905159000023768    steps: 202     evaluation reward: 1.87\n",
      "episode: 1127   score: 3.0   memory length: 210824   epsilon: 0.8902832500023818    steps: 235     evaluation reward: 1.9\n",
      "episode: 1128   score: 4.0   memory length: 211118   epsilon: 0.8899921900023882    steps: 294     evaluation reward: 1.9\n",
      "episode: 1129   score: 3.0   memory length: 211359   epsilon: 0.8897536000023933    steps: 241     evaluation reward: 1.92\n",
      "episode: 1130   score: 2.0   memory length: 211571   epsilon: 0.8895437200023979    steps: 212     evaluation reward: 1.92\n",
      "episode: 1131   score: 1.0   memory length: 211748   epsilon: 0.8893684900024017    steps: 177     evaluation reward: 1.92\n",
      "episode: 1132   score: 1.0   memory length: 211928   epsilon: 0.8891902900024056    steps: 180     evaluation reward: 1.93\n",
      "episode: 1133   score: 3.0   memory length: 212167   epsilon: 0.8889536800024107    steps: 239     evaluation reward: 1.92\n",
      "episode: 1134   score: 3.0   memory length: 212396   epsilon: 0.8887269700024156    steps: 229     evaluation reward: 1.93\n",
      "episode: 1135   score: 4.0   memory length: 212671   epsilon: 0.8884547200024215    steps: 275     evaluation reward: 1.94\n",
      "episode: 1136   score: 0.0   memory length: 212806   epsilon: 0.8883210700024244    steps: 135     evaluation reward: 1.9\n",
      "episode: 1137   score: 2.0   memory length: 213015   epsilon: 0.8881141600024289    steps: 209     evaluation reward: 1.9\n",
      "episode: 1138   score: 2.0   memory length: 213223   epsilon: 0.8879082400024334    steps: 208     evaluation reward: 1.92\n",
      "episode: 1139   score: 1.0   memory length: 213407   epsilon: 0.8877260800024374    steps: 184     evaluation reward: 1.91\n",
      "episode: 1140   score: 3.0   memory length: 213655   epsilon: 0.8874805600024427    steps: 248     evaluation reward: 1.92\n",
      "episode: 1141   score: 1.0   memory length: 213813   epsilon: 0.8873241400024461    steps: 158     evaluation reward: 1.89\n",
      "episode: 1142   score: 1.0   memory length: 213978   epsilon: 0.8871607900024496    steps: 165     evaluation reward: 1.9\n",
      "episode: 1143   score: 1.0   memory length: 214160   epsilon: 0.8869806100024535    steps: 182     evaluation reward: 1.91\n",
      "episode: 1144   score: 4.0   memory length: 214454   epsilon: 0.8866895500024599    steps: 294     evaluation reward: 1.91\n",
      "episode: 1145   score: 0.0   memory length: 214576   epsilon: 0.8865687700024625    steps: 122     evaluation reward: 1.91\n",
      "episode: 1146   score: 3.0   memory length: 214831   epsilon: 0.886316320002468    steps: 255     evaluation reward: 1.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1147   score: 3.0   memory length: 215107   epsilon: 0.8860430800024739    steps: 276     evaluation reward: 1.93\n",
      "episode: 1148   score: 2.0   memory length: 215309   epsilon: 0.8858431000024782    steps: 202     evaluation reward: 1.95\n",
      "episode: 1149   score: 5.0   memory length: 215620   epsilon: 0.8855352100024849    steps: 311     evaluation reward: 1.97\n",
      "episode: 1150   score: 2.0   memory length: 215822   epsilon: 0.8853352300024893    steps: 202     evaluation reward: 1.95\n",
      "episode: 1151   score: 2.0   memory length: 216019   epsilon: 0.8851402000024935    steps: 197     evaluation reward: 1.96\n",
      "episode: 1152   score: 2.0   memory length: 216239   epsilon: 0.8849224000024982    steps: 220     evaluation reward: 1.96\n",
      "episode: 1153   score: 3.0   memory length: 216477   epsilon: 0.8846867800025033    steps: 238     evaluation reward: 1.97\n",
      "episode: 1154   score: 6.0   memory length: 216868   epsilon: 0.8842996900025117    steps: 391     evaluation reward: 2.02\n",
      "episode: 1155   score: 1.0   memory length: 217044   epsilon: 0.8841254500025155    steps: 176     evaluation reward: 2.01\n",
      "episode: 1156   score: 6.0   memory length: 217413   epsilon: 0.8837601400025235    steps: 369     evaluation reward: 2.06\n",
      "episode: 1157   score: 4.0   memory length: 217683   epsilon: 0.8834928400025293    steps: 270     evaluation reward: 2.08\n",
      "episode: 1158   score: 1.0   memory length: 217838   epsilon: 0.8833393900025326    steps: 155     evaluation reward: 2.09\n",
      "episode: 1159   score: 3.0   memory length: 218076   epsilon: 0.8831037700025377    steps: 238     evaluation reward: 2.09\n",
      "episode: 1160   score: 1.0   memory length: 218256   epsilon: 0.8829255700025416    steps: 180     evaluation reward: 2.07\n",
      "episode: 1161   score: 3.0   memory length: 218484   epsilon: 0.8826998500025465    steps: 228     evaluation reward: 2.05\n",
      "episode: 1162   score: 2.0   memory length: 218697   epsilon: 0.882488980002551    steps: 213     evaluation reward: 2.04\n",
      "episode: 1163   score: 6.0   memory length: 219055   epsilon: 0.8821345600025587    steps: 358     evaluation reward: 2.09\n",
      "episode: 1164   score: 2.0   memory length: 219256   epsilon: 0.8819355700025631    steps: 201     evaluation reward: 2.09\n",
      "episode: 1165   score: 1.0   memory length: 219433   epsilon: 0.8817603400025669    steps: 177     evaluation reward: 2.09\n",
      "episode: 1166   score: 5.0   memory length: 219771   epsilon: 0.8814257200025741    steps: 338     evaluation reward: 2.14\n",
      "episode: 1167   score: 1.0   memory length: 219928   epsilon: 0.8812702900025775    steps: 157     evaluation reward: 2.11\n",
      "episode: 1168   score: 1.0   memory length: 220083   epsilon: 0.8811168400025808    steps: 155     evaluation reward: 2.07\n",
      "episode: 1169   score: 1.0   memory length: 220246   epsilon: 0.8809554700025843    steps: 163     evaluation reward: 2.08\n",
      "episode: 1170   score: 3.0   memory length: 220520   epsilon: 0.8806842100025902    steps: 274     evaluation reward: 2.09\n",
      "episode: 1171   score: 1.0   memory length: 220691   epsilon: 0.8805149200025939    steps: 171     evaluation reward: 2.08\n",
      "episode: 1172   score: 5.0   memory length: 220992   epsilon: 0.8802169300026004    steps: 301     evaluation reward: 2.11\n",
      "episode: 1173   score: 3.0   memory length: 221231   epsilon: 0.8799803200026055    steps: 239     evaluation reward: 2.13\n",
      "episode: 1174   score: 7.0   memory length: 221623   epsilon: 0.8795922400026139    steps: 392     evaluation reward: 2.19\n",
      "episode: 1175   score: 1.0   memory length: 221787   epsilon: 0.8794298800026175    steps: 164     evaluation reward: 2.19\n",
      "episode: 1176   score: 3.0   memory length: 222039   epsilon: 0.8791804000026229    steps: 252     evaluation reward: 2.15\n",
      "episode: 1177   score: 6.0   memory length: 222436   epsilon: 0.8787873700026314    steps: 397     evaluation reward: 2.18\n",
      "episode: 1178   score: 1.0   memory length: 222611   epsilon: 0.8786141200026352    steps: 175     evaluation reward: 2.16\n",
      "episode: 1179   score: 0.0   memory length: 222740   epsilon: 0.8784864100026379    steps: 129     evaluation reward: 2.15\n",
      "episode: 1180   score: 6.0   memory length: 223107   epsilon: 0.8781230800026458    steps: 367     evaluation reward: 2.18\n",
      "episode: 1181   score: 4.0   memory length: 223358   epsilon: 0.8778745900026512    steps: 251     evaluation reward: 2.18\n",
      "episode: 1182   score: 0.0   memory length: 223491   epsilon: 0.8777429200026541    steps: 133     evaluation reward: 2.18\n",
      "episode: 1183   score: 2.0   memory length: 223724   epsilon: 0.8775122500026591    steps: 233     evaluation reward: 2.2\n",
      "episode: 1184   score: 0.0   memory length: 223856   epsilon: 0.8773815700026619    steps: 132     evaluation reward: 2.18\n",
      "episode: 1185   score: 1.0   memory length: 224018   epsilon: 0.8772211900026654    steps: 162     evaluation reward: 2.17\n",
      "episode: 1186   score: 3.0   memory length: 224243   epsilon: 0.8769984400026702    steps: 225     evaluation reward: 2.2\n",
      "episode: 1187   score: 0.0   memory length: 224376   epsilon: 0.8768667700026731    steps: 133     evaluation reward: 2.16\n",
      "episode: 1188   score: 1.0   memory length: 224552   epsilon: 0.8766925300026769    steps: 176     evaluation reward: 2.14\n",
      "episode: 1189   score: 1.0   memory length: 224705   epsilon: 0.8765410600026802    steps: 153     evaluation reward: 2.14\n",
      "episode: 1190   score: 3.0   memory length: 224978   epsilon: 0.876270790002686    steps: 273     evaluation reward: 2.14\n",
      "episode: 1191   score: 4.0   memory length: 225243   epsilon: 0.8760084400026917    steps: 265     evaluation reward: 2.18\n",
      "episode: 1192   score: 0.0   memory length: 225376   epsilon: 0.8758767700026946    steps: 133     evaluation reward: 2.17\n",
      "episode: 1193   score: 1.0   memory length: 225566   epsilon: 0.8756886700026987    steps: 190     evaluation reward: 2.18\n",
      "episode: 1194   score: 3.0   memory length: 225827   epsilon: 0.8754302800027043    steps: 261     evaluation reward: 2.21\n",
      "episode: 1195   score: 5.0   memory length: 226208   epsilon: 0.8750530900027125    steps: 381     evaluation reward: 2.22\n",
      "episode: 1196   score: 2.0   memory length: 226412   epsilon: 0.8748511300027169    steps: 204     evaluation reward: 2.2\n",
      "episode: 1197   score: 7.0   memory length: 226799   epsilon: 0.8744680000027252    steps: 387     evaluation reward: 2.23\n",
      "episode: 1198   score: 3.0   memory length: 227033   epsilon: 0.8742363400027302    steps: 234     evaluation reward: 2.25\n",
      "episode: 1199   score: 1.0   memory length: 227209   epsilon: 0.874062100002734    steps: 176     evaluation reward: 2.25\n",
      "episode: 1200   score: 2.0   memory length: 227402   epsilon: 0.8738710300027381    steps: 193     evaluation reward: 2.26\n",
      "episode: 1201   score: 0.0   memory length: 227530   epsilon: 0.8737443100027409    steps: 128     evaluation reward: 2.25\n",
      "episode: 1202   score: 0.0   memory length: 227664   epsilon: 0.8736116500027438    steps: 134     evaluation reward: 2.23\n",
      "episode: 1203   score: 0.0   memory length: 227805   epsilon: 0.8734720600027468    steps: 141     evaluation reward: 2.21\n",
      "episode: 1204   score: 7.0   memory length: 228238   epsilon: 0.8730433900027561    steps: 433     evaluation reward: 2.26\n",
      "episode: 1205   score: 2.0   memory length: 228442   epsilon: 0.8728414300027605    steps: 204     evaluation reward: 2.25\n",
      "episode: 1206   score: 4.0   memory length: 228794   epsilon: 0.872492950002768    steps: 352     evaluation reward: 2.27\n",
      "episode: 1207   score: 0.0   memory length: 228928   epsilon: 0.8723602900027709    steps: 134     evaluation reward: 2.27\n",
      "episode: 1208   score: 2.0   memory length: 229158   epsilon: 0.8721325900027759    steps: 230     evaluation reward: 2.29\n",
      "episode: 1209   score: 5.0   memory length: 229475   epsilon: 0.8718187600027827    steps: 317     evaluation reward: 2.33\n",
      "episode: 1210   score: 2.0   memory length: 229694   epsilon: 0.8716019500027874    steps: 219     evaluation reward: 2.35\n",
      "episode: 1211   score: 4.0   memory length: 229987   epsilon: 0.8713118800027937    steps: 293     evaluation reward: 2.35\n",
      "episode: 1212   score: 11.0   memory length: 230577   epsilon: 0.8707277800028064    steps: 590     evaluation reward: 2.45\n",
      "episode: 1213   score: 2.0   memory length: 230797   epsilon: 0.8705099800028111    steps: 220     evaluation reward: 2.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1214   score: 5.0   memory length: 231091   epsilon: 0.8702189200028174    steps: 294     evaluation reward: 2.48\n",
      "episode: 1215   score: 6.0   memory length: 231473   epsilon: 0.8698407400028256    steps: 382     evaluation reward: 2.53\n",
      "episode: 1216   score: 4.0   memory length: 231757   epsilon: 0.8695595800028317    steps: 284     evaluation reward: 2.57\n",
      "episode: 1217   score: 3.0   memory length: 232002   epsilon: 0.869317030002837    steps: 245     evaluation reward: 2.57\n",
      "episode: 1218   score: 3.0   memory length: 232244   epsilon: 0.8690774500028422    steps: 242     evaluation reward: 2.6\n",
      "episode: 1219   score: 3.0   memory length: 232484   epsilon: 0.8688398500028474    steps: 240     evaluation reward: 2.62\n",
      "episode: 1220   score: 0.0   memory length: 232618   epsilon: 0.8687071900028502    steps: 134     evaluation reward: 2.59\n",
      "episode: 1221   score: 0.0   memory length: 232743   epsilon: 0.8685834400028529    steps: 125     evaluation reward: 2.59\n",
      "episode: 1222   score: 1.0   memory length: 232898   epsilon: 0.8684299900028563    steps: 155     evaluation reward: 2.59\n",
      "episode: 1223   score: 2.0   memory length: 233106   epsilon: 0.8682240700028607    steps: 208     evaluation reward: 2.53\n",
      "episode: 1224   score: 0.0   memory length: 233265   epsilon: 0.8680666600028641    steps: 159     evaluation reward: 2.52\n",
      "episode: 1225   score: 1.0   memory length: 233423   epsilon: 0.8679102400028675    steps: 158     evaluation reward: 2.53\n",
      "episode: 1226   score: 3.0   memory length: 233688   epsilon: 0.8676478900028732    steps: 265     evaluation reward: 2.54\n",
      "episode: 1227   score: 1.0   memory length: 233868   epsilon: 0.8674696900028771    steps: 180     evaluation reward: 2.52\n",
      "episode: 1228   score: 2.0   memory length: 234074   epsilon: 0.8672657500028815    steps: 206     evaluation reward: 2.5\n",
      "episode: 1229   score: 3.0   memory length: 234307   epsilon: 0.8670350800028865    steps: 233     evaluation reward: 2.5\n",
      "episode: 1230   score: 1.0   memory length: 234469   epsilon: 0.86687470000289    steps: 162     evaluation reward: 2.49\n",
      "episode: 1231   score: 2.0   memory length: 234681   epsilon: 0.8666648200028946    steps: 212     evaluation reward: 2.5\n",
      "episode: 1232   score: 1.0   memory length: 234850   epsilon: 0.8664975100028982    steps: 169     evaluation reward: 2.5\n",
      "episode: 1233   score: 3.0   memory length: 235073   epsilon: 0.866276740002903    steps: 223     evaluation reward: 2.5\n",
      "episode: 1234   score: 2.0   memory length: 235286   epsilon: 0.8660658700029076    steps: 213     evaluation reward: 2.49\n",
      "episode: 1235   score: 2.0   memory length: 235495   epsilon: 0.8658589600029121    steps: 209     evaluation reward: 2.47\n",
      "episode: 1236   score: 3.0   memory length: 235722   epsilon: 0.865634230002917    steps: 227     evaluation reward: 2.5\n",
      "episode: 1237   score: 2.0   memory length: 235916   epsilon: 0.8654421700029211    steps: 194     evaluation reward: 2.5\n",
      "episode: 1238   score: 2.0   memory length: 236138   epsilon: 0.8652223900029259    steps: 222     evaluation reward: 2.5\n",
      "episode: 1239   score: 5.0   memory length: 236491   epsilon: 0.8648729200029335    steps: 353     evaluation reward: 2.54\n",
      "episode: 1240   score: 1.0   memory length: 236654   epsilon: 0.864711550002937    steps: 163     evaluation reward: 2.52\n",
      "episode: 1241   score: 3.0   memory length: 236886   epsilon: 0.864481870002942    steps: 232     evaluation reward: 2.54\n",
      "episode: 1242   score: 5.0   memory length: 237197   epsilon: 0.8641739800029486    steps: 311     evaluation reward: 2.58\n",
      "episode: 1243   score: 2.0   memory length: 237405   epsilon: 0.8639680600029531    steps: 208     evaluation reward: 2.59\n",
      "episode: 1244   score: 1.0   memory length: 237558   epsilon: 0.8638165900029564    steps: 153     evaluation reward: 2.56\n",
      "episode: 1245   score: 2.0   memory length: 237757   epsilon: 0.8636195800029607    steps: 199     evaluation reward: 2.58\n",
      "episode: 1246   score: 3.0   memory length: 238001   epsilon: 0.8633780200029659    steps: 244     evaluation reward: 2.58\n",
      "episode: 1247   score: 1.0   memory length: 238159   epsilon: 0.8632216000029693    steps: 158     evaluation reward: 2.56\n",
      "episode: 1248   score: 5.0   memory length: 238506   epsilon: 0.8628780700029768    steps: 347     evaluation reward: 2.59\n",
      "episode: 1249   score: 6.0   memory length: 238874   epsilon: 0.8625137500029847    steps: 368     evaluation reward: 2.6\n",
      "episode: 1250   score: 0.0   memory length: 239005   epsilon: 0.8623840600029875    steps: 131     evaluation reward: 2.58\n",
      "episode: 1251   score: 5.0   memory length: 239321   epsilon: 0.8620712200029943    steps: 316     evaluation reward: 2.61\n",
      "episode: 1252   score: 3.0   memory length: 239565   epsilon: 0.8618296600029995    steps: 244     evaluation reward: 2.62\n",
      "episode: 1253   score: 2.0   memory length: 239781   epsilon: 0.8616158200030042    steps: 216     evaluation reward: 2.61\n",
      "episode: 1254   score: 0.0   memory length: 239906   epsilon: 0.8614920700030069    steps: 125     evaluation reward: 2.55\n",
      "episode: 1255   score: 2.0   memory length: 240109   epsilon: 0.8612911000030112    steps: 203     evaluation reward: 2.56\n",
      "episode: 1256   score: 5.0   memory length: 240472   epsilon: 0.860931730003019    steps: 363     evaluation reward: 2.55\n",
      "episode: 1257   score: 1.0   memory length: 240638   epsilon: 0.8607673900030226    steps: 166     evaluation reward: 2.52\n",
      "episode: 1258   score: 6.0   memory length: 241036   epsilon: 0.8603733700030312    steps: 398     evaluation reward: 2.57\n",
      "episode: 1259   score: 1.0   memory length: 241212   epsilon: 0.8601991300030349    steps: 176     evaluation reward: 2.55\n",
      "episode: 1260   score: 3.0   memory length: 241443   epsilon: 0.8599704400030399    steps: 231     evaluation reward: 2.57\n",
      "episode: 1261   score: 1.0   memory length: 241617   epsilon: 0.8597981800030436    steps: 174     evaluation reward: 2.55\n",
      "episode: 1262   score: 5.0   memory length: 241937   epsilon: 0.8594813800030505    steps: 320     evaluation reward: 2.58\n",
      "episode: 1263   score: 1.0   memory length: 242093   epsilon: 0.8593269400030539    steps: 156     evaluation reward: 2.53\n",
      "episode: 1264   score: 4.0   memory length: 242410   epsilon: 0.8590131100030607    steps: 317     evaluation reward: 2.55\n",
      "episode: 1265   score: 5.0   memory length: 242738   epsilon: 0.8586883900030677    steps: 328     evaluation reward: 2.59\n",
      "episode: 1266   score: 5.0   memory length: 243052   epsilon: 0.8583775300030745    steps: 314     evaluation reward: 2.59\n",
      "episode: 1267   score: 5.0   memory length: 243377   epsilon: 0.8580557800030815    steps: 325     evaluation reward: 2.63\n",
      "episode: 1268   score: 2.0   memory length: 243610   epsilon: 0.8578251100030865    steps: 233     evaluation reward: 2.64\n",
      "episode: 1269   score: 5.0   memory length: 243943   epsilon: 0.8574954400030936    steps: 333     evaluation reward: 2.68\n",
      "episode: 1270   score: 6.0   memory length: 244305   epsilon: 0.8571370600031014    steps: 362     evaluation reward: 2.71\n",
      "episode: 1271   score: 1.0   memory length: 244470   epsilon: 0.856973710003105    steps: 165     evaluation reward: 2.71\n",
      "episode: 1272   score: 2.0   memory length: 244671   epsilon: 0.8567747200031093    steps: 201     evaluation reward: 2.68\n",
      "episode: 1273   score: 3.0   memory length: 244933   epsilon: 0.8565153400031149    steps: 262     evaluation reward: 2.68\n",
      "episode: 1274   score: 5.0   memory length: 245253   epsilon: 0.8561985400031218    steps: 320     evaluation reward: 2.66\n",
      "episode: 1275   score: 4.0   memory length: 245554   epsilon: 0.8559005500031283    steps: 301     evaluation reward: 2.69\n",
      "episode: 1276   score: 5.0   memory length: 245880   epsilon: 0.8555778100031353    steps: 326     evaluation reward: 2.71\n",
      "episode: 1277   score: 1.0   memory length: 246059   epsilon: 0.8554006000031391    steps: 179     evaluation reward: 2.66\n",
      "episode: 1278   score: 5.0   memory length: 246410   epsilon: 0.8550531100031467    steps: 351     evaluation reward: 2.7\n",
      "episode: 1279   score: 2.0   memory length: 246612   epsilon: 0.854853130003151    steps: 202     evaluation reward: 2.72\n",
      "episode: 1280   score: 2.0   memory length: 246806   epsilon: 0.8546610700031552    steps: 194     evaluation reward: 2.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1281   score: 2.0   memory length: 247017   epsilon: 0.8544521800031597    steps: 211     evaluation reward: 2.66\n",
      "episode: 1282   score: 3.0   memory length: 247258   epsilon: 0.8542135900031649    steps: 241     evaluation reward: 2.69\n",
      "episode: 1283   score: 3.0   memory length: 247528   epsilon: 0.8539462900031707    steps: 270     evaluation reward: 2.7\n",
      "episode: 1284   score: 8.0   memory length: 247978   epsilon: 0.8535007900031804    steps: 450     evaluation reward: 2.78\n",
      "episode: 1285   score: 0.0   memory length: 248124   epsilon: 0.8533562500031835    steps: 146     evaluation reward: 2.77\n",
      "episode: 1286   score: 8.0   memory length: 248536   epsilon: 0.8529483700031923    steps: 412     evaluation reward: 2.82\n",
      "episode: 1287   score: 1.0   memory length: 248697   epsilon: 0.8527889800031958    steps: 161     evaluation reward: 2.83\n",
      "episode: 1288   score: 5.0   memory length: 249036   epsilon: 0.8524533700032031    steps: 339     evaluation reward: 2.87\n",
      "episode: 1289   score: 5.0   memory length: 249346   epsilon: 0.8521464700032098    steps: 310     evaluation reward: 2.91\n",
      "episode: 1290   score: 2.0   memory length: 249556   epsilon: 0.8519385700032143    steps: 210     evaluation reward: 2.9\n",
      "episode: 1291   score: 1.0   memory length: 249726   epsilon: 0.8517702700032179    steps: 170     evaluation reward: 2.87\n",
      "episode: 1292   score: 3.0   memory length: 249975   epsilon: 0.8515237600032233    steps: 249     evaluation reward: 2.9\n",
      "now time :  2018-12-19 02:24:26.227808\n",
      "episode: 1293   score: 1.0   memory length: 250134   epsilon: 0.8513663500032267    steps: 159     evaluation reward: 2.9\n",
      "episode: 1294   score: 2.0   memory length: 250352   epsilon: 0.8511505300032314    steps: 218     evaluation reward: 2.89\n",
      "episode: 1295   score: 2.0   memory length: 250538   epsilon: 0.8509663900032354    steps: 186     evaluation reward: 2.86\n",
      "episode: 1296   score: 4.0   memory length: 250789   epsilon: 0.8507179000032408    steps: 251     evaluation reward: 2.88\n",
      "episode: 1297   score: 1.0   memory length: 250942   epsilon: 0.8505664300032441    steps: 153     evaluation reward: 2.82\n",
      "episode: 1298   score: 9.0   memory length: 251447   epsilon: 0.8500664800032549    steps: 505     evaluation reward: 2.88\n",
      "episode: 1299   score: 1.0   memory length: 251604   epsilon: 0.8499110500032583    steps: 157     evaluation reward: 2.88\n",
      "episode: 1300   score: 1.0   memory length: 251788   epsilon: 0.8497288900032622    steps: 184     evaluation reward: 2.87\n",
      "episode: 1301   score: 0.0   memory length: 251925   epsilon: 0.8495932600032652    steps: 137     evaluation reward: 2.87\n",
      "episode: 1302   score: 3.0   memory length: 252193   epsilon: 0.8493279400032709    steps: 268     evaluation reward: 2.9\n",
      "episode: 1303   score: 3.0   memory length: 252461   epsilon: 0.8490626200032767    steps: 268     evaluation reward: 2.93\n",
      "episode: 1304   score: 2.0   memory length: 252663   epsilon: 0.848862640003281    steps: 202     evaluation reward: 2.88\n",
      "episode: 1305   score: 2.0   memory length: 252868   epsilon: 0.8486596900032854    steps: 205     evaluation reward: 2.88\n",
      "episode: 1306   score: 4.0   memory length: 253151   epsilon: 0.8483795200032915    steps: 283     evaluation reward: 2.88\n",
      "episode: 1307   score: 5.0   memory length: 253477   epsilon: 0.8480567800032985    steps: 326     evaluation reward: 2.93\n",
      "episode: 1308   score: 1.0   memory length: 253646   epsilon: 0.8478894700033022    steps: 169     evaluation reward: 2.92\n",
      "episode: 1309   score: 3.0   memory length: 253898   epsilon: 0.8476399900033076    steps: 252     evaluation reward: 2.9\n",
      "episode: 1310   score: 2.0   memory length: 254096   epsilon: 0.8474439700033118    steps: 198     evaluation reward: 2.9\n",
      "episode: 1311   score: 4.0   memory length: 254375   epsilon: 0.8471677600033178    steps: 279     evaluation reward: 2.9\n",
      "episode: 1312   score: 8.0   memory length: 254856   epsilon: 0.8466915700033282    steps: 481     evaluation reward: 2.87\n",
      "episode: 1313   score: 4.0   memory length: 255124   epsilon: 0.8464262500033339    steps: 268     evaluation reward: 2.89\n",
      "episode: 1314   score: 2.0   memory length: 255331   epsilon: 0.8462213200033384    steps: 207     evaluation reward: 2.86\n",
      "episode: 1315   score: 3.0   memory length: 255602   epsilon: 0.8459530300033442    steps: 271     evaluation reward: 2.83\n",
      "episode: 1316   score: 3.0   memory length: 255854   epsilon: 0.8457035500033496    steps: 252     evaluation reward: 2.82\n",
      "episode: 1317   score: 6.0   memory length: 256214   epsilon: 0.8453471500033574    steps: 360     evaluation reward: 2.85\n",
      "episode: 1318   score: 1.0   memory length: 256377   epsilon: 0.8451857800033609    steps: 163     evaluation reward: 2.83\n",
      "episode: 1319   score: 5.0   memory length: 256677   epsilon: 0.8448887800033673    steps: 300     evaluation reward: 2.85\n",
      "episode: 1320   score: 8.0   memory length: 256980   epsilon: 0.8445888100033738    steps: 303     evaluation reward: 2.93\n",
      "episode: 1321   score: 1.0   memory length: 257144   epsilon: 0.8444264500033773    steps: 164     evaluation reward: 2.94\n",
      "episode: 1322   score: 4.0   memory length: 257431   epsilon: 0.8441423200033835    steps: 287     evaluation reward: 2.97\n",
      "episode: 1323   score: 3.0   memory length: 257673   epsilon: 0.8439027400033887    steps: 242     evaluation reward: 2.98\n",
      "episode: 1324   score: 5.0   memory length: 257991   epsilon: 0.8435879200033956    steps: 318     evaluation reward: 3.03\n",
      "episode: 1325   score: 3.0   memory length: 258214   epsilon: 0.8433671500034003    steps: 223     evaluation reward: 3.05\n",
      "episode: 1326   score: 2.0   memory length: 258415   epsilon: 0.8431681600034047    steps: 201     evaluation reward: 3.04\n",
      "episode: 1327   score: 6.0   memory length: 258772   epsilon: 0.8428147300034123    steps: 357     evaluation reward: 3.09\n",
      "episode: 1328   score: 1.0   memory length: 258934   epsilon: 0.8426543500034158    steps: 162     evaluation reward: 3.08\n",
      "episode: 1329   score: 3.0   memory length: 259169   epsilon: 0.8424217000034209    steps: 235     evaluation reward: 3.08\n",
      "episode: 1330   score: 2.0   memory length: 259386   epsilon: 0.8422068700034255    steps: 217     evaluation reward: 3.09\n",
      "episode: 1331   score: 9.0   memory length: 259852   epsilon: 0.8417455300034355    steps: 466     evaluation reward: 3.16\n",
      "episode: 1332   score: 4.0   memory length: 260133   epsilon: 0.8414673400034416    steps: 281     evaluation reward: 3.19\n",
      "episode: 1333   score: 2.0   memory length: 260317   epsilon: 0.8412851800034455    steps: 184     evaluation reward: 3.18\n",
      "episode: 1334   score: 1.0   memory length: 260477   epsilon: 0.841126780003449    steps: 160     evaluation reward: 3.17\n",
      "episode: 1335   score: 5.0   memory length: 260781   epsilon: 0.8408258200034555    steps: 304     evaluation reward: 3.2\n",
      "episode: 1336   score: 4.0   memory length: 261062   epsilon: 0.8405476300034616    steps: 281     evaluation reward: 3.21\n",
      "episode: 1337   score: 3.0   memory length: 261302   epsilon: 0.8403100300034667    steps: 240     evaluation reward: 3.22\n",
      "episode: 1338   score: 6.0   memory length: 261634   epsilon: 0.8399813500034738    steps: 332     evaluation reward: 3.26\n",
      "episode: 1339   score: 3.0   memory length: 261902   epsilon: 0.8397160300034796    steps: 268     evaluation reward: 3.24\n",
      "episode: 1340   score: 3.0   memory length: 262120   epsilon: 0.8395002100034843    steps: 218     evaluation reward: 3.26\n",
      "episode: 1341   score: 2.0   memory length: 262339   epsilon: 0.839283400003489    steps: 219     evaluation reward: 3.25\n",
      "episode: 1342   score: 4.0   memory length: 262639   epsilon: 0.8389864000034954    steps: 300     evaluation reward: 3.24\n",
      "episode: 1343   score: 0.0   memory length: 262765   epsilon: 0.8388616600034982    steps: 126     evaluation reward: 3.22\n",
      "episode: 1344   score: 1.0   memory length: 262920   epsilon: 0.8387082100035015    steps: 155     evaluation reward: 3.22\n",
      "episode: 1345   score: 0.0   memory length: 263062   epsilon: 0.8385676300035045    steps: 142     evaluation reward: 3.2\n",
      "episode: 1346   score: 2.0   memory length: 263261   epsilon: 0.8383706200035088    steps: 199     evaluation reward: 3.19\n",
      "episode: 1347   score: 1.0   memory length: 263424   epsilon: 0.8382092500035123    steps: 163     evaluation reward: 3.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1348   score: 2.0   memory length: 263614   epsilon: 0.8380211500035164    steps: 190     evaluation reward: 3.16\n",
      "episode: 1349   score: 3.0   memory length: 263859   epsilon: 0.8377786000035217    steps: 245     evaluation reward: 3.13\n",
      "episode: 1350   score: 5.0   memory length: 264134   epsilon: 0.8375063500035276    steps: 275     evaluation reward: 3.18\n",
      "episode: 1351   score: 1.0   memory length: 264291   epsilon: 0.837350920003531    steps: 157     evaluation reward: 3.14\n",
      "episode: 1352   score: 5.0   memory length: 264591   epsilon: 0.8370539200035374    steps: 300     evaluation reward: 3.16\n",
      "episode: 1353   score: 1.0   memory length: 264769   epsilon: 0.8368777000035412    steps: 178     evaluation reward: 3.15\n",
      "episode: 1354   score: 2.0   memory length: 264977   epsilon: 0.8366717800035457    steps: 208     evaluation reward: 3.17\n",
      "episode: 1355   score: 3.0   memory length: 265209   epsilon: 0.8364421000035507    steps: 232     evaluation reward: 3.18\n",
      "episode: 1356   score: 1.0   memory length: 265382   epsilon: 0.8362708300035544    steps: 173     evaluation reward: 3.14\n",
      "episode: 1357   score: 2.0   memory length: 265576   epsilon: 0.8360787700035586    steps: 194     evaluation reward: 3.15\n",
      "episode: 1358   score: 1.0   memory length: 265734   epsilon: 0.835922350003562    steps: 158     evaluation reward: 3.1\n",
      "episode: 1359   score: 4.0   memory length: 266019   epsilon: 0.8356402000035681    steps: 285     evaluation reward: 3.13\n",
      "episode: 1360   score: 4.0   memory length: 266287   epsilon: 0.8353748800035738    steps: 268     evaluation reward: 3.14\n",
      "episode: 1361   score: 2.0   memory length: 266481   epsilon: 0.835182820003578    steps: 194     evaluation reward: 3.15\n",
      "episode: 1362   score: 2.0   memory length: 266668   epsilon: 0.834997690003582    steps: 187     evaluation reward: 3.12\n",
      "episode: 1363   score: 2.0   memory length: 266896   epsilon: 0.8347719700035869    steps: 228     evaluation reward: 3.13\n",
      "episode: 1364   score: 4.0   memory length: 267153   epsilon: 0.8345175400035925    steps: 257     evaluation reward: 3.13\n",
      "episode: 1365   score: 5.0   memory length: 267465   epsilon: 0.8342086600035992    steps: 312     evaluation reward: 3.13\n",
      "episode: 1366   score: 2.0   memory length: 267672   epsilon: 0.8340037300036036    steps: 207     evaluation reward: 3.1\n",
      "episode: 1367   score: 2.0   memory length: 267886   epsilon: 0.8337918700036082    steps: 214     evaluation reward: 3.07\n",
      "episode: 1368   score: 3.0   memory length: 268158   epsilon: 0.8335225900036141    steps: 272     evaluation reward: 3.08\n",
      "episode: 1369   score: 0.0   memory length: 268304   epsilon: 0.8333780500036172    steps: 146     evaluation reward: 3.03\n",
      "episode: 1370   score: 4.0   memory length: 268603   epsilon: 0.8330820400036236    steps: 299     evaluation reward: 3.01\n",
      "episode: 1371   score: 1.0   memory length: 268787   epsilon: 0.8328998800036276    steps: 184     evaluation reward: 3.01\n",
      "episode: 1372   score: 3.0   memory length: 269013   epsilon: 0.8326761400036324    steps: 226     evaluation reward: 3.02\n",
      "episode: 1373   score: 0.0   memory length: 269147   epsilon: 0.8325434800036353    steps: 134     evaluation reward: 2.99\n",
      "episode: 1374   score: 0.0   memory length: 269270   epsilon: 0.832421710003638    steps: 123     evaluation reward: 2.94\n",
      "episode: 1375   score: 1.0   memory length: 269431   epsilon: 0.8322623200036414    steps: 161     evaluation reward: 2.91\n",
      "episode: 1376   score: 3.0   memory length: 269664   epsilon: 0.8320316500036464    steps: 233     evaluation reward: 2.89\n",
      "episode: 1377   score: 4.0   memory length: 269914   epsilon: 0.8317841500036518    steps: 250     evaluation reward: 2.92\n",
      "episode: 1378   score: 1.0   memory length: 270093   epsilon: 0.8316069400036556    steps: 179     evaluation reward: 2.88\n",
      "episode: 1379   score: 1.0   memory length: 270269   epsilon: 0.8314327000036594    steps: 176     evaluation reward: 2.87\n",
      "episode: 1380   score: 3.0   memory length: 270501   epsilon: 0.8312030200036644    steps: 232     evaluation reward: 2.88\n",
      "episode: 1381   score: 1.0   memory length: 270690   epsilon: 0.8310159100036685    steps: 189     evaluation reward: 2.87\n",
      "episode: 1382   score: 4.0   memory length: 270959   epsilon: 0.8307496000036743    steps: 269     evaluation reward: 2.88\n",
      "episode: 1383   score: 3.0   memory length: 271193   epsilon: 0.8305179400036793    steps: 234     evaluation reward: 2.88\n",
      "episode: 1384   score: 4.0   memory length: 271482   epsilon: 0.8302318300036855    steps: 289     evaluation reward: 2.84\n",
      "episode: 1385   score: 5.0   memory length: 271860   epsilon: 0.8298576100036936    steps: 378     evaluation reward: 2.89\n",
      "episode: 1386   score: 4.0   memory length: 272116   epsilon: 0.8296041700036991    steps: 256     evaluation reward: 2.85\n",
      "episode: 1387   score: 3.0   memory length: 272368   epsilon: 0.8293546900037045    steps: 252     evaluation reward: 2.87\n",
      "episode: 1388   score: 5.0   memory length: 272686   epsilon: 0.8290398700037114    steps: 318     evaluation reward: 2.87\n",
      "episode: 1389   score: 3.0   memory length: 272904   epsilon: 0.8288240500037161    steps: 218     evaluation reward: 2.85\n",
      "episode: 1390   score: 2.0   memory length: 273104   epsilon: 0.8286260500037204    steps: 200     evaluation reward: 2.85\n",
      "episode: 1391   score: 4.0   memory length: 273386   epsilon: 0.8283468700037264    steps: 282     evaluation reward: 2.88\n",
      "episode: 1392   score: 4.0   memory length: 273664   epsilon: 0.8280716500037324    steps: 278     evaluation reward: 2.89\n",
      "episode: 1393   score: 6.0   memory length: 274018   epsilon: 0.82772119000374    steps: 354     evaluation reward: 2.94\n",
      "episode: 1394   score: 3.0   memory length: 274234   epsilon: 0.8275073500037446    steps: 216     evaluation reward: 2.95\n",
      "episode: 1395   score: 2.0   memory length: 274480   epsilon: 0.8272638100037499    steps: 246     evaluation reward: 2.95\n",
      "episode: 1396   score: 2.0   memory length: 274664   epsilon: 0.8270816500037539    steps: 184     evaluation reward: 2.93\n",
      "episode: 1397   score: 10.0   memory length: 275033   epsilon: 0.8267163400037618    steps: 369     evaluation reward: 3.02\n",
      "episode: 1398   score: 8.0   memory length: 275329   epsilon: 0.8264233000037682    steps: 296     evaluation reward: 3.01\n",
      "episode: 1399   score: 5.0   memory length: 275681   epsilon: 0.8260748200037757    steps: 352     evaluation reward: 3.05\n",
      "episode: 1400   score: 7.0   memory length: 276131   epsilon: 0.8256293200037854    steps: 450     evaluation reward: 3.11\n",
      "episode: 1401   score: 2.0   memory length: 276336   epsilon: 0.8254263700037898    steps: 205     evaluation reward: 3.13\n",
      "episode: 1402   score: 1.0   memory length: 276522   epsilon: 0.8252422300037938    steps: 186     evaluation reward: 3.11\n",
      "episode: 1403   score: 5.0   memory length: 276847   epsilon: 0.8249204800038008    steps: 325     evaluation reward: 3.13\n",
      "episode: 1404   score: 5.0   memory length: 277148   epsilon: 0.8246224900038073    steps: 301     evaluation reward: 3.16\n",
      "episode: 1405   score: 4.0   memory length: 277407   epsilon: 0.8243660800038128    steps: 259     evaluation reward: 3.18\n",
      "episode: 1406   score: 3.0   memory length: 277633   epsilon: 0.8241423400038177    steps: 226     evaluation reward: 3.17\n",
      "episode: 1407   score: 1.0   memory length: 277805   epsilon: 0.8239720600038214    steps: 172     evaluation reward: 3.13\n",
      "episode: 1408   score: 2.0   memory length: 278004   epsilon: 0.8237750500038257    steps: 199     evaluation reward: 3.14\n",
      "episode: 1409   score: 1.0   memory length: 278168   epsilon: 0.8236126900038292    steps: 164     evaluation reward: 3.12\n",
      "episode: 1410   score: 2.0   memory length: 278378   epsilon: 0.8234047900038337    steps: 210     evaluation reward: 3.12\n",
      "episode: 1411   score: 6.0   memory length: 278762   epsilon: 0.823024630003842    steps: 384     evaluation reward: 3.14\n",
      "episode: 1412   score: 6.0   memory length: 279096   epsilon: 0.8226939700038491    steps: 334     evaluation reward: 3.12\n",
      "episode: 1413   score: 2.0   memory length: 279318   epsilon: 0.8224741900038539    steps: 222     evaluation reward: 3.1\n",
      "episode: 1414   score: 3.0   memory length: 279553   epsilon: 0.822241540003859    steps: 235     evaluation reward: 3.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1415   score: 5.0   memory length: 279868   epsilon: 0.8219296900038657    steps: 315     evaluation reward: 3.13\n",
      "episode: 1416   score: 3.0   memory length: 280101   epsilon: 0.8216990200038707    steps: 233     evaluation reward: 3.13\n",
      "episode: 1417   score: 2.0   memory length: 280291   epsilon: 0.8215109200038748    steps: 190     evaluation reward: 3.09\n",
      "episode: 1418   score: 3.0   memory length: 280527   epsilon: 0.8212772800038799    steps: 236     evaluation reward: 3.11\n",
      "episode: 1419   score: 0.0   memory length: 280657   epsilon: 0.8211485800038827    steps: 130     evaluation reward: 3.06\n",
      "episode: 1420   score: 3.0   memory length: 280889   epsilon: 0.8209189000038877    steps: 232     evaluation reward: 3.01\n",
      "episode: 1421   score: 0.0   memory length: 281022   epsilon: 0.8207872300038905    steps: 133     evaluation reward: 3.0\n",
      "episode: 1422   score: 5.0   memory length: 281305   epsilon: 0.8205070600038966    steps: 283     evaluation reward: 3.01\n",
      "episode: 1423   score: 5.0   memory length: 281606   epsilon: 0.8202090700039031    steps: 301     evaluation reward: 3.03\n",
      "episode: 1424   score: 1.0   memory length: 281766   epsilon: 0.8200506700039065    steps: 160     evaluation reward: 2.99\n",
      "episode: 1425   score: 3.0   memory length: 281999   epsilon: 0.8198200000039115    steps: 233     evaluation reward: 2.99\n",
      "episode: 1426   score: 1.0   memory length: 282157   epsilon: 0.8196635800039149    steps: 158     evaluation reward: 2.98\n",
      "episode: 1427   score: 1.0   memory length: 282334   epsilon: 0.8194883500039187    steps: 177     evaluation reward: 2.93\n",
      "episode: 1428   score: 2.0   memory length: 282520   epsilon: 0.8193042100039227    steps: 186     evaluation reward: 2.94\n",
      "episode: 1429   score: 3.0   memory length: 282787   epsilon: 0.8190398800039285    steps: 267     evaluation reward: 2.94\n",
      "episode: 1430   score: 4.0   memory length: 283071   epsilon: 0.8187587200039346    steps: 284     evaluation reward: 2.96\n",
      "episode: 1431   score: 4.0   memory length: 283361   epsilon: 0.8184716200039408    steps: 290     evaluation reward: 2.91\n",
      "episode: 1432   score: 4.0   memory length: 283661   epsilon: 0.8181746200039473    steps: 300     evaluation reward: 2.91\n",
      "episode: 1433   score: 3.0   memory length: 283880   epsilon: 0.817957810003952    steps: 219     evaluation reward: 2.92\n",
      "episode: 1434   score: 4.0   memory length: 284132   epsilon: 0.8177083300039574    steps: 252     evaluation reward: 2.95\n",
      "episode: 1435   score: 3.0   memory length: 284381   epsilon: 0.8174618200039627    steps: 249     evaluation reward: 2.93\n",
      "episode: 1436   score: 4.0   memory length: 284633   epsilon: 0.8172123400039681    steps: 252     evaluation reward: 2.93\n",
      "episode: 1437   score: 1.0   memory length: 284806   epsilon: 0.8170410700039719    steps: 173     evaluation reward: 2.91\n",
      "episode: 1438   score: 1.0   memory length: 284969   epsilon: 0.8168797000039754    steps: 163     evaluation reward: 2.86\n",
      "episode: 1439   score: 2.0   memory length: 285186   epsilon: 0.81666487000398    steps: 217     evaluation reward: 2.85\n",
      "episode: 1440   score: 4.0   memory length: 285457   epsilon: 0.8163965800039859    steps: 271     evaluation reward: 2.86\n",
      "episode: 1441   score: 7.0   memory length: 285885   epsilon: 0.815972860003995    steps: 428     evaluation reward: 2.91\n",
      "episode: 1442   score: 4.0   memory length: 286146   epsilon: 0.8157144700040007    steps: 261     evaluation reward: 2.91\n",
      "episode: 1443   score: 3.0   memory length: 286419   epsilon: 0.8154442000040065    steps: 273     evaluation reward: 2.94\n",
      "episode: 1444   score: 13.0   memory length: 286941   epsilon: 0.8149274200040177    steps: 522     evaluation reward: 3.06\n",
      "episode: 1445   score: 0.0   memory length: 287069   epsilon: 0.8148007000040205    steps: 128     evaluation reward: 3.06\n",
      "episode: 1446   score: 0.0   memory length: 287200   epsilon: 0.8146710100040233    steps: 131     evaluation reward: 3.04\n",
      "episode: 1447   score: 2.0   memory length: 287399   epsilon: 0.8144740000040276    steps: 199     evaluation reward: 3.05\n",
      "episode: 1448   score: 3.0   memory length: 287650   epsilon: 0.814225510004033    steps: 251     evaluation reward: 3.06\n",
      "episode: 1449   score: 2.0   memory length: 287857   epsilon: 0.8140205800040374    steps: 207     evaluation reward: 3.05\n",
      "episode: 1450   score: 3.0   memory length: 288095   epsilon: 0.8137849600040425    steps: 238     evaluation reward: 3.03\n",
      "episode: 1451   score: 5.0   memory length: 288385   epsilon: 0.8134978600040488    steps: 290     evaluation reward: 3.07\n",
      "episode: 1452   score: 2.0   memory length: 288576   epsilon: 0.8133087700040529    steps: 191     evaluation reward: 3.04\n",
      "episode: 1453   score: 3.0   memory length: 288798   epsilon: 0.8130889900040577    steps: 222     evaluation reward: 3.06\n",
      "episode: 1454   score: 4.0   memory length: 289107   epsilon: 0.8127830800040643    steps: 309     evaluation reward: 3.08\n",
      "episode: 1455   score: 2.0   memory length: 289334   epsilon: 0.8125583500040692    steps: 227     evaluation reward: 3.07\n",
      "episode: 1456   score: 5.0   memory length: 289681   epsilon: 0.8122148200040766    steps: 347     evaluation reward: 3.11\n",
      "episode: 1457   score: 2.0   memory length: 289879   epsilon: 0.8120188000040809    steps: 198     evaluation reward: 3.11\n",
      "episode: 1458   score: 0.0   memory length: 290011   epsilon: 0.8118881200040837    steps: 132     evaluation reward: 3.1\n",
      "episode: 1459   score: 3.0   memory length: 290272   epsilon: 0.8116297300040893    steps: 261     evaluation reward: 3.09\n",
      "episode: 1460   score: 9.0   memory length: 290744   epsilon: 0.8111624500040995    steps: 472     evaluation reward: 3.14\n",
      "episode: 1461   score: 8.0   memory length: 291057   epsilon: 0.8108525800041062    steps: 313     evaluation reward: 3.2\n",
      "episode: 1462   score: 3.0   memory length: 291322   epsilon: 0.8105902300041119    steps: 265     evaluation reward: 3.21\n",
      "episode: 1463   score: 2.0   memory length: 291506   epsilon: 0.8104080700041159    steps: 184     evaluation reward: 3.21\n",
      "episode: 1464   score: 3.0   memory length: 291726   epsilon: 0.8101902700041206    steps: 220     evaluation reward: 3.2\n",
      "episode: 1465   score: 1.0   memory length: 291886   epsilon: 0.810031870004124    steps: 160     evaluation reward: 3.16\n",
      "episode: 1466   score: 4.0   memory length: 292143   epsilon: 0.8097774400041295    steps: 257     evaluation reward: 3.18\n",
      "episode: 1467   score: 4.0   memory length: 292408   epsilon: 0.8095150900041352    steps: 265     evaluation reward: 3.2\n",
      "episode: 1468   score: 1.0   memory length: 292578   epsilon: 0.8093467900041389    steps: 170     evaluation reward: 3.18\n",
      "episode: 1469   score: 1.0   memory length: 292750   epsilon: 0.8091765100041426    steps: 172     evaluation reward: 3.19\n",
      "episode: 1470   score: 2.0   memory length: 292932   epsilon: 0.8089963300041465    steps: 182     evaluation reward: 3.17\n",
      "episode: 1471   score: 5.0   memory length: 293257   epsilon: 0.8086745800041535    steps: 325     evaluation reward: 3.21\n",
      "episode: 1472   score: 8.0   memory length: 293683   epsilon: 0.8082528400041626    steps: 426     evaluation reward: 3.26\n",
      "episode: 1473   score: 2.0   memory length: 293897   epsilon: 0.8080409800041672    steps: 214     evaluation reward: 3.28\n",
      "episode: 1474   score: 1.0   memory length: 294084   epsilon: 0.8078558500041713    steps: 187     evaluation reward: 3.29\n",
      "episode: 1475   score: 2.0   memory length: 294290   epsilon: 0.8076519100041757    steps: 206     evaluation reward: 3.3\n",
      "episode: 1476   score: 5.0   memory length: 294620   epsilon: 0.8073252100041828    steps: 330     evaluation reward: 3.32\n",
      "episode: 1477   score: 8.0   memory length: 295102   epsilon: 0.8068480300041931    steps: 482     evaluation reward: 3.36\n",
      "episode: 1478   score: 2.0   memory length: 295316   epsilon: 0.8066361700041977    steps: 214     evaluation reward: 3.37\n",
      "episode: 1479   score: 4.0   memory length: 295586   epsilon: 0.8063688700042035    steps: 270     evaluation reward: 3.4\n",
      "episode: 1480   score: 2.0   memory length: 295800   epsilon: 0.8061570100042081    steps: 214     evaluation reward: 3.39\n",
      "episode: 1481   score: 2.0   memory length: 296018   epsilon: 0.8059411900042128    steps: 218     evaluation reward: 3.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1482   score: 6.0   memory length: 296404   epsilon: 0.8055590500042211    steps: 386     evaluation reward: 3.42\n",
      "episode: 1483   score: 5.0   memory length: 296723   epsilon: 0.805243240004228    steps: 319     evaluation reward: 3.44\n",
      "episode: 1484   score: 4.0   memory length: 296988   epsilon: 0.8049808900042337    steps: 265     evaluation reward: 3.44\n",
      "episode: 1485   score: 0.0   memory length: 297117   epsilon: 0.8048531800042364    steps: 129     evaluation reward: 3.39\n",
      "episode: 1486   score: 1.0   memory length: 297275   epsilon: 0.8046967600042398    steps: 158     evaluation reward: 3.36\n",
      "episode: 1487   score: 7.0   memory length: 297610   epsilon: 0.804365110004247    steps: 335     evaluation reward: 3.4\n",
      "episode: 1488   score: 6.0   memory length: 297993   epsilon: 0.8039859400042553    steps: 383     evaluation reward: 3.41\n",
      "episode: 1489   score: 4.0   memory length: 298263   epsilon: 0.8037186400042611    steps: 270     evaluation reward: 3.42\n",
      "episode: 1490   score: 9.0   memory length: 298587   epsilon: 0.803397880004268    steps: 324     evaluation reward: 3.49\n",
      "episode: 1491   score: 0.0   memory length: 298716   epsilon: 0.8032701700042708    steps: 129     evaluation reward: 3.45\n",
      "episode: 1492   score: 0.0   memory length: 298848   epsilon: 0.8031394900042736    steps: 132     evaluation reward: 3.41\n",
      "episode: 1493   score: 5.0   memory length: 299149   epsilon: 0.8028415000042801    steps: 301     evaluation reward: 3.4\n",
      "episode: 1494   score: 3.0   memory length: 299391   epsilon: 0.8026019200042853    steps: 242     evaluation reward: 3.4\n",
      "episode: 1495   score: 4.0   memory length: 299675   epsilon: 0.8023207600042914    steps: 284     evaluation reward: 3.42\n",
      "episode: 1496   score: 1.0   memory length: 299835   epsilon: 0.8021623600042949    steps: 160     evaluation reward: 3.41\n",
      "now time :  2018-12-19 02:41:03.534552\n",
      "episode: 1497   score: 7.0   memory length: 300226   epsilon: 0.8017752700043033    steps: 391     evaluation reward: 3.38\n",
      "episode: 1498   score: 2.0   memory length: 300430   epsilon: 0.8015733100043076    steps: 204     evaluation reward: 3.32\n",
      "episode: 1499   score: 3.0   memory length: 300666   epsilon: 0.8013396700043127    steps: 236     evaluation reward: 3.3\n",
      "episode: 1500   score: 11.0   memory length: 301096   epsilon: 0.800913970004322    steps: 430     evaluation reward: 3.34\n",
      "episode: 1501   score: 1.0   memory length: 301259   epsilon: 0.8007526000043255    steps: 163     evaluation reward: 3.33\n",
      "episode: 1502   score: 5.0   memory length: 301595   epsilon: 0.8004199600043327    steps: 336     evaluation reward: 3.37\n",
      "episode: 1503   score: 0.0   memory length: 301729   epsilon: 0.8002873000043356    steps: 134     evaluation reward: 3.32\n",
      "episode: 1504   score: 1.0   memory length: 301899   epsilon: 0.8001190000043392    steps: 170     evaluation reward: 3.28\n",
      "episode: 1505   score: 5.0   memory length: 302215   epsilon: 0.799806160004346    steps: 316     evaluation reward: 3.29\n",
      "episode: 1506   score: 9.0   memory length: 302567   epsilon: 0.7994576800043536    steps: 352     evaluation reward: 3.35\n",
      "episode: 1507   score: 2.0   memory length: 302753   epsilon: 0.7992735400043576    steps: 186     evaluation reward: 3.36\n",
      "episode: 1508   score: 3.0   memory length: 303007   epsilon: 0.799022080004363    steps: 254     evaluation reward: 3.37\n",
      "episode: 1509   score: 0.0   memory length: 303139   epsilon: 0.7988914000043659    steps: 132     evaluation reward: 3.36\n",
      "episode: 1510   score: 5.0   memory length: 303461   epsilon: 0.7985726200043728    steps: 322     evaluation reward: 3.39\n",
      "episode: 1511   score: 2.0   memory length: 303648   epsilon: 0.7983874900043768    steps: 187     evaluation reward: 3.35\n",
      "episode: 1512   score: 0.0   memory length: 303784   epsilon: 0.7982528500043797    steps: 136     evaluation reward: 3.29\n",
      "episode: 1513   score: 1.0   memory length: 303943   epsilon: 0.7980954400043831    steps: 159     evaluation reward: 3.28\n",
      "episode: 1514   score: 3.0   memory length: 304169   epsilon: 0.797871700004388    steps: 226     evaluation reward: 3.28\n",
      "episode: 1515   score: 2.0   memory length: 304373   epsilon: 0.7976697400043924    steps: 204     evaluation reward: 3.25\n",
      "episode: 1516   score: 9.0   memory length: 304844   epsilon: 0.7972034500044025    steps: 471     evaluation reward: 3.31\n",
      "episode: 1517   score: 3.0   memory length: 305069   epsilon: 0.7969807000044073    steps: 225     evaluation reward: 3.32\n",
      "episode: 1518   score: 3.0   memory length: 305297   epsilon: 0.7967549800044122    steps: 228     evaluation reward: 3.32\n",
      "episode: 1519   score: 8.0   memory length: 305740   epsilon: 0.7963164100044218    steps: 443     evaluation reward: 3.4\n",
      "episode: 1520   score: 6.0   memory length: 306099   epsilon: 0.7959610000044295    steps: 359     evaluation reward: 3.43\n",
      "episode: 1521   score: 7.0   memory length: 306500   epsilon: 0.7955640100044381    steps: 401     evaluation reward: 3.5\n",
      "episode: 1522   score: 0.0   memory length: 306641   epsilon: 0.7954244200044411    steps: 141     evaluation reward: 3.45\n",
      "episode: 1523   score: 4.0   memory length: 306946   epsilon: 0.7951224700044477    steps: 305     evaluation reward: 3.44\n",
      "episode: 1524   score: 4.0   memory length: 307223   epsilon: 0.7948482400044536    steps: 277     evaluation reward: 3.47\n",
      "episode: 1525   score: 2.0   memory length: 307415   epsilon: 0.7946581600044578    steps: 192     evaluation reward: 3.46\n",
      "episode: 1526   score: 6.0   memory length: 307764   epsilon: 0.7943126500044653    steps: 349     evaluation reward: 3.51\n",
      "episode: 1527   score: 2.0   memory length: 307977   epsilon: 0.7941017800044698    steps: 213     evaluation reward: 3.52\n",
      "episode: 1528   score: 2.0   memory length: 308170   epsilon: 0.793910710004474    steps: 193     evaluation reward: 3.52\n",
      "episode: 1529   score: 1.0   memory length: 308350   epsilon: 0.7937325100044779    steps: 180     evaluation reward: 3.5\n",
      "episode: 1530   score: 4.0   memory length: 308622   epsilon: 0.7934632300044837    steps: 272     evaluation reward: 3.5\n",
      "episode: 1531   score: 3.0   memory length: 308859   epsilon: 0.7932286000044888    steps: 237     evaluation reward: 3.49\n",
      "episode: 1532   score: 3.0   memory length: 309095   epsilon: 0.7929949600044939    steps: 236     evaluation reward: 3.48\n",
      "episode: 1533   score: 4.0   memory length: 309365   epsilon: 0.7927276600044997    steps: 270     evaluation reward: 3.49\n",
      "episode: 1534   score: 4.0   memory length: 309636   epsilon: 0.7924593700045055    steps: 271     evaluation reward: 3.49\n",
      "episode: 1535   score: 3.0   memory length: 309908   epsilon: 0.7921900900045113    steps: 272     evaluation reward: 3.49\n",
      "episode: 1536   score: 2.0   memory length: 310098   epsilon: 0.7920019900045154    steps: 190     evaluation reward: 3.47\n",
      "episode: 1537   score: 1.0   memory length: 310261   epsilon: 0.7918406200045189    steps: 163     evaluation reward: 3.47\n",
      "episode: 1538   score: 3.0   memory length: 310478   epsilon: 0.7916257900045236    steps: 217     evaluation reward: 3.49\n",
      "episode: 1539   score: 7.0   memory length: 310884   epsilon: 0.7912238500045323    steps: 406     evaluation reward: 3.54\n",
      "episode: 1540   score: 6.0   memory length: 311261   epsilon: 0.7908506200045404    steps: 377     evaluation reward: 3.56\n",
      "episode: 1541   score: 4.0   memory length: 311548   epsilon: 0.7905664900045466    steps: 287     evaluation reward: 3.53\n",
      "episode: 1542   score: 6.0   memory length: 311960   epsilon: 0.7901586100045555    steps: 412     evaluation reward: 3.55\n",
      "episode: 1543   score: 4.0   memory length: 312231   epsilon: 0.7898903200045613    steps: 271     evaluation reward: 3.56\n",
      "episode: 1544   score: 6.0   memory length: 312613   epsilon: 0.7895121400045695    steps: 382     evaluation reward: 3.49\n",
      "episode: 1545   score: 1.0   memory length: 312766   epsilon: 0.7893606700045728    steps: 153     evaluation reward: 3.5\n",
      "episode: 1546   score: 3.0   memory length: 312976   epsilon: 0.7891527700045773    steps: 210     evaluation reward: 3.53\n",
      "episode: 1547   score: 0.0   memory length: 313116   epsilon: 0.7890141700045803    steps: 140     evaluation reward: 3.51\n",
      "episode: 1548   score: 3.0   memory length: 313361   epsilon: 0.7887716200045856    steps: 245     evaluation reward: 3.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1549   score: 3.0   memory length: 313606   epsilon: 0.7885290700045908    steps: 245     evaluation reward: 3.52\n",
      "episode: 1550   score: 2.0   memory length: 313818   epsilon: 0.7883191900045954    steps: 212     evaluation reward: 3.51\n",
      "episode: 1551   score: 7.0   memory length: 314249   epsilon: 0.7878925000046046    steps: 431     evaluation reward: 3.53\n",
      "episode: 1552   score: 4.0   memory length: 314575   epsilon: 0.7875697600046117    steps: 326     evaluation reward: 3.55\n",
      "episode: 1553   score: 4.0   memory length: 314858   epsilon: 0.7872895900046177    steps: 283     evaluation reward: 3.56\n",
      "episode: 1554   score: 2.0   memory length: 315075   epsilon: 0.7870747600046224    steps: 217     evaluation reward: 3.54\n",
      "episode: 1555   score: 1.0   memory length: 315246   epsilon: 0.7869054700046261    steps: 171     evaluation reward: 3.53\n",
      "episode: 1556   score: 7.0   memory length: 315629   epsilon: 0.7865263000046343    steps: 383     evaluation reward: 3.55\n",
      "episode: 1557   score: 3.0   memory length: 315872   epsilon: 0.7862857300046395    steps: 243     evaluation reward: 3.56\n",
      "episode: 1558   score: 3.0   memory length: 316099   epsilon: 0.7860610000046444    steps: 227     evaluation reward: 3.59\n",
      "episode: 1559   score: 4.0   memory length: 316396   epsilon: 0.7857669700046508    steps: 297     evaluation reward: 3.6\n",
      "episode: 1560   score: 4.0   memory length: 316688   epsilon: 0.7854778900046571    steps: 292     evaluation reward: 3.55\n",
      "episode: 1561   score: 0.0   memory length: 316825   epsilon: 0.78534226000466    steps: 137     evaluation reward: 3.47\n",
      "episode: 1562   score: 1.0   memory length: 317012   epsilon: 0.785157130004664    steps: 187     evaluation reward: 3.45\n",
      "episode: 1563   score: 4.0   memory length: 317332   epsilon: 0.7848403300046709    steps: 320     evaluation reward: 3.47\n",
      "episode: 1564   score: 4.0   memory length: 317612   epsilon: 0.7845631300046769    steps: 280     evaluation reward: 3.48\n",
      "episode: 1565   score: 4.0   memory length: 317900   epsilon: 0.7842780100046831    steps: 288     evaluation reward: 3.51\n",
      "episode: 1566   score: 3.0   memory length: 318148   epsilon: 0.7840324900046884    steps: 248     evaluation reward: 3.5\n",
      "episode: 1567   score: 3.0   memory length: 318379   epsilon: 0.7838038000046934    steps: 231     evaluation reward: 3.49\n",
      "episode: 1568   score: 3.0   memory length: 318657   epsilon: 0.7835285800046994    steps: 278     evaluation reward: 3.51\n",
      "episode: 1569   score: 5.0   memory length: 318970   epsilon: 0.7832187100047061    steps: 313     evaluation reward: 3.55\n",
      "episode: 1570   score: 1.0   memory length: 319134   epsilon: 0.7830563500047096    steps: 164     evaluation reward: 3.54\n",
      "episode: 1571   score: 7.0   memory length: 319536   epsilon: 0.7826583700047183    steps: 402     evaluation reward: 3.56\n",
      "episode: 1572   score: 2.0   memory length: 319722   epsilon: 0.7824742300047223    steps: 186     evaluation reward: 3.5\n",
      "episode: 1573   score: 0.0   memory length: 319861   epsilon: 0.7823366200047253    steps: 139     evaluation reward: 3.48\n",
      "episode: 1574   score: 5.0   memory length: 320173   epsilon: 0.782027740004732    steps: 312     evaluation reward: 3.52\n",
      "episode: 1575   score: 3.0   memory length: 320388   epsilon: 0.7818148900047366    steps: 215     evaluation reward: 3.53\n",
      "episode: 1576   score: 8.0   memory length: 320681   epsilon: 0.7815248200047429    steps: 293     evaluation reward: 3.56\n",
      "episode: 1577   score: 1.0   memory length: 320856   epsilon: 0.7813515700047466    steps: 175     evaluation reward: 3.49\n",
      "episode: 1578   score: 3.0   memory length: 321086   epsilon: 0.7811238700047516    steps: 230     evaluation reward: 3.5\n",
      "episode: 1579   score: 2.0   memory length: 321301   epsilon: 0.7809110200047562    steps: 215     evaluation reward: 3.48\n",
      "episode: 1580   score: 2.0   memory length: 321504   epsilon: 0.7807100500047606    steps: 203     evaluation reward: 3.48\n",
      "episode: 1581   score: 3.0   memory length: 321740   epsilon: 0.7804764100047656    steps: 236     evaluation reward: 3.49\n",
      "episode: 1582   score: 3.0   memory length: 321999   epsilon: 0.7802200000047712    steps: 259     evaluation reward: 3.46\n",
      "episode: 1583   score: 0.0   memory length: 322138   epsilon: 0.7800823900047742    steps: 139     evaluation reward: 3.41\n",
      "episode: 1584   score: 5.0   memory length: 322457   epsilon: 0.779766580004781    steps: 319     evaluation reward: 3.42\n",
      "episode: 1585   score: 6.0   memory length: 322821   epsilon: 0.7794062200047889    steps: 364     evaluation reward: 3.48\n",
      "episode: 1586   score: 9.0   memory length: 323277   epsilon: 0.7789547800047987    steps: 456     evaluation reward: 3.56\n",
      "episode: 1587   score: 3.0   memory length: 323502   epsilon: 0.7787320300048035    steps: 225     evaluation reward: 3.52\n",
      "episode: 1588   score: 2.0   memory length: 323705   epsilon: 0.7785310600048079    steps: 203     evaluation reward: 3.48\n",
      "episode: 1589   score: 6.0   memory length: 324045   epsilon: 0.7781944600048152    steps: 340     evaluation reward: 3.5\n",
      "episode: 1590   score: 4.0   memory length: 324336   epsilon: 0.7779063700048214    steps: 291     evaluation reward: 3.45\n",
      "episode: 1591   score: 7.0   memory length: 324721   epsilon: 0.7775252200048297    steps: 385     evaluation reward: 3.52\n",
      "episode: 1592   score: 1.0   memory length: 324879   epsilon: 0.7773688000048331    steps: 158     evaluation reward: 3.53\n",
      "episode: 1593   score: 6.0   memory length: 325257   epsilon: 0.7769945800048412    steps: 378     evaluation reward: 3.54\n",
      "episode: 1594   score: 3.0   memory length: 325490   epsilon: 0.7767639100048462    steps: 233     evaluation reward: 3.54\n",
      "episode: 1595   score: 11.0   memory length: 325904   epsilon: 0.7763540500048551    steps: 414     evaluation reward: 3.61\n",
      "episode: 1596   score: 8.0   memory length: 326341   epsilon: 0.7759214200048645    steps: 437     evaluation reward: 3.68\n",
      "episode: 1597   score: 2.0   memory length: 326535   epsilon: 0.7757293600048687    steps: 194     evaluation reward: 3.63\n",
      "episode: 1598   score: 4.0   memory length: 326801   epsilon: 0.7754660200048744    steps: 266     evaluation reward: 3.65\n",
      "episode: 1599   score: 5.0   memory length: 327126   epsilon: 0.7751442700048814    steps: 325     evaluation reward: 3.67\n",
      "episode: 1600   score: 3.0   memory length: 327347   epsilon: 0.7749254800048861    steps: 221     evaluation reward: 3.59\n",
      "episode: 1601   score: 4.0   memory length: 327597   epsilon: 0.7746779800048915    steps: 250     evaluation reward: 3.62\n",
      "episode: 1602   score: 3.0   memory length: 327854   epsilon: 0.774423550004897    steps: 257     evaluation reward: 3.6\n",
      "episode: 1603   score: 2.0   memory length: 328053   epsilon: 0.7742265400049013    steps: 199     evaluation reward: 3.62\n",
      "episode: 1604   score: 4.0   memory length: 328326   epsilon: 0.7739562700049072    steps: 273     evaluation reward: 3.65\n",
      "episode: 1605   score: 3.0   memory length: 328551   epsilon: 0.773733520004912    steps: 225     evaluation reward: 3.63\n",
      "episode: 1606   score: 3.0   memory length: 328779   epsilon: 0.7735078000049169    steps: 228     evaluation reward: 3.57\n",
      "episode: 1607   score: 2.0   memory length: 328992   epsilon: 0.7732969300049215    steps: 213     evaluation reward: 3.57\n",
      "episode: 1608   score: 7.0   memory length: 329386   epsilon: 0.77290687000493    steps: 394     evaluation reward: 3.61\n",
      "episode: 1609   score: 3.0   memory length: 329638   epsilon: 0.7726573900049354    steps: 252     evaluation reward: 3.64\n",
      "episode: 1610   score: 2.0   memory length: 329849   epsilon: 0.7724485000049399    steps: 211     evaluation reward: 3.61\n",
      "episode: 1611   score: 1.0   memory length: 330010   epsilon: 0.7722891100049434    steps: 161     evaluation reward: 3.6\n",
      "episode: 1612   score: 8.0   memory length: 330465   epsilon: 0.7718386600049532    steps: 455     evaluation reward: 3.68\n",
      "episode: 1613   score: 4.0   memory length: 330726   epsilon: 0.7715802700049588    steps: 261     evaluation reward: 3.71\n",
      "episode: 1614   score: 7.0   memory length: 331082   epsilon: 0.7712278300049664    steps: 356     evaluation reward: 3.75\n",
      "episode: 1615   score: 3.0   memory length: 331301   epsilon: 0.7710110200049711    steps: 219     evaluation reward: 3.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1616   score: 7.0   memory length: 331756   epsilon: 0.7705605700049809    steps: 455     evaluation reward: 3.74\n",
      "episode: 1617   score: 7.0   memory length: 332163   epsilon: 0.7701576400049897    steps: 407     evaluation reward: 3.78\n",
      "episode: 1618   score: 2.0   memory length: 332355   epsilon: 0.7699675600049938    steps: 192     evaluation reward: 3.77\n",
      "episode: 1619   score: 4.0   memory length: 332646   epsilon: 0.769679470005    steps: 291     evaluation reward: 3.73\n",
      "episode: 1620   score: 4.0   memory length: 332948   epsilon: 0.7693804900050065    steps: 302     evaluation reward: 3.71\n",
      "episode: 1621   score: 2.0   memory length: 333131   epsilon: 0.7691993200050105    steps: 183     evaluation reward: 3.66\n",
      "episode: 1622   score: 1.0   memory length: 333306   epsilon: 0.7690260700050142    steps: 175     evaluation reward: 3.67\n",
      "episode: 1623   score: 3.0   memory length: 333545   epsilon: 0.7687894600050194    steps: 239     evaluation reward: 3.66\n",
      "episode: 1624   score: 2.0   memory length: 333763   epsilon: 0.768573640005024    steps: 218     evaluation reward: 3.64\n",
      "episode: 1625   score: 2.0   memory length: 333979   epsilon: 0.7683598000050287    steps: 216     evaluation reward: 3.64\n",
      "episode: 1626   score: 1.0   memory length: 334145   epsilon: 0.7681954600050322    steps: 166     evaluation reward: 3.59\n",
      "episode: 1627   score: 8.0   memory length: 334567   epsilon: 0.7677776800050413    steps: 422     evaluation reward: 3.65\n",
      "episode: 1628   score: 2.0   memory length: 334799   epsilon: 0.7675480000050463    steps: 232     evaluation reward: 3.65\n",
      "episode: 1629   score: 2.0   memory length: 335022   epsilon: 0.7673272300050511    steps: 223     evaluation reward: 3.66\n",
      "episode: 1630   score: 10.0   memory length: 335488   epsilon: 0.7668658900050611    steps: 466     evaluation reward: 3.72\n",
      "episode: 1631   score: 6.0   memory length: 335861   epsilon: 0.7664966200050691    steps: 373     evaluation reward: 3.75\n",
      "episode: 1632   score: 5.0   memory length: 336172   epsilon: 0.7661887300050758    steps: 311     evaluation reward: 3.77\n",
      "episode: 1633   score: 10.0   memory length: 336544   epsilon: 0.7658204500050838    steps: 372     evaluation reward: 3.83\n",
      "episode: 1634   score: 3.0   memory length: 336791   epsilon: 0.7655759200050891    steps: 247     evaluation reward: 3.82\n",
      "episode: 1635   score: 4.0   memory length: 337064   epsilon: 0.765305650005095    steps: 273     evaluation reward: 3.83\n",
      "episode: 1636   score: 1.0   memory length: 337229   epsilon: 0.7651423000050985    steps: 165     evaluation reward: 3.82\n",
      "episode: 1637   score: 3.0   memory length: 337475   epsilon: 0.7648987600051038    steps: 246     evaluation reward: 3.84\n",
      "episode: 1638   score: 4.0   memory length: 337757   epsilon: 0.7646195800051099    steps: 282     evaluation reward: 3.85\n",
      "episode: 1639   score: 2.0   memory length: 337941   epsilon: 0.7644374200051138    steps: 184     evaluation reward: 3.8\n",
      "episode: 1640   score: 2.0   memory length: 338128   epsilon: 0.7642522900051179    steps: 187     evaluation reward: 3.76\n",
      "episode: 1641   score: 4.0   memory length: 338385   epsilon: 0.7639978600051234    steps: 257     evaluation reward: 3.76\n",
      "episode: 1642   score: 4.0   memory length: 338658   epsilon: 0.7637275900051292    steps: 273     evaluation reward: 3.74\n",
      "episode: 1643   score: 5.0   memory length: 338963   epsilon: 0.7634256400051358    steps: 305     evaluation reward: 3.75\n",
      "episode: 1644   score: 2.0   memory length: 339154   epsilon: 0.7632365500051399    steps: 191     evaluation reward: 3.71\n",
      "episode: 1645   score: 5.0   memory length: 339485   epsilon: 0.762908860005147    steps: 331     evaluation reward: 3.75\n",
      "episode: 1646   score: 6.0   memory length: 339838   epsilon: 0.7625593900051546    steps: 353     evaluation reward: 3.78\n",
      "episode: 1647   score: 4.0   memory length: 340134   epsilon: 0.762266350005161    steps: 296     evaluation reward: 3.82\n",
      "episode: 1648   score: 4.0   memory length: 340428   epsilon: 0.7619752900051673    steps: 294     evaluation reward: 3.83\n",
      "episode: 1649   score: 9.0   memory length: 340765   epsilon: 0.7616416600051745    steps: 337     evaluation reward: 3.89\n",
      "episode: 1650   score: 2.0   memory length: 340982   epsilon: 0.7614268300051792    steps: 217     evaluation reward: 3.89\n",
      "episode: 1651   score: 2.0   memory length: 341166   epsilon: 0.7612446700051831    steps: 184     evaluation reward: 3.84\n",
      "episode: 1652   score: 4.0   memory length: 341471   epsilon: 0.7609427200051897    steps: 305     evaluation reward: 3.84\n",
      "episode: 1653   score: 6.0   memory length: 341861   epsilon: 0.7605566200051981    steps: 390     evaluation reward: 3.86\n",
      "episode: 1654   score: 6.0   memory length: 342235   epsilon: 0.7601863600052061    steps: 374     evaluation reward: 3.9\n",
      "episode: 1655   score: 6.0   memory length: 342596   epsilon: 0.7598289700052139    steps: 361     evaluation reward: 3.95\n",
      "episode: 1656   score: 6.0   memory length: 342958   epsilon: 0.7594705900052217    steps: 362     evaluation reward: 3.94\n",
      "episode: 1657   score: 4.0   memory length: 343250   epsilon: 0.7591815100052279    steps: 292     evaluation reward: 3.95\n",
      "episode: 1658   score: 3.0   memory length: 343515   epsilon: 0.7589191600052336    steps: 265     evaluation reward: 3.95\n",
      "episode: 1659   score: 4.0   memory length: 343792   epsilon: 0.7586449300052396    steps: 277     evaluation reward: 3.95\n",
      "episode: 1660   score: 4.0   memory length: 344052   epsilon: 0.7583875300052452    steps: 260     evaluation reward: 3.95\n",
      "episode: 1661   score: 4.0   memory length: 344322   epsilon: 0.758120230005251    steps: 270     evaluation reward: 3.99\n",
      "episode: 1662   score: 4.0   memory length: 344611   epsilon: 0.7578341200052572    steps: 289     evaluation reward: 4.02\n",
      "episode: 1663   score: 2.0   memory length: 344814   epsilon: 0.7576331500052615    steps: 203     evaluation reward: 4.0\n",
      "episode: 1664   score: 0.0   memory length: 344951   epsilon: 0.7574975200052645    steps: 137     evaluation reward: 3.96\n",
      "episode: 1665   score: 3.0   memory length: 345196   epsilon: 0.7572549700052698    steps: 245     evaluation reward: 3.95\n",
      "episode: 1666   score: 5.0   memory length: 345531   epsilon: 0.756923320005277    steps: 335     evaluation reward: 3.97\n",
      "episode: 1667   score: 3.0   memory length: 345770   epsilon: 0.7566867100052821    steps: 239     evaluation reward: 3.97\n",
      "episode: 1668   score: 6.0   memory length: 346157   epsilon: 0.7563035800052904    steps: 387     evaluation reward: 4.0\n",
      "episode: 1669   score: 8.0   memory length: 346589   epsilon: 0.7558759000052997    steps: 432     evaluation reward: 4.03\n",
      "episode: 1670   score: 3.0   memory length: 346833   epsilon: 0.7556343400053049    steps: 244     evaluation reward: 4.05\n",
      "episode: 1671   score: 5.0   memory length: 347171   epsilon: 0.7552997200053122    steps: 338     evaluation reward: 4.03\n",
      "episode: 1672   score: 10.0   memory length: 347531   epsilon: 0.7549433200053199    steps: 360     evaluation reward: 4.11\n",
      "episode: 1673   score: 1.0   memory length: 347720   epsilon: 0.754756210005324    steps: 189     evaluation reward: 4.12\n",
      "episode: 1674   score: 3.0   memory length: 347960   epsilon: 0.7545186100053292    steps: 240     evaluation reward: 4.1\n",
      "episode: 1675   score: 5.0   memory length: 348293   epsilon: 0.7541889400053363    steps: 333     evaluation reward: 4.12\n",
      "episode: 1676   score: 3.0   memory length: 348566   epsilon: 0.7539186700053422    steps: 273     evaluation reward: 4.07\n",
      "episode: 1677   score: 3.0   memory length: 348802   epsilon: 0.7536850300053473    steps: 236     evaluation reward: 4.09\n",
      "episode: 1678   score: 2.0   memory length: 349017   epsilon: 0.7534721800053519    steps: 215     evaluation reward: 4.08\n",
      "episode: 1679   score: 5.0   memory length: 349335   epsilon: 0.7531573600053587    steps: 318     evaluation reward: 4.11\n",
      "episode: 1680   score: 1.0   memory length: 349494   epsilon: 0.7529999500053621    steps: 159     evaluation reward: 4.1\n",
      "episode: 1681   score: 4.0   memory length: 349763   epsilon: 0.7527336400053679    steps: 269     evaluation reward: 4.11\n",
      "now time :  2018-12-19 02:58:39.113364\n",
      "episode: 1682   score: 7.0   memory length: 350165   epsilon: 0.7523356600053765    steps: 402     evaluation reward: 4.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1683   score: 3.0   memory length: 350440   epsilon: 0.7520634100053825    steps: 275     evaluation reward: 4.18\n",
      "episode: 1684   score: 5.0   memory length: 350735   epsilon: 0.7517713600053888    steps: 295     evaluation reward: 4.18\n",
      "episode: 1685   score: 3.0   memory length: 350966   epsilon: 0.7515426700053938    steps: 231     evaluation reward: 4.15\n",
      "episode: 1686   score: 4.0   memory length: 351265   epsilon: 0.7512466600054002    steps: 299     evaluation reward: 4.1\n",
      "episode: 1687   score: 6.0   memory length: 351612   epsilon: 0.7509031300054076    steps: 347     evaluation reward: 4.13\n",
      "episode: 1688   score: 5.0   memory length: 351960   epsilon: 0.7505586100054151    steps: 348     evaluation reward: 4.16\n",
      "episode: 1689   score: 6.0   memory length: 352327   epsilon: 0.750195280005423    steps: 367     evaluation reward: 4.16\n",
      "episode: 1690   score: 8.0   memory length: 352786   epsilon: 0.7497408700054329    steps: 459     evaluation reward: 4.2\n",
      "episode: 1691   score: 6.0   memory length: 353166   epsilon: 0.749364670005441    steps: 380     evaluation reward: 4.19\n",
      "episode: 1692   score: 2.0   memory length: 353360   epsilon: 0.7491726100054452    steps: 194     evaluation reward: 4.2\n",
      "episode: 1693   score: 8.0   memory length: 353799   epsilon: 0.7487380000054547    steps: 439     evaluation reward: 4.22\n",
      "episode: 1694   score: 5.0   memory length: 354130   epsilon: 0.7484103100054618    steps: 331     evaluation reward: 4.24\n",
      "episode: 1695   score: 4.0   memory length: 354420   epsilon: 0.748123210005468    steps: 290     evaluation reward: 4.17\n",
      "episode: 1696   score: 2.0   memory length: 354631   epsilon: 0.7479143200054725    steps: 211     evaluation reward: 4.11\n",
      "episode: 1697   score: 3.0   memory length: 354865   epsilon: 0.7476826600054776    steps: 234     evaluation reward: 4.12\n",
      "episode: 1698   score: 6.0   memory length: 355206   epsilon: 0.7473450700054849    steps: 341     evaluation reward: 4.14\n",
      "episode: 1699   score: 5.0   memory length: 355531   epsilon: 0.7470233200054919    steps: 325     evaluation reward: 4.14\n",
      "episode: 1700   score: 3.0   memory length: 355762   epsilon: 0.7467946300054968    steps: 231     evaluation reward: 4.14\n",
      "episode: 1701   score: 2.0   memory length: 355979   epsilon: 0.7465798000055015    steps: 217     evaluation reward: 4.12\n",
      "episode: 1702   score: 5.0   memory length: 356312   epsilon: 0.7462501300055087    steps: 333     evaluation reward: 4.14\n",
      "episode: 1703   score: 6.0   memory length: 356737   epsilon: 0.7458293800055178    steps: 425     evaluation reward: 4.18\n",
      "episode: 1704   score: 5.0   memory length: 357053   epsilon: 0.7455165400055246    steps: 316     evaluation reward: 4.19\n",
      "episode: 1705   score: 2.0   memory length: 357271   epsilon: 0.7453007200055293    steps: 218     evaluation reward: 4.18\n",
      "episode: 1706   score: 8.0   memory length: 357678   epsilon: 0.744897790005538    steps: 407     evaluation reward: 4.23\n",
      "episode: 1707   score: 4.0   memory length: 357927   epsilon: 0.7446512800055434    steps: 249     evaluation reward: 4.25\n",
      "episode: 1708   score: 3.0   memory length: 358182   epsilon: 0.7443988300055489    steps: 255     evaluation reward: 4.21\n",
      "episode: 1709   score: 0.0   memory length: 358322   epsilon: 0.7442602300055519    steps: 140     evaluation reward: 4.18\n",
      "episode: 1710   score: 6.0   memory length: 358708   epsilon: 0.7438780900055602    steps: 386     evaluation reward: 4.22\n",
      "episode: 1711   score: 5.0   memory length: 359045   epsilon: 0.7435444600055674    steps: 337     evaluation reward: 4.26\n",
      "episode: 1712   score: 4.0   memory length: 359352   epsilon: 0.743240530005574    steps: 307     evaluation reward: 4.22\n",
      "episode: 1713   score: 4.0   memory length: 359670   epsilon: 0.7429257100055808    steps: 318     evaluation reward: 4.22\n",
      "episode: 1714   score: 5.0   memory length: 359958   epsilon: 0.742640590005587    steps: 288     evaluation reward: 4.2\n",
      "episode: 1715   score: 0.0   memory length: 360108   epsilon: 0.7424920900055902    steps: 150     evaluation reward: 4.17\n",
      "episode: 1716   score: 11.0   memory length: 360384   epsilon: 0.7422188500055962    steps: 276     evaluation reward: 4.21\n",
      "episode: 1717   score: 4.0   memory length: 360670   epsilon: 0.7419357100056023    steps: 286     evaluation reward: 4.18\n",
      "episode: 1718   score: 8.0   memory length: 360978   epsilon: 0.7416307900056089    steps: 308     evaluation reward: 4.24\n",
      "episode: 1719   score: 7.0   memory length: 361341   epsilon: 0.7412714200056167    steps: 363     evaluation reward: 4.27\n",
      "episode: 1720   score: 3.0   memory length: 361592   epsilon: 0.7410229300056221    steps: 251     evaluation reward: 4.26\n",
      "episode: 1721   score: 3.0   memory length: 361858   epsilon: 0.7407595900056279    steps: 266     evaluation reward: 4.27\n",
      "episode: 1722   score: 10.0   memory length: 362273   epsilon: 0.7403487400056368    steps: 415     evaluation reward: 4.36\n",
      "episode: 1723   score: 6.0   memory length: 362643   epsilon: 0.7399824400056447    steps: 370     evaluation reward: 4.39\n",
      "episode: 1724   score: 2.0   memory length: 362827   epsilon: 0.7398002800056487    steps: 184     evaluation reward: 4.39\n",
      "episode: 1725   score: 1.0   memory length: 363014   epsilon: 0.7396151500056527    steps: 187     evaluation reward: 4.38\n",
      "episode: 1726   score: 5.0   memory length: 363338   epsilon: 0.7392943900056597    steps: 324     evaluation reward: 4.42\n",
      "episode: 1727   score: 6.0   memory length: 363690   epsilon: 0.7389459100056672    steps: 352     evaluation reward: 4.4\n",
      "episode: 1728   score: 4.0   memory length: 363980   epsilon: 0.7386588100056735    steps: 290     evaluation reward: 4.42\n",
      "episode: 1729   score: 3.0   memory length: 364213   epsilon: 0.7384281400056785    steps: 233     evaluation reward: 4.43\n",
      "episode: 1730   score: 3.0   memory length: 364462   epsilon: 0.7381816300056838    steps: 249     evaluation reward: 4.36\n",
      "episode: 1731   score: 2.0   memory length: 364681   epsilon: 0.7379648200056885    steps: 219     evaluation reward: 4.32\n",
      "episode: 1732   score: 2.0   memory length: 364903   epsilon: 0.7377450400056933    steps: 222     evaluation reward: 4.29\n",
      "episode: 1733   score: 5.0   memory length: 365199   epsilon: 0.7374520000056997    steps: 296     evaluation reward: 4.24\n",
      "episode: 1734   score: 4.0   memory length: 365488   epsilon: 0.7371658900057059    steps: 289     evaluation reward: 4.25\n",
      "episode: 1735   score: 2.0   memory length: 365695   epsilon: 0.7369609600057103    steps: 207     evaluation reward: 4.23\n",
      "episode: 1736   score: 6.0   memory length: 366066   epsilon: 0.7365936700057183    steps: 371     evaluation reward: 4.28\n",
      "episode: 1737   score: 9.0   memory length: 366504   epsilon: 0.7361600500057277    steps: 438     evaluation reward: 4.34\n",
      "episode: 1738   score: 5.0   memory length: 366786   epsilon: 0.7358808700057338    steps: 282     evaluation reward: 4.35\n",
      "episode: 1739   score: 6.0   memory length: 367143   epsilon: 0.7355274400057414    steps: 357     evaluation reward: 4.39\n",
      "episode: 1740   score: 1.0   memory length: 367332   epsilon: 0.7353403300057455    steps: 189     evaluation reward: 4.38\n",
      "episode: 1741   score: 5.0   memory length: 367638   epsilon: 0.7350373900057521    steps: 306     evaluation reward: 4.39\n",
      "episode: 1742   score: 3.0   memory length: 367902   epsilon: 0.7347760300057578    steps: 264     evaluation reward: 4.38\n",
      "episode: 1743   score: 4.0   memory length: 368199   epsilon: 0.7344820000057641    steps: 297     evaluation reward: 4.37\n",
      "episode: 1744   score: 13.0   memory length: 368695   epsilon: 0.7339909600057748    steps: 496     evaluation reward: 4.48\n",
      "episode: 1745   score: 3.0   memory length: 368925   epsilon: 0.7337632600057797    steps: 230     evaluation reward: 4.46\n",
      "episode: 1746   score: 4.0   memory length: 369196   epsilon: 0.7334949700057856    steps: 271     evaluation reward: 4.44\n",
      "episode: 1747   score: 2.0   memory length: 369383   epsilon: 0.7333098400057896    steps: 187     evaluation reward: 4.42\n",
      "episode: 1748   score: 1.0   memory length: 369542   epsilon: 0.733152430005793    steps: 159     evaluation reward: 4.39\n",
      "episode: 1749   score: 4.0   memory length: 369851   epsilon: 0.7328465200057996    steps: 309     evaluation reward: 4.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1750   score: 7.0   memory length: 370247   epsilon: 0.7324544800058082    steps: 396     evaluation reward: 4.39\n",
      "episode: 1751   score: 3.0   memory length: 370476   epsilon: 0.7322277700058131    steps: 229     evaluation reward: 4.4\n",
      "episode: 1752   score: 6.0   memory length: 370837   epsilon: 0.7318703800058208    steps: 361     evaluation reward: 4.42\n",
      "episode: 1753   score: 11.0   memory length: 371400   epsilon: 0.7313130100058329    steps: 563     evaluation reward: 4.47\n",
      "episode: 1754   score: 3.0   memory length: 371636   epsilon: 0.731079370005838    steps: 236     evaluation reward: 4.44\n",
      "episode: 1755   score: 7.0   memory length: 372044   epsilon: 0.7306754500058468    steps: 408     evaluation reward: 4.45\n",
      "episode: 1756   score: 6.0   memory length: 372406   epsilon: 0.7303170700058546    steps: 362     evaluation reward: 4.45\n",
      "episode: 1757   score: 2.0   memory length: 372604   epsilon: 0.7301210500058588    steps: 198     evaluation reward: 4.43\n",
      "episode: 1758   score: 2.0   memory length: 372804   epsilon: 0.7299230500058631    steps: 200     evaluation reward: 4.42\n",
      "episode: 1759   score: 4.0   memory length: 373080   epsilon: 0.729649810005869    steps: 276     evaluation reward: 4.42\n",
      "episode: 1760   score: 5.0   memory length: 373402   epsilon: 0.729331030005876    steps: 322     evaluation reward: 4.43\n",
      "episode: 1761   score: 5.0   memory length: 373708   epsilon: 0.7290280900058825    steps: 306     evaluation reward: 4.44\n",
      "episode: 1762   score: 6.0   memory length: 374043   epsilon: 0.7286964400058897    steps: 335     evaluation reward: 4.46\n",
      "episode: 1763   score: 6.0   memory length: 374378   epsilon: 0.7283647900058969    steps: 335     evaluation reward: 4.5\n",
      "episode: 1764   score: 14.0   memory length: 374784   epsilon: 0.7279628500059057    steps: 406     evaluation reward: 4.64\n",
      "episode: 1765   score: 2.0   memory length: 375011   epsilon: 0.7277381200059105    steps: 227     evaluation reward: 4.63\n",
      "episode: 1766   score: 6.0   memory length: 375387   epsilon: 0.7273658800059186    steps: 376     evaluation reward: 4.64\n",
      "episode: 1767   score: 3.0   memory length: 375628   epsilon: 0.7271272900059238    steps: 241     evaluation reward: 4.64\n",
      "episode: 1768   score: 8.0   memory length: 376059   epsilon: 0.7267006000059331    steps: 431     evaluation reward: 4.66\n",
      "episode: 1769   score: 9.0   memory length: 376409   epsilon: 0.7263541000059406    steps: 350     evaluation reward: 4.67\n",
      "episode: 1770   score: 9.0   memory length: 376771   epsilon: 0.7259957200059484    steps: 362     evaluation reward: 4.73\n",
      "episode: 1771   score: 3.0   memory length: 377012   epsilon: 0.7257571300059535    steps: 241     evaluation reward: 4.71\n",
      "episode: 1772   score: 0.0   memory length: 377148   epsilon: 0.7256224900059565    steps: 136     evaluation reward: 4.61\n",
      "episode: 1773   score: 3.0   memory length: 377369   epsilon: 0.7254037000059612    steps: 221     evaluation reward: 4.63\n",
      "episode: 1774   score: 2.0   memory length: 377561   epsilon: 0.7252136200059653    steps: 192     evaluation reward: 4.62\n",
      "episode: 1775   score: 3.0   memory length: 377799   epsilon: 0.7249780000059705    steps: 238     evaluation reward: 4.6\n",
      "episode: 1776   score: 2.0   memory length: 378041   epsilon: 0.7247384200059757    steps: 242     evaluation reward: 4.59\n",
      "episode: 1777   score: 4.0   memory length: 378348   epsilon: 0.7244344900059823    steps: 307     evaluation reward: 4.6\n",
      "episode: 1778   score: 5.0   memory length: 378676   epsilon: 0.7241097700059893    steps: 328     evaluation reward: 4.63\n",
      "episode: 1779   score: 3.0   memory length: 378884   epsilon: 0.7239038500059938    steps: 208     evaluation reward: 4.61\n",
      "episode: 1780   score: 4.0   memory length: 379140   epsilon: 0.7236504100059993    steps: 256     evaluation reward: 4.64\n",
      "episode: 1781   score: 6.0   memory length: 379522   epsilon: 0.7232722300060075    steps: 382     evaluation reward: 4.66\n",
      "episode: 1782   score: 1.0   memory length: 379686   epsilon: 0.723109870006011    steps: 164     evaluation reward: 4.6\n",
      "episode: 1783   score: 6.0   memory length: 380066   epsilon: 0.7227336700060192    steps: 380     evaluation reward: 4.63\n",
      "episode: 1784   score: 1.0   memory length: 380244   epsilon: 0.722557450006023    steps: 178     evaluation reward: 4.59\n",
      "episode: 1785   score: 1.0   memory length: 380405   epsilon: 0.7223980600060265    steps: 161     evaluation reward: 4.57\n",
      "episode: 1786   score: 2.0   memory length: 380599   epsilon: 0.7222060000060306    steps: 194     evaluation reward: 4.55\n",
      "episode: 1787   score: 6.0   memory length: 380927   epsilon: 0.7218812800060377    steps: 328     evaluation reward: 4.55\n",
      "episode: 1788   score: 8.0   memory length: 381415   epsilon: 0.7213981600060482    steps: 488     evaluation reward: 4.58\n",
      "episode: 1789   score: 3.0   memory length: 381633   epsilon: 0.7211823400060529    steps: 218     evaluation reward: 4.55\n",
      "episode: 1790   score: 3.0   memory length: 381858   epsilon: 0.7209595900060577    steps: 225     evaluation reward: 4.5\n",
      "episode: 1791   score: 6.0   memory length: 382189   epsilon: 0.7206319000060648    steps: 331     evaluation reward: 4.5\n",
      "episode: 1792   score: 6.0   memory length: 382547   epsilon: 0.7202774800060725    steps: 358     evaluation reward: 4.54\n",
      "episode: 1793   score: 7.0   memory length: 382943   epsilon: 0.719885440006081    steps: 396     evaluation reward: 4.53\n",
      "episode: 1794   score: 7.0   memory length: 383338   epsilon: 0.7194943900060895    steps: 395     evaluation reward: 4.55\n",
      "episode: 1795   score: 3.0   memory length: 383565   epsilon: 0.7192696600060944    steps: 227     evaluation reward: 4.54\n",
      "episode: 1796   score: 5.0   memory length: 383865   epsilon: 0.7189726600061008    steps: 300     evaluation reward: 4.57\n",
      "episode: 1797   score: 2.0   memory length: 384067   epsilon: 0.7187726800061052    steps: 202     evaluation reward: 4.56\n",
      "episode: 1798   score: 12.0   memory length: 384546   epsilon: 0.7182984700061155    steps: 479     evaluation reward: 4.62\n",
      "episode: 1799   score: 3.0   memory length: 384785   epsilon: 0.7180618600061206    steps: 239     evaluation reward: 4.6\n",
      "episode: 1800   score: 8.0   memory length: 385068   epsilon: 0.7177816900061267    steps: 283     evaluation reward: 4.65\n",
      "episode: 1801   score: 5.0   memory length: 385393   epsilon: 0.7174599400061337    steps: 325     evaluation reward: 4.68\n",
      "episode: 1802   score: 3.0   memory length: 385654   epsilon: 0.7172015500061393    steps: 261     evaluation reward: 4.66\n",
      "episode: 1803   score: 4.0   memory length: 385911   epsilon: 0.7169471200061448    steps: 257     evaluation reward: 4.64\n",
      "episode: 1804   score: 2.0   memory length: 386102   epsilon: 0.7167580300061489    steps: 191     evaluation reward: 4.61\n",
      "episode: 1805   score: 3.0   memory length: 386332   epsilon: 0.7165303300061538    steps: 230     evaluation reward: 4.62\n",
      "episode: 1806   score: 5.0   memory length: 386649   epsilon: 0.7162165000061607    steps: 317     evaluation reward: 4.59\n",
      "episode: 1807   score: 9.0   memory length: 386994   epsilon: 0.7158749500061681    steps: 345     evaluation reward: 4.64\n",
      "episode: 1808   score: 3.0   memory length: 387240   epsilon: 0.7156314100061734    steps: 246     evaluation reward: 4.64\n",
      "episode: 1809   score: 3.0   memory length: 387494   epsilon: 0.7153799500061788    steps: 254     evaluation reward: 4.67\n",
      "episode: 1810   score: 4.0   memory length: 387753   epsilon: 0.7151235400061844    steps: 259     evaluation reward: 4.65\n",
      "episode: 1811   score: 3.0   memory length: 387971   epsilon: 0.7149077200061891    steps: 218     evaluation reward: 4.63\n",
      "episode: 1812   score: 3.0   memory length: 388187   epsilon: 0.7146938800061937    steps: 216     evaluation reward: 4.62\n",
      "episode: 1813   score: 5.0   memory length: 388476   epsilon: 0.7144077700061999    steps: 289     evaluation reward: 4.63\n",
      "episode: 1814   score: 4.0   memory length: 388752   epsilon: 0.7141345300062059    steps: 276     evaluation reward: 4.62\n",
      "episode: 1815   score: 6.0   memory length: 389145   epsilon: 0.7137454600062143    steps: 393     evaluation reward: 4.68\n",
      "episode: 1816   score: 7.0   memory length: 389538   epsilon: 0.7133563900062228    steps: 393     evaluation reward: 4.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1817   score: 9.0   memory length: 389872   epsilon: 0.7130257300062299    steps: 334     evaluation reward: 4.69\n",
      "episode: 1818   score: 6.0   memory length: 390252   epsilon: 0.7126495300062381    steps: 380     evaluation reward: 4.67\n",
      "episode: 1819   score: 10.0   memory length: 390756   epsilon: 0.7121505700062489    steps: 504     evaluation reward: 4.7\n",
      "episode: 1820   score: 5.0   memory length: 391043   epsilon: 0.7118664400062551    steps: 287     evaluation reward: 4.72\n",
      "episode: 1821   score: 4.0   memory length: 391334   epsilon: 0.7115783500062614    steps: 291     evaluation reward: 4.73\n",
      "episode: 1822   score: 8.0   memory length: 391785   epsilon: 0.711131860006271    steps: 451     evaluation reward: 4.71\n",
      "episode: 1823   score: 3.0   memory length: 392029   epsilon: 0.7108903000062763    steps: 244     evaluation reward: 4.68\n",
      "episode: 1824   score: 8.0   memory length: 392348   epsilon: 0.7105744900062831    steps: 319     evaluation reward: 4.74\n",
      "episode: 1825   score: 4.0   memory length: 392641   epsilon: 0.7102844200062894    steps: 293     evaluation reward: 4.77\n",
      "episode: 1826   score: 5.0   memory length: 392975   epsilon: 0.7099537600062966    steps: 334     evaluation reward: 4.77\n",
      "episode: 1827   score: 2.0   memory length: 393187   epsilon: 0.7097438800063012    steps: 212     evaluation reward: 4.73\n",
      "episode: 1828   score: 4.0   memory length: 393469   epsilon: 0.7094647000063072    steps: 282     evaluation reward: 4.73\n",
      "episode: 1829   score: 5.0   memory length: 393788   epsilon: 0.7091488900063141    steps: 319     evaluation reward: 4.75\n",
      "episode: 1830   score: 9.0   memory length: 394122   epsilon: 0.7088182300063213    steps: 334     evaluation reward: 4.81\n",
      "episode: 1831   score: 4.0   memory length: 394424   epsilon: 0.7085192500063278    steps: 302     evaluation reward: 4.83\n",
      "episode: 1832   score: 8.0   memory length: 394837   epsilon: 0.7081103800063366    steps: 413     evaluation reward: 4.89\n",
      "episode: 1833   score: 6.0   memory length: 395176   epsilon: 0.7077747700063439    steps: 339     evaluation reward: 4.9\n",
      "episode: 1834   score: 2.0   memory length: 395365   epsilon: 0.707587660006348    steps: 189     evaluation reward: 4.88\n",
      "episode: 1835   score: 4.0   memory length: 395626   epsilon: 0.7073292700063536    steps: 261     evaluation reward: 4.9\n",
      "episode: 1836   score: 7.0   memory length: 396017   epsilon: 0.706942180006362    steps: 391     evaluation reward: 4.91\n",
      "episode: 1837   score: 9.0   memory length: 396426   epsilon: 0.7065372700063708    steps: 409     evaluation reward: 4.91\n",
      "episode: 1838   score: 11.0   memory length: 396827   epsilon: 0.7061402800063794    steps: 401     evaluation reward: 4.97\n",
      "episode: 1839   score: 4.0   memory length: 397098   epsilon: 0.7058719900063852    steps: 271     evaluation reward: 4.95\n",
      "episode: 1840   score: 1.0   memory length: 397255   epsilon: 0.7057165600063886    steps: 157     evaluation reward: 4.95\n",
      "episode: 1841   score: 14.0   memory length: 397662   epsilon: 0.7053136300063974    steps: 407     evaluation reward: 5.04\n",
      "episode: 1842   score: 6.0   memory length: 398009   epsilon: 0.7049701000064048    steps: 347     evaluation reward: 5.07\n",
      "episode: 1843   score: 3.0   memory length: 398248   epsilon: 0.70473349000641    steps: 239     evaluation reward: 5.06\n",
      "episode: 1844   score: 4.0   memory length: 398539   epsilon: 0.7044454000064162    steps: 291     evaluation reward: 4.97\n",
      "episode: 1845   score: 9.0   memory length: 399013   epsilon: 0.7039761400064264    steps: 474     evaluation reward: 5.03\n",
      "episode: 1846   score: 8.0   memory length: 399434   epsilon: 0.7035593500064354    steps: 421     evaluation reward: 5.07\n",
      "episode: 1847   score: 8.0   memory length: 399882   epsilon: 0.7031158300064451    steps: 448     evaluation reward: 5.13\n",
      "now time :  2018-12-19 03:17:10.587224\n",
      "episode: 1848   score: 8.0   memory length: 400327   epsilon: 0.7026752800064546    steps: 445     evaluation reward: 5.2\n",
      "episode: 1849   score: 8.0   memory length: 400771   epsilon: 0.7022357200064642    steps: 444     evaluation reward: 5.24\n",
      "episode: 1850   score: 7.0   memory length: 401149   epsilon: 0.7018615000064723    steps: 378     evaluation reward: 5.24\n",
      "episode: 1851   score: 10.0   memory length: 401704   epsilon: 0.7013120500064842    steps: 555     evaluation reward: 5.31\n",
      "episode: 1852   score: 3.0   memory length: 401973   epsilon: 0.70104574000649    steps: 269     evaluation reward: 5.28\n",
      "episode: 1853   score: 2.0   memory length: 402193   epsilon: 0.7008279400064947    steps: 220     evaluation reward: 5.19\n",
      "episode: 1854   score: 4.0   memory length: 402465   epsilon: 0.7005586600065006    steps: 272     evaluation reward: 5.2\n",
      "episode: 1855   score: 6.0   memory length: 402835   epsilon: 0.7001923600065085    steps: 370     evaluation reward: 5.19\n",
      "episode: 1856   score: 5.0   memory length: 403181   epsilon: 0.699849820006516    steps: 346     evaluation reward: 5.18\n",
      "episode: 1857   score: 6.0   memory length: 403519   epsilon: 0.6995152000065232    steps: 338     evaluation reward: 5.22\n",
      "episode: 1858   score: 4.0   memory length: 403825   epsilon: 0.6992122600065298    steps: 306     evaluation reward: 5.24\n",
      "episode: 1859   score: 3.0   memory length: 404044   epsilon: 0.6989954500065345    steps: 219     evaluation reward: 5.23\n",
      "episode: 1860   score: 3.0   memory length: 404266   epsilon: 0.6987756700065393    steps: 222     evaluation reward: 5.21\n",
      "episode: 1861   score: 5.0   memory length: 404582   epsilon: 0.6984628300065461    steps: 316     evaluation reward: 5.21\n",
      "episode: 1862   score: 4.0   memory length: 404843   epsilon: 0.6982044400065517    steps: 261     evaluation reward: 5.19\n",
      "episode: 1863   score: 3.0   memory length: 405075   epsilon: 0.6979747600065567    steps: 232     evaluation reward: 5.16\n",
      "episode: 1864   score: 10.0   memory length: 405546   epsilon: 0.6975084700065668    steps: 471     evaluation reward: 5.12\n",
      "episode: 1865   score: 8.0   memory length: 406030   epsilon: 0.6970293100065772    steps: 484     evaluation reward: 5.18\n",
      "episode: 1866   score: 4.0   memory length: 406316   epsilon: 0.6967461700065833    steps: 286     evaluation reward: 5.16\n",
      "episode: 1867   score: 13.0   memory length: 406916   epsilon: 0.6961521700065962    steps: 600     evaluation reward: 5.26\n",
      "episode: 1868   score: 2.0   memory length: 407108   epsilon: 0.6959620900066004    steps: 192     evaluation reward: 5.2\n",
      "episode: 1869   score: 3.0   memory length: 407389   epsilon: 0.6956839000066064    steps: 281     evaluation reward: 5.14\n",
      "episode: 1870   score: 3.0   memory length: 407639   epsilon: 0.6954364000066118    steps: 250     evaluation reward: 5.08\n",
      "episode: 1871   score: 3.0   memory length: 407874   epsilon: 0.6952037500066168    steps: 235     evaluation reward: 5.08\n",
      "episode: 1872   score: 11.0   memory length: 408296   epsilon: 0.6947859700066259    steps: 422     evaluation reward: 5.19\n",
      "episode: 1873   score: 4.0   memory length: 408583   epsilon: 0.6945018400066321    steps: 287     evaluation reward: 5.2\n",
      "episode: 1874   score: 10.0   memory length: 408984   epsilon: 0.6941048500066407    steps: 401     evaluation reward: 5.28\n",
      "episode: 1875   score: 17.0   memory length: 409677   epsilon: 0.6934187800066556    steps: 693     evaluation reward: 5.42\n",
      "episode: 1876   score: 4.0   memory length: 410013   epsilon: 0.6930861400066628    steps: 336     evaluation reward: 5.44\n",
      "episode: 1877   score: 6.0   memory length: 410371   epsilon: 0.6927317200066705    steps: 358     evaluation reward: 5.46\n",
      "episode: 1878   score: 7.0   memory length: 410754   epsilon: 0.6923525500066787    steps: 383     evaluation reward: 5.48\n",
      "episode: 1879   score: 5.0   memory length: 411065   epsilon: 0.6920446600066854    steps: 311     evaluation reward: 5.5\n",
      "episode: 1880   score: 2.0   memory length: 411289   epsilon: 0.6918229000066902    steps: 224     evaluation reward: 5.48\n",
      "episode: 1881   score: 2.0   memory length: 411499   epsilon: 0.6916150000066947    steps: 210     evaluation reward: 5.44\n",
      "episode: 1882   score: 10.0   memory length: 411995   epsilon: 0.6911239600067054    steps: 496     evaluation reward: 5.53\n",
      "episode: 1883   score: 3.0   memory length: 412214   epsilon: 0.6909071500067101    steps: 219     evaluation reward: 5.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1884   score: 6.0   memory length: 412573   epsilon: 0.6905517400067178    steps: 359     evaluation reward: 5.55\n",
      "episode: 1885   score: 7.0   memory length: 412934   epsilon: 0.6901943500067256    steps: 361     evaluation reward: 5.61\n",
      "episode: 1886   score: 6.0   memory length: 413277   epsilon: 0.689854780006733    steps: 343     evaluation reward: 5.65\n",
      "episode: 1887   score: 6.0   memory length: 413613   epsilon: 0.6895221400067402    steps: 336     evaluation reward: 5.65\n",
      "episode: 1888   score: 10.0   memory length: 414038   epsilon: 0.6891013900067493    steps: 425     evaluation reward: 5.67\n",
      "episode: 1889   score: 9.0   memory length: 414369   epsilon: 0.6887737000067564    steps: 331     evaluation reward: 5.73\n",
      "episode: 1890   score: 4.0   memory length: 414652   epsilon: 0.6884935300067625    steps: 283     evaluation reward: 5.74\n",
      "episode: 1891   score: 2.0   memory length: 414842   epsilon: 0.6883054300067666    steps: 190     evaluation reward: 5.7\n",
      "episode: 1892   score: 5.0   memory length: 415161   epsilon: 0.6879896200067734    steps: 319     evaluation reward: 5.69\n",
      "episode: 1893   score: 4.0   memory length: 415461   epsilon: 0.6876926200067799    steps: 300     evaluation reward: 5.66\n",
      "episode: 1894   score: 2.0   memory length: 415663   epsilon: 0.6874926400067842    steps: 202     evaluation reward: 5.61\n",
      "episode: 1895   score: 8.0   memory length: 416054   epsilon: 0.6871055500067926    steps: 391     evaluation reward: 5.66\n",
      "episode: 1896   score: 6.0   memory length: 416372   epsilon: 0.6867907300067995    steps: 318     evaluation reward: 5.67\n",
      "episode: 1897   score: 7.0   memory length: 416764   epsilon: 0.6864026500068079    steps: 392     evaluation reward: 5.72\n",
      "episode: 1898   score: 10.0   memory length: 417241   epsilon: 0.6859304200068181    steps: 477     evaluation reward: 5.7\n",
      "episode: 1899   score: 6.0   memory length: 417620   epsilon: 0.6855552100068263    steps: 379     evaluation reward: 5.73\n",
      "episode: 1900   score: 6.0   memory length: 417995   epsilon: 0.6851839600068343    steps: 375     evaluation reward: 5.71\n",
      "episode: 1901   score: 3.0   memory length: 418253   epsilon: 0.6849285400068399    steps: 258     evaluation reward: 5.69\n",
      "episode: 1902   score: 2.0   memory length: 418458   epsilon: 0.6847255900068443    steps: 205     evaluation reward: 5.68\n",
      "episode: 1903   score: 4.0   memory length: 418765   epsilon: 0.6844216600068509    steps: 307     evaluation reward: 5.68\n",
      "episode: 1904   score: 3.0   memory length: 418980   epsilon: 0.6842088100068555    steps: 215     evaluation reward: 5.69\n",
      "episode: 1905   score: 13.0   memory length: 419592   epsilon: 0.6836029300068687    steps: 612     evaluation reward: 5.79\n",
      "episode: 1906   score: 3.0   memory length: 419821   epsilon: 0.6833762200068736    steps: 229     evaluation reward: 5.77\n",
      "episode: 1907   score: 7.0   memory length: 420229   epsilon: 0.6829723000068824    steps: 408     evaluation reward: 5.75\n",
      "episode: 1908   score: 1.0   memory length: 420387   epsilon: 0.6828158800068858    steps: 158     evaluation reward: 5.73\n",
      "episode: 1909   score: 8.0   memory length: 420695   epsilon: 0.6825109600068924    steps: 308     evaluation reward: 5.78\n",
      "episode: 1910   score: 5.0   memory length: 421031   epsilon: 0.6821783200068996    steps: 336     evaluation reward: 5.79\n",
      "episode: 1911   score: 7.0   memory length: 421440   epsilon: 0.6817734100069084    steps: 409     evaluation reward: 5.83\n",
      "episode: 1912   score: 10.0   memory length: 421842   epsilon: 0.681375430006917    steps: 402     evaluation reward: 5.9\n",
      "episode: 1913   score: 8.0   memory length: 422134   epsilon: 0.6810863500069233    steps: 292     evaluation reward: 5.93\n",
      "episode: 1914   score: 7.0   memory length: 422540   epsilon: 0.680684410006932    steps: 406     evaluation reward: 5.96\n",
      "episode: 1915   score: 5.0   memory length: 422851   epsilon: 0.6803765200069387    steps: 311     evaluation reward: 5.95\n",
      "episode: 1916   score: 5.0   memory length: 423182   epsilon: 0.6800488300069458    steps: 331     evaluation reward: 5.93\n",
      "episode: 1917   score: 4.0   memory length: 423455   epsilon: 0.6797785600069517    steps: 273     evaluation reward: 5.88\n",
      "episode: 1918   score: 4.0   memory length: 423735   epsilon: 0.6795013600069577    steps: 280     evaluation reward: 5.86\n",
      "episode: 1919   score: 5.0   memory length: 424063   epsilon: 0.6791766400069648    steps: 328     evaluation reward: 5.81\n",
      "episode: 1920   score: 11.0   memory length: 424524   epsilon: 0.6787202500069747    steps: 461     evaluation reward: 5.87\n",
      "episode: 1921   score: 10.0   memory length: 424911   epsilon: 0.678337120006983    steps: 387     evaluation reward: 5.93\n",
      "episode: 1922   score: 3.0   memory length: 425137   epsilon: 0.6781133800069878    steps: 226     evaluation reward: 5.88\n",
      "episode: 1923   score: 6.0   memory length: 425448   epsilon: 0.6778054900069945    steps: 311     evaluation reward: 5.91\n",
      "episode: 1924   score: 1.0   memory length: 425605   epsilon: 0.6776500600069979    steps: 157     evaluation reward: 5.84\n",
      "episode: 1925   score: 3.0   memory length: 425827   epsilon: 0.6774302800070027    steps: 222     evaluation reward: 5.83\n",
      "episode: 1926   score: 2.0   memory length: 426035   epsilon: 0.6772243600070071    steps: 208     evaluation reward: 5.8\n",
      "episode: 1927   score: 3.0   memory length: 426281   epsilon: 0.6769808200070124    steps: 246     evaluation reward: 5.81\n",
      "episode: 1928   score: 2.0   memory length: 426486   epsilon: 0.6767778700070168    steps: 205     evaluation reward: 5.79\n",
      "episode: 1929   score: 5.0   memory length: 426829   epsilon: 0.6764383000070242    steps: 343     evaluation reward: 5.79\n",
      "episode: 1930   score: 2.0   memory length: 427044   epsilon: 0.6762254500070288    steps: 215     evaluation reward: 5.72\n",
      "episode: 1931   score: 5.0   memory length: 427392   epsilon: 0.6758809300070363    steps: 348     evaluation reward: 5.73\n",
      "episode: 1932   score: 7.0   memory length: 427829   epsilon: 0.6754483000070457    steps: 437     evaluation reward: 5.72\n",
      "episode: 1933   score: 9.0   memory length: 428297   epsilon: 0.6749849800070558    steps: 468     evaluation reward: 5.75\n",
      "episode: 1934   score: 5.0   memory length: 428628   epsilon: 0.6746572900070629    steps: 331     evaluation reward: 5.78\n",
      "episode: 1935   score: 2.0   memory length: 428847   epsilon: 0.6744404800070676    steps: 219     evaluation reward: 5.76\n",
      "episode: 1936   score: 5.0   memory length: 429133   epsilon: 0.6741573400070737    steps: 286     evaluation reward: 5.74\n",
      "episode: 1937   score: 2.0   memory length: 429321   epsilon: 0.6739712200070778    steps: 188     evaluation reward: 5.67\n",
      "episode: 1938   score: 5.0   memory length: 429678   epsilon: 0.6736177900070854    steps: 357     evaluation reward: 5.61\n",
      "episode: 1939   score: 3.0   memory length: 429932   epsilon: 0.6733663300070909    steps: 254     evaluation reward: 5.6\n",
      "episode: 1940   score: 10.0   memory length: 430453   epsilon: 0.6728505400071021    steps: 521     evaluation reward: 5.69\n",
      "episode: 1941   score: 2.0   memory length: 430640   epsilon: 0.6726654100071061    steps: 187     evaluation reward: 5.57\n",
      "episode: 1942   score: 4.0   memory length: 430954   epsilon: 0.6723545500071129    steps: 314     evaluation reward: 5.55\n",
      "episode: 1943   score: 11.0   memory length: 431389   epsilon: 0.6719239000071222    steps: 435     evaluation reward: 5.63\n",
      "episode: 1944   score: 5.0   memory length: 431695   epsilon: 0.6716209600071288    steps: 306     evaluation reward: 5.64\n",
      "episode: 1945   score: 7.0   memory length: 432075   epsilon: 0.671244760007137    steps: 380     evaluation reward: 5.62\n",
      "episode: 1946   score: 6.0   memory length: 432415   epsilon: 0.6709081600071443    steps: 340     evaluation reward: 5.6\n",
      "episode: 1947   score: 7.0   memory length: 432801   epsilon: 0.6705260200071526    steps: 386     evaluation reward: 5.59\n",
      "episode: 1948   score: 9.0   memory length: 433143   epsilon: 0.6701874400071599    steps: 342     evaluation reward: 5.6\n",
      "episode: 1949   score: 6.0   memory length: 433483   epsilon: 0.6698508400071672    steps: 340     evaluation reward: 5.58\n",
      "episode: 1950   score: 3.0   memory length: 433709   epsilon: 0.6696271000071721    steps: 226     evaluation reward: 5.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1951   score: 6.0   memory length: 434109   epsilon: 0.6692311000071807    steps: 400     evaluation reward: 5.5\n",
      "episode: 1952   score: 2.0   memory length: 434301   epsilon: 0.6690410200071848    steps: 192     evaluation reward: 5.49\n",
      "episode: 1953   score: 2.0   memory length: 434508   epsilon: 0.6688360900071892    steps: 207     evaluation reward: 5.49\n",
      "episode: 1954   score: 9.0   memory length: 434977   epsilon: 0.6683717800071993    steps: 469     evaluation reward: 5.54\n",
      "episode: 1955   score: 14.0   memory length: 435612   epsilon: 0.667743130007213    steps: 635     evaluation reward: 5.62\n",
      "episode: 1956   score: 17.0   memory length: 436110   epsilon: 0.6672501100072237    steps: 498     evaluation reward: 5.74\n",
      "episode: 1957   score: 4.0   memory length: 436370   epsilon: 0.6669927100072293    steps: 260     evaluation reward: 5.72\n",
      "episode: 1958   score: 4.0   memory length: 436640   epsilon: 0.6667254100072351    steps: 270     evaluation reward: 5.72\n",
      "episode: 1959   score: 5.0   memory length: 436970   epsilon: 0.6663987100072422    steps: 330     evaluation reward: 5.74\n",
      "episode: 1960   score: 4.0   memory length: 437262   epsilon: 0.6661096300072484    steps: 292     evaluation reward: 5.75\n",
      "episode: 1961   score: 8.0   memory length: 437644   epsilon: 0.6657314500072566    steps: 382     evaluation reward: 5.78\n",
      "episode: 1962   score: 4.0   memory length: 437920   epsilon: 0.6654582100072626    steps: 276     evaluation reward: 5.78\n",
      "episode: 1963   score: 4.0   memory length: 438217   epsilon: 0.665164180007269    steps: 297     evaluation reward: 5.79\n",
      "episode: 1964   score: 0.0   memory length: 438345   epsilon: 0.6650374600072717    steps: 128     evaluation reward: 5.69\n",
      "episode: 1965   score: 8.0   memory length: 438638   epsilon: 0.664747390007278    steps: 293     evaluation reward: 5.69\n",
      "episode: 1966   score: 8.0   memory length: 439094   epsilon: 0.6642959500072878    steps: 456     evaluation reward: 5.73\n",
      "episode: 1967   score: 7.0   memory length: 439458   epsilon: 0.6639355900072956    steps: 364     evaluation reward: 5.67\n",
      "episode: 1968   score: 5.0   memory length: 439742   epsilon: 0.6636544300073017    steps: 284     evaluation reward: 5.7\n",
      "episode: 1969   score: 12.0   memory length: 440251   epsilon: 0.6631505200073127    steps: 509     evaluation reward: 5.79\n",
      "episode: 1970   score: 3.0   memory length: 440486   epsilon: 0.6629178700073177    steps: 235     evaluation reward: 5.79\n",
      "episode: 1971   score: 13.0   memory length: 440949   epsilon: 0.6624595000073277    steps: 463     evaluation reward: 5.89\n",
      "episode: 1972   score: 3.0   memory length: 441204   epsilon: 0.6622070500073332    steps: 255     evaluation reward: 5.81\n",
      "episode: 1973   score: 8.0   memory length: 441649   epsilon: 0.6617665000073427    steps: 445     evaluation reward: 5.85\n",
      "episode: 1974   score: 11.0   memory length: 442136   epsilon: 0.6612843700073532    steps: 487     evaluation reward: 5.86\n",
      "episode: 1975   score: 3.0   memory length: 442377   epsilon: 0.6610457800073584    steps: 241     evaluation reward: 5.72\n",
      "episode: 1976   score: 6.0   memory length: 442742   epsilon: 0.6606844300073662    steps: 365     evaluation reward: 5.74\n",
      "episode: 1977   score: 6.0   memory length: 443113   epsilon: 0.6603171400073742    steps: 371     evaluation reward: 5.74\n",
      "episode: 1978   score: 7.0   memory length: 443489   epsilon: 0.6599449000073823    steps: 376     evaluation reward: 5.74\n",
      "episode: 1979   score: 5.0   memory length: 443800   epsilon: 0.659637010007389    steps: 311     evaluation reward: 5.74\n",
      "episode: 1980   score: 5.0   memory length: 444101   epsilon: 0.6593390200073954    steps: 301     evaluation reward: 5.77\n",
      "episode: 1981   score: 5.0   memory length: 444395   epsilon: 0.6590479600074017    steps: 294     evaluation reward: 5.8\n",
      "episode: 1982   score: 7.0   memory length: 444809   epsilon: 0.6586381000074106    steps: 414     evaluation reward: 5.77\n",
      "episode: 1983   score: 8.0   memory length: 445234   epsilon: 0.6582173500074198    steps: 425     evaluation reward: 5.82\n",
      "episode: 1984   score: 7.0   memory length: 445496   epsilon: 0.6579579700074254    steps: 262     evaluation reward: 5.83\n",
      "episode: 1985   score: 7.0   memory length: 445843   epsilon: 0.6576144400074329    steps: 347     evaluation reward: 5.83\n",
      "episode: 1986   score: 4.0   memory length: 446155   epsilon: 0.6573055600074396    steps: 312     evaluation reward: 5.81\n",
      "episode: 1987   score: 7.0   memory length: 446548   epsilon: 0.656916490007448    steps: 393     evaluation reward: 5.82\n",
      "episode: 1988   score: 9.0   memory length: 447007   epsilon: 0.6564620800074579    steps: 459     evaluation reward: 5.81\n",
      "episode: 1989   score: 5.0   memory length: 447330   epsilon: 0.6561423100074648    steps: 323     evaluation reward: 5.77\n",
      "episode: 1990   score: 6.0   memory length: 447683   epsilon: 0.6557928400074724    steps: 353     evaluation reward: 5.79\n",
      "episode: 1991   score: 9.0   memory length: 448185   epsilon: 0.6552958600074832    steps: 502     evaluation reward: 5.86\n",
      "episode: 1992   score: 1.0   memory length: 448355   epsilon: 0.6551275600074868    steps: 170     evaluation reward: 5.82\n",
      "episode: 1993   score: 8.0   memory length: 448640   epsilon: 0.654845410007493    steps: 285     evaluation reward: 5.86\n",
      "episode: 1994   score: 4.0   memory length: 448942   epsilon: 0.6545464300074995    steps: 302     evaluation reward: 5.88\n",
      "episode: 1995   score: 9.0   memory length: 449312   epsilon: 0.6541801300075074    steps: 370     evaluation reward: 5.89\n",
      "episode: 1996   score: 12.0   memory length: 449766   epsilon: 0.6537306700075172    steps: 454     evaluation reward: 5.95\n",
      "now time :  2018-12-19 03:36:40.646007\n",
      "episode: 1997   score: 9.0   memory length: 450255   epsilon: 0.6532465600075277    steps: 489     evaluation reward: 5.97\n",
      "episode: 1998   score: 7.0   memory length: 450645   epsilon: 0.6528604600075361    steps: 390     evaluation reward: 5.94\n",
      "episode: 1999   score: 3.0   memory length: 450881   epsilon: 0.6526268200075411    steps: 236     evaluation reward: 5.91\n",
      "episode: 2000   score: 8.0   memory length: 451331   epsilon: 0.6521813200075508    steps: 450     evaluation reward: 5.93\n",
      "episode: 2001   score: 8.0   memory length: 451621   epsilon: 0.651894220007557    steps: 290     evaluation reward: 5.98\n",
      "episode: 2002   score: 5.0   memory length: 451934   epsilon: 0.6515843500075638    steps: 313     evaluation reward: 6.01\n",
      "episode: 2003   score: 7.0   memory length: 452363   epsilon: 0.651159640007573    steps: 429     evaluation reward: 6.04\n",
      "episode: 2004   score: 6.0   memory length: 452715   epsilon: 0.6508111600075805    steps: 352     evaluation reward: 6.07\n",
      "episode: 2005   score: 4.0   memory length: 452985   epsilon: 0.6505438600075863    steps: 270     evaluation reward: 5.98\n",
      "episode: 2006   score: 12.0   memory length: 453465   epsilon: 0.6500686600075967    steps: 480     evaluation reward: 6.07\n",
      "episode: 2007   score: 11.0   memory length: 454014   epsilon: 0.6495251500076085    steps: 549     evaluation reward: 6.11\n",
      "episode: 2008   score: 5.0   memory length: 454307   epsilon: 0.6492350800076148    steps: 293     evaluation reward: 6.15\n",
      "episode: 2009   score: 6.0   memory length: 454689   epsilon: 0.648856900007623    steps: 382     evaluation reward: 6.13\n",
      "episode: 2010   score: 7.0   memory length: 455059   epsilon: 0.6484906000076309    steps: 370     evaluation reward: 6.15\n",
      "episode: 2011   score: 3.0   memory length: 455281   epsilon: 0.6482708200076357    steps: 222     evaluation reward: 6.11\n",
      "episode: 2012   score: 9.0   memory length: 455765   epsilon: 0.6477916600076461    steps: 484     evaluation reward: 6.1\n",
      "episode: 2013   score: 9.0   memory length: 456276   epsilon: 0.6472857700076571    steps: 511     evaluation reward: 6.11\n",
      "episode: 2014   score: 5.0   memory length: 456596   epsilon: 0.646968970007664    steps: 320     evaluation reward: 6.09\n",
      "episode: 2015   score: 4.0   memory length: 456861   epsilon: 0.6467066200076697    steps: 265     evaluation reward: 6.08\n",
      "episode: 2016   score: 7.0   memory length: 457267   epsilon: 0.6463046800076784    steps: 406     evaluation reward: 6.1\n",
      "episode: 2017   score: 7.0   memory length: 457643   epsilon: 0.6459324400076865    steps: 376     evaluation reward: 6.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2018   score: 4.0   memory length: 457915   epsilon: 0.6456631600076923    steps: 272     evaluation reward: 6.13\n",
      "episode: 2019   score: 3.0   memory length: 458136   epsilon: 0.645444370007697    steps: 221     evaluation reward: 6.11\n",
      "episode: 2020   score: 9.0   memory length: 458582   epsilon: 0.6450028300077066    steps: 446     evaluation reward: 6.09\n",
      "episode: 2021   score: 6.0   memory length: 458932   epsilon: 0.6446563300077142    steps: 350     evaluation reward: 6.05\n",
      "episode: 2022   score: 11.0   memory length: 459347   epsilon: 0.6442454800077231    steps: 415     evaluation reward: 6.13\n",
      "episode: 2023   score: 3.0   memory length: 459573   epsilon: 0.6440217400077279    steps: 226     evaluation reward: 6.1\n",
      "episode: 2024   score: 11.0   memory length: 460005   epsilon: 0.6435940600077372    steps: 432     evaluation reward: 6.2\n",
      "episode: 2025   score: 13.0   memory length: 460612   epsilon: 0.6429931300077503    steps: 607     evaluation reward: 6.3\n",
      "episode: 2026   score: 4.0   memory length: 460902   epsilon: 0.6427060300077565    steps: 290     evaluation reward: 6.32\n",
      "episode: 2027   score: 3.0   memory length: 461138   epsilon: 0.6424723900077616    steps: 236     evaluation reward: 6.32\n",
      "episode: 2028   score: 9.0   memory length: 461577   epsilon: 0.642037780007771    steps: 439     evaluation reward: 6.39\n",
      "episode: 2029   score: 12.0   memory length: 462033   epsilon: 0.6415863400077808    steps: 456     evaluation reward: 6.46\n",
      "episode: 2030   score: 5.0   memory length: 462351   epsilon: 0.6412715200077876    steps: 318     evaluation reward: 6.49\n",
      "episode: 2031   score: 8.0   memory length: 462781   epsilon: 0.6408458200077969    steps: 430     evaluation reward: 6.52\n",
      "episode: 2032   score: 7.0   memory length: 463189   epsilon: 0.6404419000078057    steps: 408     evaluation reward: 6.52\n",
      "episode: 2033   score: 7.0   memory length: 463646   epsilon: 0.6399894700078155    steps: 457     evaluation reward: 6.5\n",
      "episode: 2034   score: 5.0   memory length: 463963   epsilon: 0.6396756400078223    steps: 317     evaluation reward: 6.5\n",
      "episode: 2035   score: 3.0   memory length: 464205   epsilon: 0.6394360600078275    steps: 242     evaluation reward: 6.51\n",
      "episode: 2036   score: 8.0   memory length: 464671   epsilon: 0.6389747200078375    steps: 466     evaluation reward: 6.54\n",
      "episode: 2037   score: 9.0   memory length: 465023   epsilon: 0.6386262400078451    steps: 352     evaluation reward: 6.61\n",
      "episode: 2038   score: 6.0   memory length: 465380   epsilon: 0.6382728100078527    steps: 357     evaluation reward: 6.62\n",
      "episode: 2039   score: 12.0   memory length: 465866   epsilon: 0.6377916700078632    steps: 486     evaluation reward: 6.71\n",
      "episode: 2040   score: 14.0   memory length: 466426   epsilon: 0.6372372700078752    steps: 560     evaluation reward: 6.75\n",
      "episode: 2041   score: 14.0   memory length: 467007   epsilon: 0.6366620800078877    steps: 581     evaluation reward: 6.87\n",
      "episode: 2042   score: 9.0   memory length: 467340   epsilon: 0.6363324100078949    steps: 333     evaluation reward: 6.92\n",
      "episode: 2043   score: 4.0   memory length: 467624   epsilon: 0.636051250007901    steps: 284     evaluation reward: 6.85\n",
      "episode: 2044   score: 2.0   memory length: 467823   epsilon: 0.6358542400079052    steps: 199     evaluation reward: 6.82\n",
      "episode: 2045   score: 4.0   memory length: 468119   epsilon: 0.6355612000079116    steps: 296     evaluation reward: 6.79\n",
      "episode: 2046   score: 6.0   memory length: 468489   epsilon: 0.6351949000079196    steps: 370     evaluation reward: 6.79\n",
      "episode: 2047   score: 5.0   memory length: 468804   epsilon: 0.6348830500079263    steps: 315     evaluation reward: 6.77\n",
      "episode: 2048   score: 6.0   memory length: 469141   epsilon: 0.6345494200079336    steps: 337     evaluation reward: 6.74\n",
      "episode: 2049   score: 4.0   memory length: 469407   epsilon: 0.6342860800079393    steps: 266     evaluation reward: 6.72\n",
      "episode: 2050   score: 3.0   memory length: 469648   epsilon: 0.6340474900079445    steps: 241     evaluation reward: 6.72\n",
      "episode: 2051   score: 3.0   memory length: 469924   epsilon: 0.6337742500079504    steps: 276     evaluation reward: 6.69\n",
      "episode: 2052   score: 6.0   memory length: 470290   epsilon: 0.6334119100079583    steps: 366     evaluation reward: 6.73\n",
      "episode: 2053   score: 7.0   memory length: 470676   epsilon: 0.6330297700079666    steps: 386     evaluation reward: 6.78\n",
      "episode: 2054   score: 5.0   memory length: 470969   epsilon: 0.6327397000079729    steps: 293     evaluation reward: 6.74\n",
      "episode: 2055   score: 15.0   memory length: 471391   epsilon: 0.6323219200079819    steps: 422     evaluation reward: 6.75\n",
      "episode: 2056   score: 18.0   memory length: 471834   epsilon: 0.6318833500079915    steps: 443     evaluation reward: 6.76\n",
      "episode: 2057   score: 7.0   memory length: 472218   epsilon: 0.6315031900079997    steps: 384     evaluation reward: 6.79\n",
      "episode: 2058   score: 2.0   memory length: 472422   epsilon: 0.6313012300080041    steps: 204     evaluation reward: 6.77\n",
      "episode: 2059   score: 5.0   memory length: 472723   epsilon: 0.6310032400080106    steps: 301     evaluation reward: 6.77\n",
      "episode: 2060   score: 4.0   memory length: 472980   epsilon: 0.6307488100080161    steps: 257     evaluation reward: 6.77\n",
      "episode: 2061   score: 8.0   memory length: 473286   epsilon: 0.6304458700080227    steps: 306     evaluation reward: 6.77\n",
      "episode: 2062   score: 5.0   memory length: 473624   epsilon: 0.6301112500080299    steps: 338     evaluation reward: 6.78\n",
      "episode: 2063   score: 8.0   memory length: 474073   epsilon: 0.6296667400080396    steps: 449     evaluation reward: 6.82\n",
      "episode: 2064   score: 15.0   memory length: 474513   epsilon: 0.629231140008049    steps: 440     evaluation reward: 6.97\n",
      "episode: 2065   score: 13.0   memory length: 475033   epsilon: 0.6287163400080602    steps: 520     evaluation reward: 7.02\n",
      "episode: 2066   score: 8.0   memory length: 475474   epsilon: 0.6282797500080697    steps: 441     evaluation reward: 7.02\n",
      "episode: 2067   score: 6.0   memory length: 475806   epsilon: 0.6279510700080768    steps: 332     evaluation reward: 7.01\n",
      "episode: 2068   score: 6.0   memory length: 476162   epsilon: 0.6275986300080845    steps: 356     evaluation reward: 7.02\n",
      "episode: 2069   score: 11.0   memory length: 476720   epsilon: 0.6270462100080965    steps: 558     evaluation reward: 7.01\n",
      "episode: 2070   score: 5.0   memory length: 477034   epsilon: 0.6267353500081032    steps: 314     evaluation reward: 7.03\n",
      "episode: 2071   score: 11.0   memory length: 477447   epsilon: 0.6263264800081121    steps: 413     evaluation reward: 7.01\n",
      "episode: 2072   score: 3.0   memory length: 477698   epsilon: 0.6260779900081175    steps: 251     evaluation reward: 7.01\n",
      "episode: 2073   score: 5.0   memory length: 478009   epsilon: 0.6257701000081242    steps: 311     evaluation reward: 6.98\n",
      "episode: 2074   score: 6.0   memory length: 478391   epsilon: 0.6253919200081324    steps: 382     evaluation reward: 6.93\n",
      "episode: 2075   score: 7.0   memory length: 478810   epsilon: 0.6249771100081414    steps: 419     evaluation reward: 6.97\n",
      "episode: 2076   score: 4.0   memory length: 479066   epsilon: 0.6247236700081469    steps: 256     evaluation reward: 6.95\n",
      "episode: 2077   score: 6.0   memory length: 479439   epsilon: 0.6243544000081549    steps: 373     evaluation reward: 6.95\n",
      "episode: 2078   score: 7.0   memory length: 479835   epsilon: 0.6239623600081634    steps: 396     evaluation reward: 6.95\n",
      "episode: 2079   score: 4.0   memory length: 480138   epsilon: 0.6236623900081699    steps: 303     evaluation reward: 6.94\n",
      "episode: 2080   score: 6.0   memory length: 480534   epsilon: 0.6232703500081784    steps: 396     evaluation reward: 6.95\n",
      "episode: 2081   score: 4.0   memory length: 480790   epsilon: 0.6230169100081839    steps: 256     evaluation reward: 6.94\n",
      "episode: 2082   score: 10.0   memory length: 481190   epsilon: 0.6226209100081925    steps: 400     evaluation reward: 6.97\n",
      "episode: 2083   score: 14.0   memory length: 481752   epsilon: 0.6220645300082046    steps: 562     evaluation reward: 7.03\n",
      "episode: 2084   score: 10.0   memory length: 482260   epsilon: 0.6215616100082155    steps: 508     evaluation reward: 7.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 2085   score: 3.0   memory length: 482525   epsilon: 0.6212992600082212    steps: 265     evaluation reward: 7.02\n",
      "episode: 2086   score: 9.0   memory length: 483002   epsilon: 0.6208270300082315    steps: 477     evaluation reward: 7.07\n",
      "episode: 2087   score: 12.0   memory length: 483463   epsilon: 0.6203706400082414    steps: 461     evaluation reward: 7.12\n",
      "episode: 2088   score: 10.0   memory length: 483915   epsilon: 0.6199231600082511    steps: 452     evaluation reward: 7.13\n",
      "episode: 2089   score: 3.0   memory length: 484164   epsilon: 0.6196766500082564    steps: 249     evaluation reward: 7.11\n",
      "episode: 2090   score: 3.0   memory length: 484429   epsilon: 0.6194143000082621    steps: 265     evaluation reward: 7.08\n",
      "episode: 2091   score: 5.0   memory length: 484754   epsilon: 0.6190925500082691    steps: 325     evaluation reward: 7.04\n",
      "episode: 2092   score: 8.0   memory length: 485213   epsilon: 0.618638140008279    steps: 459     evaluation reward: 7.11\n",
      "episode: 2093   score: 6.0   memory length: 485570   epsilon: 0.6182847100082867    steps: 357     evaluation reward: 7.09\n",
      "episode: 2094   score: 9.0   memory length: 486012   epsilon: 0.6178471300082962    steps: 442     evaluation reward: 7.14\n",
      "episode: 2095   score: 5.0   memory length: 486313   epsilon: 0.6175491400083026    steps: 301     evaluation reward: 7.1\n",
      "episode: 2096   score: 3.0   memory length: 486552   epsilon: 0.6173125300083078    steps: 239     evaluation reward: 7.01\n",
      "episode: 2097   score: 5.0   memory length: 486859   epsilon: 0.6170086000083144    steps: 307     evaluation reward: 6.97\n",
      "episode: 2098   score: 3.0   memory length: 487098   epsilon: 0.6167719900083195    steps: 239     evaluation reward: 6.93\n",
      "episode: 2099   score: 9.0   memory length: 487595   epsilon: 0.6162799600083302    steps: 497     evaluation reward: 6.99\n",
      "episode: 2100   score: 9.0   memory length: 488100   epsilon: 0.615780010008341    steps: 505     evaluation reward: 7.0\n",
      "episode: 2101   score: 14.0   memory length: 488733   epsilon: 0.6151533400083546    steps: 633     evaluation reward: 7.06\n"
     ]
    }
   ],
   "source": [
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "    step = 0\n",
    "    d = False\n",
    "    state = env.reset()\n",
    "    life = number_lives\n",
    "\n",
    "    get_init_state(history, state)\n",
    "\n",
    "    while not done:\n",
    "        step += 1\n",
    "        frame += 1\n",
    "        #if render_breakout:\n",
    "        #    env.render()\n",
    "\n",
    "        # Select and perform an action\n",
    "        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "\n",
    "        \n",
    "        next_state, reward, done, info = env.step(action + 1)\n",
    "\n",
    "        frame_next_state = get_frame(next_state)\n",
    "        history[4, :, :] = frame_next_state\n",
    "        terminal_state = check_live(life, info['ale.lives'])\n",
    "\n",
    "        life = info['ale.lives']\n",
    "        r = np.clip(reward, -1, 1)\n",
    "\n",
    "        # Store the transition in memory \n",
    "        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "        # Start training after random sample generation\n",
    "        if(frame >= train_frame):\n",
    "            agent.train_policy_net(frame)\n",
    "            # Update the target network\n",
    "            if(frame % Update_target_network_frequency)== 0:\n",
    "                agent.update_target_net()\n",
    "        score += reward\n",
    "        history[:4, :, :] = history[1:, :, :]\n",
    "\n",
    "        if frame % 50000 == 0:\n",
    "            print('now time : ', datetime.now())\n",
    "            rewards.append(np.mean(evaluation_reward))\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, rewards, 'b')\n",
    "            pylab.savefig(\"./save_graph/breakout_dqn.png\")\n",
    "\n",
    "        if done:\n",
    "            evaluation_reward.append(score)\n",
    "            # every episode, plot the play time\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n",
    "                  \"    evaluation reward:\", np.mean(evaluation_reward))\n",
    "\n",
    "            # if the mean of scores of last 10 episode is bigger than 400\n",
    "            # stop training\n",
    "            if np.mean(evaluation_reward) > 10:\n",
    "                torch.save(agent.policy_net, \"./save_model/breakout_dqn\")\n",
    "                sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.policy_net, \"./save_model/breakout_dqn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
